{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurgalakshmiU/durgaa_INFO5731_Spring2021/blob/main/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "559bbc38-3daf-40ae-a3ff-742184357bb8"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('abst1.csv') \n",
        "df\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"...   ...\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\"... The concept of maximum entropy can be tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\"... Scaling conditional random fields for nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"... The paper addresses the issue of cooperat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"... In most natural language processing appli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>\"... This paper presents a workbench built by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>\"... Abstract—Natural Language Processing (NLP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>\"... ABSTRACT: After twenty years of disfavor,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>\"... Text statistics are frequently used in st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>\"... We summarize our experience using FrameNe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0                                           ABSTRACT\n",
              "0            0                                        \"...   ...\"\n",
              "1            1  \"... The concept of maximum entropy can be tra...\n",
              "2            2  \"... Scaling conditional random fields for nat...\n",
              "3            3  \"... The paper addresses the issue of cooperat...\n",
              "4            4  \"... In most natural language processing appli...\n",
              "..         ...                                                ...\n",
              "95          95  \"... This paper presents a workbench built by ...\n",
              "96          96  \"... Abstract—Natural Language Processing (NLP...\n",
              "97          97  \"... ABSTRACT: After twenty years of disfavor,...\n",
              "98          98  \"... Text statistics are frequently used in st...\n",
              "99          99  \"... We summarize our experience using FrameNe...\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8lM-kvfPVWo-",
        "outputId": "b1e6380d-5bb7-42fa-b0e3-63b5b0e18965"
      },
      "source": [
        "df = pd.read_csv('abst1.csv')\r\n",
        "df.to_csv(\"abst2.csv\", index=False)\r\n",
        "df['cleansentence'] = df['ABSTRACT'].apply(lambda a: \" \".join(a.lower() for a in a.split()))\r\n",
        "df['cleansentence'].head()  #lower casing\r\n",
        "df['cleansentence'] =df['cleansentence'] .str.replace('[^\\w\\s]','')\r\n",
        "df['cleansentence'] .head()  # special char and punctuation removal\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stop = stopwords.words('english')\r\n",
        "df['cleansentence']= df['cleansentence'].apply(lambda a: \" \".join(a for a in a.split() if a not in stop))\r\n",
        "df['cleansentence'].head()  #stopwords removal\r\n",
        "df['cleansentence'] = df['cleansentence'].str.replace(\"[0-9]\", \" \")\r\n",
        "df['cleansentence'].head()      #Numbers removal\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "st = PorterStemmer()    #stemming\r\n",
        "df['cleansentence'][:6].apply(lambda a: \" \".join([st.stem(word) for word in a.split()]))\r\n",
        "nltk.download('wordnet')\r\n",
        "from textblob import Word\r\n",
        "df['cleansentence'] = df['cleansentence'].apply(lambda a: \" \".join([Word(word).lemmatize() for word in a.split()]))\r\n",
        "df['cleansentence'].head()   #Lemmatization\r\n",
        "df['cleansentence'].to_csv('abst2.csv')     #Adding cleaned sentence column to csv file\r\n",
        "df                  #cleaned sentence\r\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>cleansentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"...   ...\"</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\"... The concept of maximum entropy can be tra...</td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\"... Scaling conditional random fields for nat...</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"... The paper addresses the issue of cooperat...</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"... In most natural language processing appli...</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>\"... This paper presents a workbench built by ...</td>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>\"... Abstract—Natural Language Processing (NLP...</td>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>\"... ABSTRACT: After twenty years of disfavor,...</td>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>\"... Text statistics are frequently used in st...</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>\"... We summarize our experience using FrameNe...</td>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                      cleansentence\n",
              "0            0  ...                                                   \n",
              "1            1  ...  concept maximum entropy traced back along mult...\n",
              "2            2  ...  scaling conditional random field natural langu...\n",
              "3            3  ...  paper address issue cooperation linguistics na...\n",
              "4            4  ...  natural language processing application descri...\n",
              "..         ...  ...                                                ...\n",
              "95          95  ...  paper present workbench built priberam informá...\n",
              "96          96  ...  abstractnatural language processing nlp effect...\n",
              "97          97  ...  abstract twenty year disfavor technology retur...\n",
              "98          98  ...  text statistic frequently used stylometry cryp...\n",
              "99          99  ...  summarize experience using framenet two rather...\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADxir__rVkfR",
        "outputId": "2ef9e4f0-8258-42e9-b705-68716f6a604b"
      },
      "source": [
        "#trigrams\r\n",
        "from nltk.util import ngrams\r\n",
        "d = open('abst2.csv', \"r\")\r\n",
        "tri_grams = ngrams(d.read().split(), 3)\r\n",
        "t_freqdist=nltk.FreqDist(tri_grams)   #count\r\n",
        "display(t_freqdist)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FreqDist({(',cleansentence', '0,', '1,concept'): 1,\n",
              "          ('0,', '1,concept', 'maximum'): 1,\n",
              "          ('1,concept', 'maximum', 'entropy'): 1,\n",
              "          ('maximum', 'entropy', 'traced'): 1,\n",
              "          ('entropy', 'traced', 'back'): 1,\n",
              "          ('traced', 'back', 'along'): 1,\n",
              "          ('back', 'along', 'multiple'): 1,\n",
              "          ('along', 'multiple', 'thread'): 1,\n",
              "          ('multiple', 'thread', 'biblical'): 1,\n",
              "          ('thread', 'biblical', 'time'): 1,\n",
              "          ('biblical', 'time', 'recently'): 1,\n",
              "          ('time', 'recently', 'however'): 1,\n",
              "          ('recently', 'however', 'computer'): 1,\n",
              "          ('however', 'computer', 'become'): 1,\n",
              "          ('computer', 'become', 'powerful'): 1,\n",
              "          ('become', 'powerful', 'enough'): 1,\n",
              "          ('powerful', 'enough', 'permit'): 1,\n",
              "          ('enough', 'permit', 'widescale'): 1,\n",
              "          ('permit', 'widescale', 'application'): 1,\n",
              "          ('widescale', 'application', 'concept'): 1,\n",
              "          ('application', 'concept', 'real'): 1,\n",
              "          ('concept', 'real', 'world'): 1,\n",
              "          ('real', 'world', 'problem'): 1,\n",
              "          ('world', 'problem', 'statistical'): 1,\n",
              "          ('problem', 'statistical', 'estimation'): 1,\n",
              "          ('statistical', 'estimation', 'pattern'): 1,\n",
              "          ('estimation', 'pattern', 'recognition'): 1,\n",
              "          ('pattern', 'recognition', 'paper'): 1,\n",
              "          ('recognition', 'paper', 'de'): 1,\n",
              "          ('paper', 'de', '2,scaling'): 1,\n",
              "          ('de', '2,scaling', 'conditional'): 1,\n",
              "          ('2,scaling', 'conditional', 'random'): 1,\n",
              "          ('conditional', 'random', 'field'): 1,\n",
              "          ('random', 'field', 'natural'): 1,\n",
              "          ('field', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'processing'): 50,\n",
              "          ('language', 'processing', 'term'): 1,\n",
              "          ('processing', 'term', 'condition'): 1,\n",
              "          ('term', 'condition', 'term'): 1,\n",
              "          ('condition', 'term', 'condition'): 1,\n",
              "          ('term', 'condition', 'copyright'): 1,\n",
              "          ('condition', 'copyright', 'work'): 1,\n",
              "          ('copyright', 'work', 'deposited'): 1,\n",
              "          ('work', 'deposited', 'minerva'): 1,\n",
              "          ('deposited', 'minerva', 'access'): 1,\n",
              "          ('minerva', 'access', 'retained'): 1,\n",
              "          ('access', 'retained', '3,paper'): 1,\n",
              "          ('retained', '3,paper', 'address'): 1,\n",
              "          ('3,paper', 'address', 'issue'): 1,\n",
              "          ('address', 'issue', 'cooperation'): 1,\n",
              "          ('issue', 'cooperation', 'linguistics'): 1,\n",
              "          ('cooperation', 'linguistics', 'natural'): 1,\n",
              "          ('linguistics', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'nlp'): 16,\n",
              "          ('processing', 'nlp', 'general'): 1,\n",
              "          ('nlp', 'general', 'linguistics'): 1,\n",
              "          ('general', 'linguistics', 'machine'): 1,\n",
              "          ('linguistics', 'machine', 'translation'): 1,\n",
              "          ('machine', 'translation', 'mt'): 1,\n",
              "          ('translation', 'mt', 'particular'): 1,\n",
              "          ('mt', 'particular', 'focus'): 1,\n",
              "          ('particular', 'focus', 'one'): 1,\n",
              "          ('focus', 'one', 'direction'): 1,\n",
              "          ('one', 'direction', 'cooperation'): 1,\n",
              "          ('direction', 'cooperation', 'namely'): 1,\n",
              "          ('cooperation', 'namely', 'application'): 1,\n",
              "          ('namely', 'application', 'linguistics'): 1,\n",
              "          ('application', 'linguistics', 'nlp'): 1,\n",
              "          ('linguistics', 'nlp', 'virtually'): 1,\n",
              "          ('nlp', 'virtually', 'ignoring'): 1,\n",
              "          ('virtually', 'ignoring', '4,natural'): 1,\n",
              "          ('ignoring', '4,natural', 'language'): 1,\n",
              "          ('4,natural', 'language', 'processing'): 1,\n",
              "          ('language', 'processing', 'application'): 2,\n",
              "          ('processing', 'application', 'description'): 1,\n",
              "          ('application', 'description', 'logic'): 1,\n",
              "          ('description', 'logic', 'used'): 1,\n",
              "          ('logic', 'used', 'encode'): 1,\n",
              "          ('used', 'encode', 'knowledge'): 1,\n",
              "          ('encode', 'knowledge', 'base'): 1,\n",
              "          ('knowledge', 'base', 'syntactic'): 1,\n",
              "          ('base', 'syntactic', 'semantic'): 1,\n",
              "          ('syntactic', 'semantic', 'pragmatic'): 1,\n",
              "          ('semantic', 'pragmatic', 'element'): 1,\n",
              "          ('pragmatic', 'element', 'needed'): 1,\n",
              "          ('element', 'needed', 'drive'): 1,\n",
              "          ('needed', 'drive', 'semantic'): 1,\n",
              "          ('drive', 'semantic', 'interpretation'): 1,\n",
              "          ('semantic', 'interpretation', 'natural'): 1,\n",
              "          ('interpretation', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'generation'): 1,\n",
              "          ('language', 'generation', 'process'): 1,\n",
              "          ('generation', 'process', 'recently'): 1,\n",
              "          ('process', 'recently', 'description'): 1,\n",
              "          ('recently', 'description', 'logic'): 1,\n",
              "          ('description', 'logic', 'u'): 1,\n",
              "          ('logic', 'u', '5,propose'): 1,\n",
              "          ('u', '5,propose', 'unified'): 1,\n",
              "          ('5,propose', 'unified', 'neural'): 1,\n",
              "          ('unified', 'neural', 'network'): 1,\n",
              "          ('neural', 'network', 'architecture'): 2,\n",
              "          ('network', 'architecture', 'learning'): 1,\n",
              "          ('architecture', 'learning', 'algorithm'): 1,\n",
              "          ('learning', 'algorithm', 'applied'): 1,\n",
              "          ('algorithm', 'applied', 'various'): 1,\n",
              "          ('applied', 'various', 'natural'): 1,\n",
              "          ('various', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'task'): 2,\n",
              "          ('processing', 'task', 'including'): 1,\n",
              "          ('task', 'including', 'partofspeech'): 1,\n",
              "          ('including', 'partofspeech', 'tagging'): 1,\n",
              "          ('partofspeech', 'tagging', 'chunking'): 1,\n",
              "          ('tagging', 'chunking', 'named'): 1,\n",
              "          ('chunking', 'named', 'entity'): 1,\n",
              "          ('named', 'entity', 'recognition'): 1,\n",
              "          ('entity', 'recognition', 'semantic'): 1,\n",
              "          ('recognition', 'semantic', 'role'): 1,\n",
              "          ('semantic', 'role', 'labeling'): 1,\n",
              "          ('role', 'labeling', 'versatility'): 1,\n",
              "          ('labeling', 'versatility', 'achieved'): 1,\n",
              "          ('versatility', 'achieved', 'trying'): 1,\n",
              "          ('achieved', 'trying', 'avoid'): 1,\n",
              "          ('trying', 'avoid', 'taskspecific'): 1,\n",
              "          ('avoid', 'taskspecific', 'eng'): 1,\n",
              "          ('taskspecific', 'eng', '6,natural'): 1,\n",
              "          ('eng', '6,natural', 'language'): 1,\n",
              "          ('6,natural', 'language', 'processing'): 1,\n",
              "          ('language', 'processing', 'subject'): 1,\n",
              "          ('processing', 'subject', 'natural'): 1,\n",
              "          ('subject', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'considered'): 1,\n",
              "          ('processing', 'considered', 'broad'): 1,\n",
              "          ('considered', 'broad', 'narrow'): 1,\n",
              "          ('broad', 'narrow', 'sens'): 1,\n",
              "          ('narrow', 'sens', 'broad'): 1,\n",
              "          ('sens', 'broad', 'sense'): 1,\n",
              "          ('broad', 'sense', 'cover'): 1,\n",
              "          ('sense', 'cover', 'processing'): 1,\n",
              "          ('cover', 'processing', 'issue'): 1,\n",
              "          ('processing', 'issue', 'level'): 1,\n",
              "          ('issue', 'level', 'natural'): 1,\n",
              "          ('level', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'understanding'): 1,\n",
              "          ('language', 'understanding', 'including'): 1,\n",
              "          ('understanding', 'including', 'speech'): 1,\n",
              "          ('including', 'speech', 'recognition'): 1,\n",
              "          ('speech', 'recognition', 'syntactic'): 1,\n",
              "          ('recognition', 'syntactic', 'semantic'): 1,\n",
              "          ('syntactic', 'semantic', 'analysis'): 1,\n",
              "          ('semantic', 'analysis', 'sentence'): 1,\n",
              "          ('analysis', 'sentence', 'refer'): 1,\n",
              "          ('sentence', 'refer', '7,robot'): 1,\n",
              "          ('refer', '7,robot', 'interact'): 1,\n",
              "          ('7,robot', 'interact', 'human'): 1,\n",
              "          ('interact', 'human', 'facetoface'): 1,\n",
              "          ('human', 'facetoface', 'using'): 1,\n",
              "          ('facetoface', 'using', 'natural'): 1,\n",
              "          ('using', 'natural', 'language'): 2,\n",
              "          ('natural', 'language', 'need'): 2,\n",
              "          ('language', 'need', 'responsive'): 1,\n",
              "          ('need', 'responsive', 'way'): 1,\n",
              "          ('responsive', 'way', 'human'): 1,\n",
              "          ('way', 'human', 'use'): 1,\n",
              "          ('human', 'use', 'language'): 1,\n",
              "          ('use', 'language', 'situation'): 1,\n",
              "          ('language', 'situation', 'propose'): 1,\n",
              "          ('situation', 'propose', 'psychologicallyinspired'): 1,\n",
              "          ('propose', 'psychologicallyinspired', 'natural'): 1,\n",
              "          ('psychologicallyinspired', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'system'): 6,\n",
              "          ('processing', 'system', 'robot'): 1,\n",
              "          ('system', 'robot', 'performs'): 1,\n",
              "          ('robot', 'performs', 'incremental'): 1,\n",
              "          ('performs', 'incremental', 'semantic'): 1,\n",
              "          ('incremental', 'semantic', 'interpretation'): 1,\n",
              "          ('semantic', 'interpretation', 'spoken'): 1,\n",
              "          ('interpretation', 'spoken', 'utterance'): 1,\n",
              "          ('spoken', 'utterance', '8,natural'): 1,\n",
              "          ('utterance', '8,natural', 'language'): 1,\n",
              "          ('8,natural', 'language', 'language'): 1,\n",
              "          ('language', 'language', 'spoken'): 2,\n",
              "          ('language', 'spoken', 'human'): 1,\n",
              "          ('spoken', 'human', 'currently'): 1,\n",
              "          ('human', 'currently', 'yet'): 1,\n",
              "          ('currently', 'yet', 'point'): 1,\n",
              "          ('yet', 'point', 'language'): 1,\n",
              "          ('point', 'language', 'unprocessed'): 1,\n",
              "          ('language', 'unprocessed', 'form'): 1,\n",
              "          ('unprocessed', 'form', 'understood'): 1,\n",
              "          ('form', 'understood', 'computer'): 1,\n",
              "          ('understood', 'computer', 'natural'): 1,\n",
              "          ('computer', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'collection'): 1,\n",
              "          ('processing', 'collection', 'technique'): 1,\n",
              "          ('collection', 'technique', 'employed'): 1,\n",
              "          ('technique', 'employed', 'try'): 1,\n",
              "          ('employed', 'try', 'accomplish'): 1,\n",
              "          ('try', 'accomplish', 'goal'): 1,\n",
              "          ('accomplish', 'goal', 'field'): 1,\n",
              "          ('goal', 'field', 'natural'): 1,\n",
              "          ('field', 'natural', 'l'): 1,\n",
              "          ('natural', 'l', '9,abstract'): 1,\n",
              "          ('l', '9,abstract', 'ambiguity'): 1,\n",
              "          ('9,abstract', 'ambiguity', 'referred'): 1,\n",
              "          ('ambiguity', 'referred', 'ability'): 1,\n",
              "          ('referred', 'ability', 'one'): 1,\n",
              "          ('ability', 'one', 'meaning'): 1,\n",
              "          ('one', 'meaning', 'understood'): 1,\n",
              "          ('meaning', 'understood', 'one'): 1,\n",
              "          ('understood', 'one', 'way'): 1,\n",
              "          ('one', 'way', 'natural'): 1,\n",
              "          ('way', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'ambiguous'): 1,\n",
              "          ('language', 'ambiguous', 'computer'): 1,\n",
              "          ('ambiguous', 'computer', 'able'): 1,\n",
              "          ('computer', 'able', 'understand'): 1,\n",
              "          ('able', 'understand', 'language'): 1,\n",
              "          ('understand', 'language', 'way'): 1,\n",
              "          ('language', 'way', 'people'): 1,\n",
              "          ('way', 'people', 'natural'): 1,\n",
              "          ('people', 'natural', 'language'): 1,\n",
              "          ('processing', 'nlp', 'concerned'): 1,\n",
              "          ('nlp', 'concerned', 'development'): 1,\n",
              "          ('concerned', 'development', 'co'): 1,\n",
              "          ('development', 'co', '10,introduction'): 1,\n",
              "          ('co', '10,introduction', 'statistical'): 1,\n",
              "          ('10,introduction', 'statistical', 'natural'): 1,\n",
              "          ('statistical', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'snlp'): 1,\n",
              "          ('processing', 'snlp', 'field'): 1,\n",
              "          ('snlp', 'field', 'lying'): 1,\n",
              "          ('field', 'lying', 'intersection'): 1,\n",
              "          ('lying', 'intersection', 'natural'): 1,\n",
              "          ('intersection', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'machine'): 1,\n",
              "          ('processing', 'machine', 'learning'): 1,\n",
              "          ('machine', 'learning', 'snlp'): 1,\n",
              "          ('learning', 'snlp', 'diers'): 1,\n",
              "          ('snlp', 'diers', 'traditional'): 1,\n",
              "          ('diers', 'traditional', 'natural'): 1,\n",
              "          ('traditional', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'instead'): 1,\n",
              "          ('processing', 'instead', 'linguist'): 1,\n",
              "          ('instead', 'linguist', 'manually'): 1,\n",
              "          ('linguist', 'manually', 'construct'): 1,\n",
              "          ('manually', 'construct', 'model'): 1,\n",
              "          ('construct', 'model', 'given'): 1,\n",
              "          ('model', 'given', 'linguistic'): 1,\n",
              "          ('given', 'linguistic', '11,paper'): 1,\n",
              "          ('linguistic', '11,paper', 'summarizes'): 1,\n",
              "          ('11,paper', 'summarizes', 'essential'): 1,\n",
              "          ('summarizes', 'essential', 'property'): 1,\n",
              "          ('essential', 'property', 'document'): 1,\n",
              "          ('property', 'document', 'retrieval'): 1,\n",
              "          ('document', 'retrieval', 'review'): 1,\n",
              "          ('retrieval', 'review', 'conventional'): 1,\n",
              "          ('review', 'conventional', 'practice'): 1,\n",
              "          ('conventional', 'practice', 'research'): 1,\n",
              "          ('practice', 'research', 'finding'): 1,\n",
              "          ('research', 'finding', 'latter'): 1,\n",
              "          ('finding', 'latter', 'suggesting'): 1,\n",
              "          ('latter', 'suggesting', 'simple'): 1,\n",
              "          ('suggesting', 'simple', 'statistical'): 1,\n",
              "          ('simple', 'statistical', 'technique'): 1,\n",
              "          ('statistical', 'technique', 'effective'): 1,\n",
              "          ('technique', 'effective', 'considers'): 1,\n",
              "          ('effective', 'considers', 'new'): 1,\n",
              "          ('considers', 'new', 'opportunity'): 1,\n",
              "          ('new', 'opportunity', 'challenge'): 1,\n",
              "          ('opportunity', 'challenge', 'presented'): 1,\n",
              "          ('challenge', 'presented', 'ability'): 1,\n",
              "          ('presented', 'ability', 'search'): 1,\n",
              "          ('ability', 'search', 'full'): 1,\n",
              "          ('search', 'full', '12,abstract'): 1,\n",
              "          ('full', '12,abstract', 'language'): 1,\n",
              "          ('12,abstract', 'language', 'way'): 1,\n",
              "          ('language', 'way', 'communicating'): 1,\n",
              "          ('way', 'communicating', 'word'): 1,\n",
              "          ('communicating', 'word', 'language'): 1,\n",
              "          ('word', 'language', 'help'): 1,\n",
              "          ('language', 'help', 'understanding'): 1,\n",
              "          ('help', 'understanding', 'worldwe'): 1,\n",
              "          ('understanding', 'worldwe', 'get'): 1,\n",
              "          ('worldwe', 'get', 'better'): 1,\n",
              "          ('get', 'better', 'insight'): 1,\n",
              "          ('better', 'insight', 'world'): 1,\n",
              "          ('insight', 'world', 'language'): 1,\n",
              "          ('world', 'language', 'help'): 1,\n",
              "          ('language', 'help', 'speaker'): 1,\n",
              "          ('help', 'speaker', 'vague'): 1,\n",
              "          ('speaker', 'vague', 'precise'): 1,\n",
              "          ('vague', 'precise', 'like'): 1,\n",
              "          ('precise', 'like', 'nlp'): 1,\n",
              "          ('like', 'nlp', 'stand'): 1,\n",
              "          ('nlp', 'stand', 'natural'): 1,\n",
              "          ('stand', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'natural'): 1,\n",
              "          ('processing', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'language'): 2,\n",
              "          ('language', 'spoken', '13,report'): 1,\n",
              "          ('spoken', '13,report', 'experiment'): 1,\n",
              "          ('13,report', 'experiment', 'use'): 1,\n",
              "          ('experiment', 'use', 'standard'): 1,\n",
              "          ('use', 'standard', 'natural'): 1,\n",
              "          ('standard', 'natural', 'language'): 1,\n",
              "          ('processing', 'nlp', 'tool'): 1,\n",
              "          ('nlp', 'tool', 'analysis'): 1,\n",
              "          ('tool', 'analysis', 'music'): 1,\n",
              "          ('analysis', 'music', 'lyric'): 1,\n",
              "          ('music', 'lyric', 'significant'): 1,\n",
              "          ('lyric', 'significant', 'amount'): 1,\n",
              "          ('significant', 'amount', 'music'): 1,\n",
              "          ('amount', 'music', 'audio'): 1,\n",
              "          ('music', 'audio', 'lyric'): 1,\n",
              "          ('audio', 'lyric', 'lyric'): 1,\n",
              "          ('lyric', 'lyric', 'encode'): 1,\n",
              "          ('lyric', 'encode', 'important'): 1,\n",
              "          ('encode', 'important', 'part'): 1,\n",
              "          ('important', 'part', 'semantics'): 1,\n",
              "          ('part', 'semantics', 'song'): 1,\n",
              "          ('semantics', 'song', 'therefore'): 1,\n",
              "          ('song', 'therefore', 'analysis'): 1,\n",
              "          ('therefore', 'analysis', 'complement'): 1,\n",
              "          ('analysis', 'complement', 'acoustic'): 1,\n",
              "          ('complement', 'acoustic', 'cultural'): 1,\n",
              "          ('acoustic', 'cultural', 'metada'): 1,\n",
              "          ('cultural', 'metada', '14,paper'): 1,\n",
              "          ('metada', '14,paper', 'describe'): 1,\n",
              "          ('14,paper', 'describe', 'simple'): 1,\n",
              "          ('describe', 'simple', 'rulebased'): 1,\n",
              "          ('simple', 'rulebased', 'approach'): 1,\n",
              "          ('rulebased', 'approach', 'automated'): 1,\n",
              "          ('approach', 'automated', 'learning'): 1,\n",
              "          ('automated', 'learning', 'linguistic'): 1,\n",
              "          ('learning', 'linguistic', 'knowledge'): 1,\n",
              "          ('linguistic', 'knowledge', 'approach'): 1,\n",
              "          ('knowledge', 'approach', 'shown'): 1,\n",
              "          ('approach', 'shown', 'number'): 1,\n",
              "          ('shown', 'number', 'task'): 1,\n",
              "          ('number', 'task', 'capture'): 1,\n",
              "          ('task', 'capture', 'information'): 1,\n",
              "          ('capture', 'information', 'clearer'): 1,\n",
              "          ('information', 'clearer', 'direct'): 1,\n",
              "          ('clearer', 'direct', 'fashion'): 1,\n",
              "          ('direct', 'fashion', 'without'): 1,\n",
              "          ('fashion', 'without', 'compromise'): 1,\n",
              "          ('without', 'compromise', 'performance'): 1,\n",
              "          ('compromise', 'performance', 'present'): 1,\n",
              "          ('performance', 'present', 'detailed'): 1,\n",
              "          ('present', 'detailed', 'case'): 1,\n",
              "          ('detailed', 'case', 'study'): 1,\n",
              "          ('case', 'study', 'learni'): 1,\n",
              "          ('study', 'learni', '15,paper'): 1,\n",
              "          ('learni', '15,paper', 'focus'): 1,\n",
              "          ('15,paper', 'focus', 'connectionist'): 1,\n",
              "          ('focus', 'connectionist', 'model'): 1,\n",
              "          ('connectionist', 'model', 'natural'): 1,\n",
              "          ('model', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'briefly'): 1,\n",
              "          ('processing', 'briefly', 'present'): 1,\n",
              "          ('briefly', 'present', 'discus'): 1,\n",
              "          ('present', 'discus', 'several'): 1,\n",
              "          ('discus', 'several', 'aspect'): 1,\n",
              "          ('several', 'aspect', 'high'): 1,\n",
              "          ('aspect', 'high', 'level'): 1,\n",
              "          ('high', 'level', 'task'): 1,\n",
              "          ('level', 'task', 'recently'): 1,\n",
              "          ('task', 'recently', 'approached'): 1,\n",
              "          ('recently', 'approached', 'connectionism'): 1,\n",
              "          ('approached', 'connectionism', 'either'): 1,\n",
              "          ('connectionism', 'either', 'localist'): 1,\n",
              "          ('either', 'localist', 'parallel'): 1,\n",
              "          ('localist', 'parallel', 'distributed'): 1,\n",
              "          ('parallel', 'distributed', 'processing'): 1,\n",
              "          ('distributed', 'processing', 'model'): 1,\n",
              "          ('processing', 'model', 'several'): 1,\n",
              "          ('model', 'several', 'interesting'): 1,\n",
              "          ('several', 'interesting', 'architecture'): 1,\n",
              "          ('interesting', 'architecture', '16,abstract'): 1,\n",
              "          ('architecture', '16,abstract', 'article'): 1,\n",
              "          ('16,abstract', 'article', 'explores'): 1,\n",
              "          ('article', 'explores', 'possibility'): 1,\n",
              "          ('explores', 'possibility', 'construct'): 1,\n",
              "          ('possibility', 'construct', 'unified'): 1,\n",
              "          ('construct', 'unified', 'word'): 1,\n",
              "          ('unified', 'word', 'feature'): 1,\n",
              "          ('word', 'feature', 'component'): 1,\n",
              "          ('feature', 'component', 'feature'): 1,\n",
              "          ('component', 'feature', 'letter'): 1,\n",
              "          ('feature', 'letter', 'letter'): 1,\n",
              "          ('letter', 'letter', 'modeled'): 1,\n",
              "          ('letter', 'modeled', 'different'): 1,\n",
              "          ('modeled', 'different', 'attractor'): 1,\n",
              "          ('different', 'attractor', 'finally'): 1,\n",
              "          ('attractor', 'finally', 'embedded'): 1,\n",
              "          ('finally', 'embedded', 'quadratic'): 1,\n",
              "          ('embedded', 'quadratic', 'iterated'): 1,\n",
              "          ('quadratic', 'iterated', 'map'): 1,\n",
              "          ('iterated', 'map', 'result'): 1,\n",
              "          ('map', 'result', 'word'): 1,\n",
              "          ('result', 'word', 'feature'): 1,\n",
              "          ('word', 'feature', 'account'): 1,\n",
              "          ('feature', 'account', 'meaning'): 1,\n",
              "          ('account', 'meaning', 'extraction'): 1,\n",
              "          ('meaning', 'extraction', 'pr'): 1,\n",
              "          ('extraction', 'pr', '17,paper'): 1,\n",
              "          ('pr', '17,paper', 'see'): 1,\n",
              "          ('17,paper', 'see', 'schank'): 1,\n",
              "          ('see', 'schank', 'theoretical'): 1,\n",
              "          ('schank', 'theoretical', 'discussion'): 1,\n",
              "          ('theoretical', 'discussion', 'ka'): 1,\n",
              "          ('discussion', 'ka', 'leake'): 1,\n",
              "          ('ka', 'leake', 'owen'): 1,\n",
              "          ('leake', 'owen', 'brief'): 1,\n",
              "          ('owen', 'brief', 'discussion'): 1,\n",
              "          ('brief', 'discussion', 'program'): 1,\n",
              "          ('discussion', 'program', 'built'): 1,\n",
              "          ('program', 'built', 'around'): 1,\n",
              "          ('built', 'around', 'principle'): 1,\n",
              "          ('around', 'principle', 'goal'): 1,\n",
              "          ('principle', 'goal', 'simply'): 1,\n",
              "          ('goal', 'simply', 'point'): 1,\n",
              "          ('simply', 'point', 'interest'): 1,\n",
              "          ('point', 'interest', 'natural'): 1,\n",
              "          ('interest', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'led'): 1,\n",
              "          ('processing', 'led', 'u'): 1,\n",
              "          ('led', 'u', 'naturally'): 1,\n",
              "          ('u', 'naturally', 'indeed'): 1,\n",
              "          ('naturally', 'indeed', 'inevitably'): 1,\n",
              "          ('indeed', 'inevitably', 'de'): 1,\n",
              "          ('inevitably', 'de', '18,objective'): 1,\n",
              "          ('de', '18,objective', 'provide'): 1,\n",
              "          ('18,objective', 'provide', 'overview'): 1,\n",
              "          ('provide', 'overview', 'tutorial'): 1,\n",
              "          ('overview', 'tutorial', 'natural'): 1,\n",
              "          ('tutorial', 'natural', 'language'): 1,\n",
              "          ('processing', 'nlp', 'modern'): 1,\n",
              "          ('nlp', 'modern', 'nlpsystem'): 1,\n",
              "          ('modern', 'nlpsystem', 'design'): 1,\n",
              "          ('nlpsystem', 'design', 'target'): 1,\n",
              "          ('design', 'target', 'audience'): 1,\n",
              "          ('target', 'audience', 'tutorial'): 1,\n",
              "          ('audience', 'tutorial', 'target'): 1,\n",
              "          ('tutorial', 'target', 'medical'): 1,\n",
              "          ('target', 'medical', 'informatics'): 1,\n",
              "          ('medical', 'informatics', 'generalist'): 1,\n",
              "          ('informatics', 'generalist', 'limited'): 1,\n",
              "          ('generalist', 'limited', 'acquaintance'): 1,\n",
              "          ('limited', 'acquaintance', 'principle'): 1,\n",
              "          ('acquaintance', 'principle', 'behind'): 1,\n",
              "          ('principle', 'behind', 'nlp'): 1,\n",
              "          ('behind', 'nlp', 'andor'): 1,\n",
              "          ('nlp', 'andor', 'limited'): 1,\n",
              "          ('andor', 'limited', 'knowledge'): 1,\n",
              "          ('limited', 'knowledge', 'current'): 1,\n",
              "          ('knowledge', 'current', 'state'): 1,\n",
              "          ('current', 'state', '19,paper'): 1,\n",
              "          ('state', '19,paper', 'briefly'): 1,\n",
              "          ('19,paper', 'briefly', 'describes'): 1,\n",
              "          ('briefly', 'describes', 'current'): 1,\n",
              "          ('describes', 'current', 'implementation'): 1,\n",
              "          ('current', 'implementation', 'status'): 1,\n",
              "          ('implementation', 'status', 'intelligent'): 1,\n",
              "          ('status', 'intelligent', 'information'): 1,\n",
              "          ('intelligent', 'information', 'retrieval'): 1,\n",
              "          ('information', 'retrieval', 'system'): 2,\n",
              "          ('retrieval', 'system', 'marie'): 1,\n",
              "          ('system', 'marie', 'employ'): 1,\n",
              "          ('marie', 'employ', 'natural'): 1,\n",
              "          ('employ', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'technique'): 2,\n",
              "          ('processing', 'technique', 'descriptive'): 1,\n",
              "          ('technique', 'descriptive', 'caption'): 1,\n",
              "          ('descriptive', 'caption', 'used'): 1,\n",
              "          ('caption', 'used', 'iden'): 1,\n",
              "          ('used', 'iden', 'tify'): 1,\n",
              "          ('iden', 'tify', 'photographic'): 1,\n",
              "          ('tify', 'photographic', 'image'): 1,\n",
              "          ('photographic', 'image', 'concerning'): 1,\n",
              "          ('image', 'concerning', 'various'): 1,\n",
              "          ('concerning', 'various', 'military'): 1,\n",
              "          ('various', 'military', 'project'): 1,\n",
              "          ('military', 'project', 'caption'): 1,\n",
              "          ('project', 'caption', 'parsed'): 1,\n",
              "          ('caption', 'parsed', '20,abstract'): 1,\n",
              "          ('parsed', '20,abstract', 'metabolism'): 1,\n",
              "          ('20,abstract', 'metabolism', 'machinery'): 1,\n",
              "          ('metabolism', 'machinery', 'life'): 1,\n",
              "          ('machinery', 'life', 'signal'): 1,\n",
              "          ('life', 'signal', 'transduction'): 1,\n",
              "          ('signal', 'transduction', 'provides'): 1,\n",
              "          ('transduction', 'provides', 'regulatory'): 1,\n",
              "          ('provides', 'regulatory', 'mechanism'): 1,\n",
              "          ('regulatory', 'mechanism', 'control'): 1,\n",
              "          ('mechanism', 'control', 'machinery'): 1,\n",
              "          ('control', 'machinery', 'due'): 1,\n",
              "          ('machinery', 'due', 'complexity'): 1,\n",
              "          ('due', 'complexity', 'signal'): 1,\n",
              "          ('complexity', 'signal', 'transduction'): 1,\n",
              "          ('signal', 'transduction', 'pathway'): 1,\n",
              "          ('transduction', 'pathway', 'computational'): 1,\n",
              "          ('pathway', 'computational', 'approach'): 1,\n",
              "          ('computational', 'approach', 'needed'): 1,\n",
              "          ('approach', 'needed', 'aid'): 1,\n",
              "          ('needed', 'aid', 'biologist'): 1,\n",
              "          ('aid', 'biologist', 'integrating'): 1,\n",
              "          ('biologist', 'integrating', 'available'): 1,\n",
              "          ('integrating', 'available', 'knowledge'): 1,\n",
              "          ('available', 'knowledge', 'formulatio'): 1,\n",
              "          ('knowledge', 'formulatio', '21,report'): 1,\n",
              "          ('formulatio', '21,report', 'present'): 1,\n",
              "          ('21,report', 'present', 'detailed'): 1,\n",
              "          ('present', 'detailed', 'analysis'): 1,\n",
              "          ('detailed', 'analysis', 'review'): 1,\n",
              "          ('analysis', 'review', 'nlp'): 1,\n",
              "          ('review', 'nlp', 'evaluation'): 1,\n",
              "          ('nlp', 'evaluation', 'principle'): 1,\n",
              "          ('evaluation', 'principle', 'practice'): 1,\n",
              "          ('principle', 'practice', 'part'): 1,\n",
              "          ('practice', 'part', 'examines'): 1,\n",
              "          ('part', 'examines', 'evaluation'): 1,\n",
              "          ('examines', 'evaluation', 'concept'): 1,\n",
              "          ('evaluation', 'concept', 'establishes'): 1,\n",
              "          ('concept', 'establishes', 'framework'): 1,\n",
              "          ('establishes', 'framework', 'nlp'): 1,\n",
              "          ('framework', 'nlp', 'system'): 1,\n",
              "          ('nlp', 'system', 'evaluation'): 1,\n",
              "          ('system', 'evaluation', 'make'): 1,\n",
              "          ('evaluation', 'make', 'use'): 1,\n",
              "          ('make', 'use', 'experience'): 1,\n",
              "          ('use', 'experience', 'related'): 1,\n",
              "          ('experience', 'related', 'area'): 1,\n",
              "          ('related', 'area', 'information'): 1,\n",
              "          ('area', 'information', 'retrieval'): 1,\n",
              "          ('information', 'retrieval', 'analysis'): 1,\n",
              "          ('retrieval', 'analysis', 'also'): 1,\n",
              "          ('analysis', 'also', 'refers'): 1,\n",
              "          ('also', 'refers', 'ev'): 1,\n",
              "          ('refers', 'ev', '22,web'): 1,\n",
              "          ('ev', '22,web', 'emerged'): 1,\n",
              "          ('22,web', 'emerged', 'important'): 1,\n",
              "          ('emerged', 'important', 'source'): 1,\n",
              "          ('important', 'source', 'information'): 1,\n",
              "          ('source', 'information', 'world'): 1,\n",
              "          ('information', 'world', 'resulted'): 1,\n",
              "          ('world', 'resulted', 'need'): 1,\n",
              "          ('resulted', 'need', 'automated'): 1,\n",
              "          ('need', 'automated', 'software'): 1,\n",
              "          ('automated', 'software', 'component'): 1,\n",
              "          ('software', 'component', 'analyze'): 1,\n",
              "          ('component', 'analyze', 'web'): 1,\n",
              "          ('analyze', 'web', 'page'): 1,\n",
              "          ('web', 'page', 'harvest'): 1,\n",
              "          ('page', 'harvest', 'useful'): 1,\n",
              "          ('harvest', 'useful', 'information'): 1,\n",
              "          ('useful', 'information', 'however'): 1,\n",
              "          ('information', 'however', 'typical'): 1,\n",
              "          ('however', 'typical', 'web'): 1,\n",
              "          ('typical', 'web', 'page'): 1,\n",
              "          ('web', 'page', 'informative'): 1,\n",
              "          ('page', 'informative', 'content'): 1,\n",
              "          ('informative', 'content', 'surrounded'): 1,\n",
              "          ('content', 'surrounded', 'high'): 1,\n",
              "          ('surrounded', 'high', 'degree'): 1,\n",
              "          ('high', 'degree', 'noise'): 1,\n",
              "          ('degree', 'noise', '23,abstract'): 1,\n",
              "          ('noise', '23,abstract', 'natural'): 1,\n",
              "          ('23,abstract', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'theoretically'): 1,\n",
              "          ('processing', 'theoretically', 'motivated'): 1,\n",
              "          ('theoretically', 'motivated', 'range'): 1,\n",
              "          ('motivated', 'range', 'computational'): 1,\n",
              "          ('range', 'computational', 'technique'): 1,\n",
              "          ('computational', 'technique', 'analysing'): 1,\n",
              "          ('technique', 'analysing', 'representing'): 1,\n",
              "          ('analysing', 'representing', 'naturally'): 1,\n",
              "          ('representing', 'naturally', 'occurring'): 1,\n",
              "          ('naturally', 'occurring', 'text'): 1,\n",
              "          ('occurring', 'text', 'one'): 1,\n",
              "          ('text', 'one', 'level'): 1,\n",
              "          ('one', 'level', 'linguistic'): 1,\n",
              "          ('level', 'linguistic', 'analysis'): 1,\n",
              "          ('linguistic', 'analysis', 'purpose'): 1,\n",
              "          ('analysis', 'purpose', 'achieving'): 1,\n",
              "          ('purpose', 'achieving', 'humanlike'): 1,\n",
              "          ('achieving', 'humanlike', 'language'): 1,\n",
              "          ('humanlike', 'language', 'processing'): 1,\n",
              "          ('language', 'processing', 'range'): 1,\n",
              "          ('processing', 'range', 'task'): 1,\n",
              "          ('range', 'task', 'application'): 1,\n",
              "          ('task', 'application', '24,paper'): 1,\n",
              "          ('application', '24,paper', 'review'): 1,\n",
              "          ('24,paper', 'review', 'process'): 1,\n",
              "          ('review', 'process', 'involved'): 1,\n",
              "          ('process', 'involved', 'natural'): 1,\n",
              "          ('involved', 'natural', 'language'): 1,\n",
              "          ('processing', 'nlp', 'demonstrates'): 1,\n",
              "          ('nlp', 'demonstrates', 'various'): 1,\n",
              "          ('demonstrates', 'various', 'kind'): 1,\n",
              "          ('various', 'kind', 'choice'): 1,\n",
              "          ('kind', 'choice', 'need'): 1,\n",
              "          ('choice', 'need', 'taken'): 1,\n",
              "          ('need', 'taken', 'execution'): 1,\n",
              "          ('taken', 'execution', 'word'): 1,\n",
              "          ('execution', 'word', 'morphology'): 1,\n",
              "          ('word', 'morphology', 'syntactic'): 1,\n",
              "          ('morphology', 'syntactic', 'text'): 1,\n",
              "          ('syntactic', 'text', 'analysis'): 1,\n",
              "          ('text', 'analysis', 'text'): 1,\n",
              "          ('analysis', 'text', 'generation'): 1,\n",
              "          ('text', 'generation', 'component'): 1,\n",
              "          ('generation', 'component', 'compare'): 1,\n",
              "          ('component', 'compare', 'time'): 1,\n",
              "          ('compare', 'time', 'complexity'): 1,\n",
              "          ('time', 'complexity', 'traditional'): 1,\n",
              "          ('complexity', 'traditional', '25,article'): 1,\n",
              "          ('traditional', '25,article', 'focus'): 1,\n",
              "          ('25,article', 'focus', 'derivation'): 1,\n",
              "          ('focus', 'derivation', 'large'): 1,\n",
              "          ('derivation', 'large', 'lexicon'): 1,\n",
              "          ('large', 'lexicon', 'natural'): 1,\n",
              "          ('lexicon', 'natural', 'language'): 1,\n",
              "          ('language', 'processing', 'describe'): 1,\n",
              "          ('processing', 'describe', 'development'): 1,\n",
              "          ('describe', 'development', 'dictionary'): 1,\n",
              "          ('development', 'dictionary', 'support'): 1,\n",
              "          ('dictionary', 'support', 'environment'): 1,\n",
              "          ('support', 'environment', 'linking'): 1,\n",
              "          ('environment', 'linking', 'restructured'): 1,\n",
              "          ('linking', 'restructured', 'version'): 1,\n",
              "          ('restructured', 'version', 'longman'): 1,\n",
              "          ('version', 'longman', 'dictionary'): 1,\n",
              "          ('longman', 'dictionary', 'contemporary'): 1,\n",
              "          ('dictionary', 'contemporary', 'english'): 1,\n",
              "          ('contemporary', 'english', 'natural'): 1,\n",
              "          ('english', 'natural', 'language'): 1,\n",
              "          ('processing', 'system', 'process'): 1,\n",
              "          ('system', 'process', 'restruc'): 1,\n",
              "          ('process', 'restruc', '26,introduce'): 1,\n",
              "          ('restruc', '26,introduce', 'method'): 1,\n",
              "          ('26,introduce', 'method', 'analyzing'): 1,\n",
              "          ('method', 'analyzing', 'complexity'): 1,\n",
              "          ('analyzing', 'complexity', 'natural'): 1,\n",
              "          ('complexity', 'natural', 'language'): 1,\n",
              "          ('processing', 'task', 'predicting'): 1,\n",
              "          ('task', 'predicting', 'difficulty'): 1,\n",
              "          ('predicting', 'difficulty', 'new'): 1,\n",
              "          ('difficulty', 'new', 'nlp'): 1,\n",
              "          ('new', 'nlp', 'task'): 1,\n",
              "          ('nlp', 'task', 'complexity'): 1,\n",
              "          ('task', 'complexity', 'measure'): 1,\n",
              "          ('complexity', 'measure', 'derived'): 1,\n",
              "          ('measure', 'derived', 'kolmogorov'): 1,\n",
              "          ('derived', 'kolmogorov', 'complexity'): 1,\n",
              "          ('kolmogorov', 'complexity', 'class'): 1,\n",
              "          ('complexity', 'class', 'automaton'): 1,\n",
              "          ('class', 'automaton', 'meaning'): 1,\n",
              "          ('automaton', 'meaning', 'automaton'): 1,\n",
              "          ('meaning', 'automaton', 'whose'): 1,\n",
              "          ('automaton', 'whose', 'purpose'): 1,\n",
              "          ('whose', 'purpose', 'extract'): 1,\n",
              "          ('purpose', 'extract', 'relevant'): 1,\n",
              "          ('extract', 'relevant', 'piece'): 1,\n",
              "          ('relevant', 'piece', 'infor'): 1,\n",
              "          ('piece', 'infor', '27,deep'): 1,\n",
              "          ('infor', '27,deep', 'learning'): 1,\n",
              "          ('27,deep', 'learning', 'emerged'): 1,\n",
              "          ('learning', 'emerged', 'new'): 1,\n",
              "          ('emerged', 'new', 'area'): 1,\n",
              "          ('new', 'area', 'machine'): 1,\n",
              "          ('area', 'machine', 'learning'): 1,\n",
              "          ('machine', 'learning', 'research'): 1,\n",
              "          ('learning', 'research', 'try'): 1,\n",
              "          ('research', 'try', 'mimic'): 1,\n",
              "          ('try', 'mimic', 'human'): 1,\n",
              "          ('mimic', 'human', 'brain'): 1,\n",
              "          ('human', 'brain', 'capable'): 1,\n",
              "          ('brain', 'capable', 'processing'): 1,\n",
              "          ('capable', 'processing', 'learning'): 1,\n",
              "          ('processing', 'learning', 'complex'): 1,\n",
              "          ('learning', 'complex', 'input'): 1,\n",
              "          ('complex', 'input', 'data'): 1,\n",
              "          ('input', 'data', 'solving'): 1,\n",
              "          ('data', 'solving', 'different'): 1,\n",
              "          ('solving', 'different', 'kind'): 1,\n",
              "          ('different', 'kind', 'complicated'): 1,\n",
              "          ('kind', 'complicated', 'task'): 1,\n",
              "          ('complicated', 'task', 'well'): 1,\n",
              "          ('task', 'well', 'successfully'): 1,\n",
              "          ('well', 'successfully', 'applied'): 1,\n",
              "          ('successfully', 'applied', 'several'): 1,\n",
              "          ('applied', 'several', 'field'): 1,\n",
              "          ('several', 'field', 'image'): 1,\n",
              "          ('field', 'image', '28,authorproduced'): 1,\n",
              "          ('image', '28,authorproduced', 'version'): 1,\n",
              "          ('28,authorproduced', 'version', 'paper'): 1,\n",
              "          ('version', 'paper', 'published'): 1,\n",
              "          ('paper', 'published', '29,abstractnatural'): 1,\n",
              "          ('published', '29,abstractnatural', 'language'): 1,\n",
              "          ('29,abstractnatural', 'language', 'processing'): 1,\n",
              "          ('processing', 'nlp', 'application'): 1,\n",
              "          ('nlp', 'application', 'automated'): 1,\n",
              "          ('application', 'automated', 'parsing'): 1,\n",
              "          ('automated', 'parsing', 'machine'): 1,\n",
              "          ('parsing', 'machine', 'learning'): 1,\n",
              "          ('machine', 'learning', 'technique'): 2,\n",
              "          ('learning', 'technique', 'analyze'): 1,\n",
              "          ('technique', 'analyze', 'standard'): 1,\n",
              "          ('analyze', 'standard', 'text'): 1,\n",
              "          ('standard', 'text', 'application'): 1,\n",
              "          ('text', 'application', 'nlp'): 1,\n",
              "          ('application', 'nlp', 'requirement'): 1,\n",
              "          ('nlp', 'requirement', 'engineering'): 1,\n",
              "          ('requirement', 'engineering', 'include'): 1,\n",
              "          ('engineering', 'include', 'extraction'): 1,\n",
              "          ('include', 'extraction', 'ontology'): 1,\n",
              "          ('extraction', 'ontology', 'requirement'): 1,\n",
              "          ('ontology', 'requirement', 'specification'): 1,\n",
              "          ('requirement', 'specification', 'use'): 1,\n",
              "          ('specification', 'use', 'nlp'): 1,\n",
              "          ('use', 'nlp', 'verify'): 1,\n",
              "          ('nlp', 'verify', 'consistency'): 1,\n",
              "          ('verify', 'consistency', '30,information'): 1,\n",
              "          ('consistency', '30,information', 'retrieval'): 1,\n",
              "          ('30,information', 'retrieval', 'address'): 1,\n",
              "          ('retrieval', 'address', 'problem'): 1,\n",
              "          ('address', 'problem', 'finding'): 1,\n",
              "          ('problem', 'finding', 'document'): 1,\n",
              "          ('finding', 'document', 'whose'): 1,\n",
              "          ('document', 'whose', 'content'): 1,\n",
              "          ('whose', 'content', 'match'): 1,\n",
              "          ('content', 'match', 'useraposs'): 1,\n",
              "          ('match', 'useraposs', 'request'): 1,\n",
              "          ('useraposs', 'request', 'among'): 1,\n",
              "          ('request', 'among', 'large'): 1,\n",
              "          ('among', 'large', 'collection'): 1,\n",
              "          ('large', 'collection', 'document'): 1,\n",
              "          ('collection', 'document', 'currently'): 1,\n",
              "          ('document', 'currently', 'successful'): 1,\n",
              "          ('currently', 'successful', 'general'): 1,\n",
              "          ('successful', 'general', 'purpose'): 1,\n",
              "          ('general', 'purpose', 'retrieval'): 1,\n",
              "          ('purpose', 'retrieval', 'method'): 1,\n",
              "          ('retrieval', 'method', 'statistical'): 1,\n",
              "          ('method', 'statistical', 'method'): 1,\n",
              "          ('statistical', 'method', 'treat'): 1,\n",
              "          ('method', 'treat', 'text'): 1,\n",
              "          ('treat', 'text', 'little'): 1,\n",
              "          ('text', 'little', 'bag'): 1,\n",
              "          ('little', 'bag', 'w'): 1,\n",
              "          ('bag', 'w', '31,work'): 1,\n",
              "          ('w', '31,work', 'computational'): 1,\n",
              "          ('31,work', 'computational', 'linguistics'): 1,\n",
              "          ('computational', 'linguistics', 'began'): 1,\n",
              "          ('linguistics', 'began', 'soon'): 1,\n",
              "          ('began', 'soon', 'development'): 1,\n",
              "          ('soon', 'development', 'first'): 1,\n",
              "          ('development', 'first', 'computer'): 1,\n",
              "          ('first', 'computer', 'booth'): 1,\n",
              "          ('computer', 'booth', 'brandwood'): 1,\n",
              "          ('booth', 'brandwood', 'cleave'): 1,\n",
              "          ('brandwood', 'cleave', 'yet'): 1,\n",
              "          ('cleave', 'yet', 'intervening'): 1,\n",
              "          ('yet', 'intervening', 'four'): 1,\n",
              "          ('intervening', 'four', 'decade'): 1,\n",
              "          ('four', 'decade', 'pervasive'): 1,\n",
              "          ('decade', 'pervasive', 'feeling'): 1,\n",
              "          ('pervasive', 'feeling', 'progress'): 1,\n",
              "          ('feeling', 'progress', 'computer'): 1,\n",
              "          ('progress', 'computer', 'understanding'): 1,\n",
              "          ('computer', 'understanding', 'natural'): 1,\n",
              "          ('understanding', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'commensurate'): 1,\n",
              "          ('language', 'commensurate', 'progres'): 1,\n",
              "          ('commensurate', 'progres', '32,abstracta'): 1,\n",
              "          ('progres', '32,abstracta', 'system'): 1,\n",
              "          ('32,abstracta', 'system', 'recognizes'): 1,\n",
              "          ('system', 'recognizes', 'authenticates'): 1,\n",
              "          ('recognizes', 'authenticates', 'voice'): 1,\n",
              "          ('authenticates', 'voice', 'user'): 1,\n",
              "          ('voice', 'user', 'extracting'): 1,\n",
              "          ('user', 'extracting', 'distinct'): 1,\n",
              "          ('extracting', 'distinct', 'feature'): 1,\n",
              "          ('distinct', 'feature', 'voice'): 1,\n",
              "          ('feature', 'voice', 'sample'): 1,\n",
              "          ('voice', 'sample', 'usually'): 1,\n",
              "          ('sample', 'usually', 'termed'): 1,\n",
              "          ('usually', 'termed', 'voice'): 1,\n",
              "          ('termed', 'voice', 'recognition'): 1,\n",
              "          ('voice', 'recognition', 'system'): 1,\n",
              "          ('recognition', 'system', 'voice'): 1,\n",
              "          ('system', 'voice', 'identification'): 1,\n",
              "          ('voice', 'identification', 'carried'): 1,\n",
              "          ('identification', 'carried', 'converting'): 1,\n",
              "          ('carried', 'converting', 'human'): 1,\n",
              "          ('converting', 'human', 'voice'): 1,\n",
              "          ('human', 'voice', 'digital'): 1,\n",
              "          ('voice', 'digital', 'data'): 1,\n",
              "          ('digital', 'data', 'digitized'): 1,\n",
              "          ('data', 'digitized', 'audio'): 1,\n",
              "          ('digitized', 'audio', 'sample'): 1,\n",
              "          ('audio', 'sample', 'unde'): 1,\n",
              "          ('sample', 'unde', '33,abstract'): 1,\n",
              "          ('unde', '33,abstract', 'testing'): 1,\n",
              "          ('33,abstract', 'testing', 'natural'): 1,\n",
              "          ('testing', 'natural', 'language'): 1,\n",
              "          ('natural', 'language', 'requirement'): 1,\n",
              "          ('language', 'requirement', 'standard'): 1,\n",
              "          ('requirement', 'standard', 'approach'): 1,\n",
              "          ('standard', 'approach', 'system'): 1,\n",
              "          ('approach', 'system', 'acceptance'): 1,\n",
              "          ('system', 'acceptance', 'testing'): 1,\n",
              "          ('acceptance', 'testing', 'test'): 1,\n",
              "          ('testing', 'test', 'often'): 1,\n",
              "          ('test', 'often', 'performed'): 1,\n",
              "          ('often', 'performed', 'independent'): 1,\n",
              "          ('performed', 'independent', 'test'): 1,\n",
              "          ('independent', 'test', 'organization'): 1,\n",
              "          ('test', 'organization', 'unfamiliar'): 1,\n",
              "          ('organization', 'unfamiliar', 'application'): 1,\n",
              "          ('unfamiliar', 'application', 'area'): 1,\n",
              "          ('application', 'area', 'thing'): 1,\n",
              "          ('area', 'thing', 'tester'): 1,\n",
              "          ('thing', 'tester', 'go'): 1,\n",
              "          ('tester', 'go', 'written'): 1,\n",
              "          ('go', 'written', 'requirement'): 1,\n",
              "          ('written', 'requirement', '34,'): 1,\n",
              "          ('requirement', '34,', '35,algorithm'): 1,\n",
              "          ('34,', '35,algorithm', 'allow'): 1,\n",
              "          ('35,algorithm', 'allow', 'understanding'): 1,\n",
              "          ('allow', 'understanding', 'generation'): 1,\n",
              "          ('understanding', 'generation', 'humor'): 1,\n",
              "          ('generation', 'humor', 'general'): 1,\n",
              "          ('humor', 'general', 'aim'): 1,\n",
              "          ('general', 'aim', 'modeling'): 1,\n",
              "          ('aim', 'modeling', 'humor'): 1,\n",
              "          ('modeling', 'humor', 'provide'): 1,\n",
              "          ('humor', 'provide', 'u'): 1,\n",
              "          ('provide', 'u', 'lot'): 1,\n",
              "          ('u', 'lot', 'information'): 1,\n",
              "          ('lot', 'information', 'cognitive'): 1,\n",
              "          ('information', 'cognitive', 'ability'): 1,\n",
              "          ('cognitive', 'ability', 'general'): 1,\n",
              "          ('ability', 'general', 'reasoning'): 1,\n",
              "          ('general', 'reasoning', 'remembering'): 1,\n",
              "          ('reasoning', 'remembering', 'understanding'): 1,\n",
              "          ('remembering', 'understanding', 'situation'): 1,\n",
              "          ('understanding', 'situation', 'understanding'): 1,\n",
              "          ('situation', 'understanding', 'conversati'): 1,\n",
              "          ('understanding', 'conversati', '36,'): 1,\n",
              "          ('conversati', '36,', '37,recent'): 1,\n",
              "          ('36,', '37,recent', 'year'): 1,\n",
              "          ('37,recent', 'year', 'machine'): 1,\n",
              "          ('year', 'machine', 'learning'): 1,\n",
              "          ('machine', 'learning', 'ml'): 2,\n",
              "          ('learning', 'ml', 'used'): 1,\n",
              "          ('ml', 'used', 'solve'): 1,\n",
              "          ('used', 'solve', 'complex'): 1,\n",
              "          ('solve', 'complex', 'task'): 1,\n",
              "          ('complex', 'task', 'different'): 1,\n",
              "          ('task', 'different', 'discipline'): 1,\n",
              "          ('different', 'discipline', 'ranging'): 1,\n",
              "          ('discipline', 'ranging', 'data'): 1,\n",
              "          ('ranging', 'data', 'mining'): 1,\n",
              "          ('data', 'mining', 'information'): 1,\n",
              "          ('mining', 'information', '38,argue'): 1,\n",
              "          ('information', '38,argue', 'manual'): 1,\n",
              "          ('38,argue', 'manual', 'automatic'): 1,\n",
              "          ('manual', 'automatic', 'thesaurus'): 1,\n",
              "          ('automatic', 'thesaurus', 'alternative'): 1,\n",
              "          ('thesaurus', 'alternative', 'resource'): 1,\n",
              "          ('alternative', 'resource', 'nlp'): 1,\n",
              "          ('resource', 'nlp', 'task'): 1,\n",
              "          ('nlp', 'task', 'involves'): 1,\n",
              "          ('task', 'involves', 'radical'): 1,\n",
              "          ('involves', 'radical', 'step'): 1,\n",
              "          ('radical', 'step', 'interpreting'): 1,\n",
              "          ('step', 'interpreting', 'manual'): 1,\n",
              "          ('interpreting', 'manual', 'thesaurus'): 1,\n",
              "          ('manual', 'thesaurus', 'classification'): 1,\n",
              "          ('thesaurus', 'classification', 'word'): 1,\n",
              "          ('classification', 'word', 'rather'): 1,\n",
              "          ('word', 'rather', 'word'): 1,\n",
              "          ('rather', 'word', 'sens'): 1,\n",
              "          ('word', 'sens', 'case'): 1,\n",
              "          ('sens', 'case', 'made'): 1,\n",
              "          ('case', 'made', 'range'): 1,\n",
              "          ('made', 'range', 'role'): 1,\n",
              "          ('range', 'role', 'thesaurus'): 1,\n",
              "          ('role', 'thesaurus', 'within'): 1,\n",
              "          ('thesaurus', 'within', 'nlp'): 1,\n",
              "          ('within', 'nlp', 'briefly'): 1,\n",
              "          ('nlp', 'briefly', '39,introduction'): 1,\n",
              "          ('briefly', '39,introduction', 'pattern'): 1,\n",
              "          ('39,introduction', 'pattern', 'music'): 1,\n",
              "          ('pattern', 'music', 'object'): 1,\n",
              "          ('music', 'object', 'intensive'): 1,\n",
              "          ('object', 'intensive', 'study'): 1,\n",
              "          ('intensive', 'study', 'past'): 1,\n",
              "          ('study', 'past', 'year'): 1,\n",
              "          ('past', 'year', 'one'): 1,\n",
              "          ('year', 'one', 'purpose'): 1,\n",
              "          ('one', 'purpose', 'analyzing'): 1,\n",
              "          ('purpose', 'analyzing', 'musical'): 1,\n",
              "          ('analyzing', 'musical', 'structure'): 1,\n",
              "          ('musical', 'structure', 'form'): 1,\n",
              "          ('structure', 'form', 'discover'): 1,\n",
              "          ('form', 'discover', 'pattern'): 1,\n",
              "          ('discover', 'pattern', 'explicit'): 1,\n",
              "          ('pattern', 'explicit', 'implicit'): 1,\n",
              "          ('explicit', 'implicit', 'musical'): 1,\n",
              "          ('implicit', 'musical', 'work'): 1,\n",
              "          ('musical', 'work', 'simon'): 1,\n",
              "          ('work', 'simon', 'pattern'): 1,\n",
              "          ('simon', 'pattern', 'comprise'): 1,\n",
              "          ('pattern', 'comprise', 'periodicity'): 1,\n",
              "          ('comprise', 'periodicity', 'make'): 1,\n",
              "          ('periodicity', 'make', 'use'): 1,\n",
              "          ('make', 'use', 'alphabet'): 1,\n",
              "          ('use', 'alphabet', '40,abstract'): 1,\n",
              "          ('alphabet', '40,abstract', 'many'): 1,\n",
              "          ('40,abstract', 'many', 'information'): 1,\n",
              "          ('many', 'information', 'retrievalir'): 1,\n",
              "          ('information', 'retrievalir', 'system'): 1,\n",
              "          ('retrievalir', 'system', 'retrieve'): 1,\n",
              "          ('system', 'retrieve', 'relevant'): 1,\n",
              "          ('retrieve', 'relevant', 'document'): 1,\n",
              "          ('relevant', 'document', 'based'): 1,\n",
              "          ('document', 'based', 'exact'): 1,\n",
              "          ('based', 'exact', 'matching'): 1,\n",
              "          ('exact', 'matching', 'keywords'): 1,\n",
              "          ('matching', 'keywords', 'query'): 1,\n",
              "          ('keywords', 'query', 'document'): 1,\n",
              "          ('query', 'document', 'method'): 1,\n",
              "          ('document', 'method', 'degrades'): 1,\n",
              "          ('method', 'degrades', 'precision'): 1,\n",
              "          ('degrades', 'precision', 'rate'): 1,\n",
              "          ('precision', 'rate', 'order'): 1,\n",
              "          ('rate', 'order', 'solve'): 1,\n",
              "          ('order', 'solve', 'problem'): 1,\n",
              "          ('solve', 'problem', 'collected'): 1,\n",
              "          ('problem', 'collected', 'semantically'): 1,\n",
              "          ('collected', 'semantically', 'related'): 1,\n",
              "          ('semantically', 'related', 'word'): 1,\n",
              "          ('related', 'word', 'assigned'): 1,\n",
              "          ('word', 'assigned', 'semantic'): 1,\n",
              "          ('assigned', 'semantic', 'relationship'): 1,\n",
              "          ('semantic', 'relationship', 'used'): 1,\n",
              "          ('relationship', 'used', 'gener'): 1,\n",
              "          ('used', 'gener', '41,paper'): 1,\n",
              "          ('gener', '41,paper', 'argue'): 1,\n",
              "          ('41,paper', 'argue', 'questionanswering'): 1,\n",
              "          ('argue', 'questionanswering', 'qa'): 1,\n",
              "          ('questionanswering', 'qa', 'technical'): 1,\n",
              "          ('qa', 'technical', 'domain'): 1,\n",
              "          ('technical', 'domain', 'distinctly'): 1,\n",
              "          ('domain', 'distinctly', 'different'): 1,\n",
              "          ('distinctly', 'different', 'trecbased'): 1,\n",
              "          ('different', 'trecbased', 'qa'): 1,\n",
              "          ('trecbased', 'qa', 'webbased'): 1,\n",
              "          ('qa', 'webbased', 'qa'): 1,\n",
              "          ('webbased', 'qa', 'cannot'): 1,\n",
              "          ('qa', 'cannot', 'benefit'): 1,\n",
              "          ('cannot', 'benefit', 'lom'): 1,\n",
              "          ('benefit', 'lom', 'dataintensive'): 1,\n",
              "          ('lom', 'dataintensive', 'approach'): 1,\n",
              "          ('dataintensive', 'approach', '42,universitquotat'): 1,\n",
              "          ('approach', '42,universitquotat', 'de'): 1,\n",
              "          ('42,universitquotat', 'de', 'saarlandes'): 1,\n",
              "          ('de', 'saarlandes', '43,proceeding'): 1,\n",
              "          ('saarlandes', '43,proceeding', 'workshop'): 1,\n",
              "          ('43,proceeding', 'workshop', '44,unihamburgde'): 1,\n",
              "          ('workshop', '44,unihamburgde', '45,'): 1,\n",
              "          ('44,unihamburgde', '45,', '46,'): 1,\n",
              "          ('45,', '46,', '47,sri'): 1,\n",
              "          ('46,', '47,sri', 'developed'): 1,\n",
              "          ('47,sri', 'developed', 'new'): 1,\n",
              "          ('developed', 'new', 'architecture'): 1,\n",
              "          ('new', 'architecture', 'integrating'): 1,\n",
              "          ('architecture', 'integrating', 'speech'): 1,\n",
              "          ('integrating', 'speech', 'naturallanguage'): 1,\n",
              "          ('speech', 'naturallanguage', 'processing'): 1,\n",
              "          ('naturallanguage', 'processing', 'applies'): 1,\n",
              "          ('processing', 'applies', 'linguistic'): 1,\n",
              "          ('applies', 'linguistic', 'constraint'): 1,\n",
              "          ('linguistic', 'constraint', 'recognition'): 1,\n",
              "          ('constraint', 'recognition', 'incrementally'): 1,\n",
              "          ('recognition', 'incrementally', 'expanding'): 1,\n",
              "          ('incrementally', 'expanding', 'statetransition'): 1,\n",
              "          ('expanding', 'statetransition', 'network'): 1,\n",
              "          ('statetransition', 'network', 'embodied'): 1,\n",
              "          ('network', 'embodied', 'unification'): 1,\n",
              "          ('embodied', 'unification', 'grammar'): 1,\n",
              "          ('unification', 'grammar', 'compare'): 1,\n",
              "          ('grammar', 'compare', 'dynamicgralnlnarnetwork'): 1,\n",
              "          ('compare', 'dynamicgralnlnarnetwork', 'dgn'): 1,\n",
              "          ('dynamicgralnlnarnetwork', 'dgn', 'approach'): 1,\n",
              "          ('dgn', 'approach', '48,chapter'): 1,\n",
              "          ('approach', '48,chapter', 'considers'): 1,\n",
              "          ...})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTYvQUIXVrMc",
        "outputId": "6791c227-3722-443f-9c3c-ffb1c1e2668d"
      },
      "source": [
        "#bigrams\r\n",
        "from nltk.util import ngrams\r\n",
        "d = open('abst2.csv', \"r\")\r\n",
        "bi_grams = ngrams(d.read().split(), 2)\r\n",
        "b_freqdist=nltk.FreqDist(bi_grams)         #count\r\n",
        "display(b_freqdist)\r\n",
        "\r\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FreqDist({(',cleansentence', '0,'): 1,\n",
              "          ('0,', '1,concept'): 1,\n",
              "          ('1,concept', 'maximum'): 1,\n",
              "          ('maximum', 'entropy'): 1,\n",
              "          ('entropy', 'traced'): 1,\n",
              "          ('traced', 'back'): 1,\n",
              "          ('back', 'along'): 1,\n",
              "          ('along', 'multiple'): 1,\n",
              "          ('multiple', 'thread'): 1,\n",
              "          ('thread', 'biblical'): 1,\n",
              "          ('biblical', 'time'): 1,\n",
              "          ('time', 'recently'): 1,\n",
              "          ('recently', 'however'): 1,\n",
              "          ('however', 'computer'): 1,\n",
              "          ('computer', 'become'): 1,\n",
              "          ('become', 'powerful'): 1,\n",
              "          ('powerful', 'enough'): 1,\n",
              "          ('enough', 'permit'): 1,\n",
              "          ('permit', 'widescale'): 1,\n",
              "          ('widescale', 'application'): 1,\n",
              "          ('application', 'concept'): 1,\n",
              "          ('concept', 'real'): 1,\n",
              "          ('real', 'world'): 1,\n",
              "          ('world', 'problem'): 1,\n",
              "          ('problem', 'statistical'): 1,\n",
              "          ('statistical', 'estimation'): 1,\n",
              "          ('estimation', 'pattern'): 1,\n",
              "          ('pattern', 'recognition'): 1,\n",
              "          ('recognition', 'paper'): 1,\n",
              "          ('paper', 'de'): 1,\n",
              "          ('de', '2,scaling'): 1,\n",
              "          ('2,scaling', 'conditional'): 1,\n",
              "          ('conditional', 'random'): 1,\n",
              "          ('random', 'field'): 1,\n",
              "          ('field', 'natural'): 2,\n",
              "          ('natural', 'language'): 66,\n",
              "          ('language', 'processing'): 61,\n",
              "          ('processing', 'term'): 1,\n",
              "          ('term', 'condition'): 2,\n",
              "          ('condition', 'term'): 1,\n",
              "          ('condition', 'copyright'): 1,\n",
              "          ('copyright', 'work'): 1,\n",
              "          ('work', 'deposited'): 1,\n",
              "          ('deposited', 'minerva'): 1,\n",
              "          ('minerva', 'access'): 1,\n",
              "          ('access', 'retained'): 1,\n",
              "          ('retained', '3,paper'): 1,\n",
              "          ('3,paper', 'address'): 1,\n",
              "          ('address', 'issue'): 1,\n",
              "          ('issue', 'cooperation'): 1,\n",
              "          ('cooperation', 'linguistics'): 1,\n",
              "          ('linguistics', 'natural'): 1,\n",
              "          ('processing', 'nlp'): 16,\n",
              "          ('nlp', 'general'): 1,\n",
              "          ('general', 'linguistics'): 1,\n",
              "          ('linguistics', 'machine'): 1,\n",
              "          ('machine', 'translation'): 3,\n",
              "          ('translation', 'mt'): 1,\n",
              "          ('mt', 'particular'): 1,\n",
              "          ('particular', 'focus'): 1,\n",
              "          ('focus', 'one'): 1,\n",
              "          ('one', 'direction'): 1,\n",
              "          ('direction', 'cooperation'): 1,\n",
              "          ('cooperation', 'namely'): 1,\n",
              "          ('namely', 'application'): 1,\n",
              "          ('application', 'linguistics'): 1,\n",
              "          ('linguistics', 'nlp'): 1,\n",
              "          ('nlp', 'virtually'): 1,\n",
              "          ('virtually', 'ignoring'): 1,\n",
              "          ('ignoring', '4,natural'): 1,\n",
              "          ('4,natural', 'language'): 1,\n",
              "          ('processing', 'application'): 2,\n",
              "          ('application', 'description'): 1,\n",
              "          ('description', 'logic'): 4,\n",
              "          ('logic', 'used'): 1,\n",
              "          ('used', 'encode'): 1,\n",
              "          ('encode', 'knowledge'): 1,\n",
              "          ('knowledge', 'base'): 3,\n",
              "          ('base', 'syntactic'): 1,\n",
              "          ('syntactic', 'semantic'): 2,\n",
              "          ('semantic', 'pragmatic'): 1,\n",
              "          ('pragmatic', 'element'): 1,\n",
              "          ('element', 'needed'): 1,\n",
              "          ('needed', 'drive'): 1,\n",
              "          ('drive', 'semantic'): 1,\n",
              "          ('semantic', 'interpretation'): 2,\n",
              "          ('interpretation', 'natural'): 1,\n",
              "          ('language', 'generation'): 1,\n",
              "          ('generation', 'process'): 1,\n",
              "          ('process', 'recently'): 1,\n",
              "          ('recently', 'description'): 1,\n",
              "          ('logic', 'u'): 1,\n",
              "          ('u', '5,propose'): 1,\n",
              "          ('5,propose', 'unified'): 1,\n",
              "          ('unified', 'neural'): 1,\n",
              "          ('neural', 'network'): 4,\n",
              "          ('network', 'architecture'): 2,\n",
              "          ('architecture', 'learning'): 1,\n",
              "          ('learning', 'algorithm'): 1,\n",
              "          ('algorithm', 'applied'): 1,\n",
              "          ('applied', 'various'): 1,\n",
              "          ('various', 'natural'): 1,\n",
              "          ('processing', 'task'): 2,\n",
              "          ('task', 'including'): 1,\n",
              "          ('including', 'partofspeech'): 1,\n",
              "          ('partofspeech', 'tagging'): 1,\n",
              "          ('tagging', 'chunking'): 1,\n",
              "          ('chunking', 'named'): 1,\n",
              "          ('named', 'entity'): 2,\n",
              "          ('entity', 'recognition'): 1,\n",
              "          ('recognition', 'semantic'): 1,\n",
              "          ('semantic', 'role'): 2,\n",
              "          ('role', 'labeling'): 1,\n",
              "          ('labeling', 'versatility'): 1,\n",
              "          ('versatility', 'achieved'): 1,\n",
              "          ('achieved', 'trying'): 1,\n",
              "          ('trying', 'avoid'): 1,\n",
              "          ('avoid', 'taskspecific'): 1,\n",
              "          ('taskspecific', 'eng'): 1,\n",
              "          ('eng', '6,natural'): 1,\n",
              "          ('6,natural', 'language'): 1,\n",
              "          ('processing', 'subject'): 1,\n",
              "          ('subject', 'natural'): 1,\n",
              "          ('processing', 'considered'): 1,\n",
              "          ('considered', 'broad'): 1,\n",
              "          ('broad', 'narrow'): 1,\n",
              "          ('narrow', 'sens'): 1,\n",
              "          ('sens', 'broad'): 1,\n",
              "          ('broad', 'sense'): 1,\n",
              "          ('sense', 'cover'): 1,\n",
              "          ('cover', 'processing'): 1,\n",
              "          ('processing', 'issue'): 1,\n",
              "          ('issue', 'level'): 1,\n",
              "          ('level', 'natural'): 1,\n",
              "          ('language', 'understanding'): 1,\n",
              "          ('understanding', 'including'): 1,\n",
              "          ('including', 'speech'): 1,\n",
              "          ('speech', 'recognition'): 4,\n",
              "          ('recognition', 'syntactic'): 1,\n",
              "          ('semantic', 'analysis'): 1,\n",
              "          ('analysis', 'sentence'): 1,\n",
              "          ('sentence', 'refer'): 1,\n",
              "          ('refer', '7,robot'): 1,\n",
              "          ('7,robot', 'interact'): 1,\n",
              "          ('interact', 'human'): 1,\n",
              "          ('human', 'facetoface'): 1,\n",
              "          ('facetoface', 'using'): 1,\n",
              "          ('using', 'natural'): 2,\n",
              "          ('language', 'need'): 2,\n",
              "          ('need', 'responsive'): 1,\n",
              "          ('responsive', 'way'): 1,\n",
              "          ('way', 'human'): 1,\n",
              "          ('human', 'use'): 1,\n",
              "          ('use', 'language'): 1,\n",
              "          ('language', 'situation'): 1,\n",
              "          ('situation', 'propose'): 1,\n",
              "          ('propose', 'psychologicallyinspired'): 1,\n",
              "          ('psychologicallyinspired', 'natural'): 1,\n",
              "          ('processing', 'system'): 6,\n",
              "          ('system', 'robot'): 1,\n",
              "          ('robot', 'performs'): 1,\n",
              "          ('performs', 'incremental'): 1,\n",
              "          ('incremental', 'semantic'): 1,\n",
              "          ('interpretation', 'spoken'): 1,\n",
              "          ('spoken', 'utterance'): 1,\n",
              "          ('utterance', '8,natural'): 1,\n",
              "          ('8,natural', 'language'): 1,\n",
              "          ('language', 'language'): 3,\n",
              "          ('language', 'spoken'): 2,\n",
              "          ('spoken', 'human'): 1,\n",
              "          ('human', 'currently'): 1,\n",
              "          ('currently', 'yet'): 1,\n",
              "          ('yet', 'point'): 1,\n",
              "          ('point', 'language'): 1,\n",
              "          ('language', 'unprocessed'): 1,\n",
              "          ('unprocessed', 'form'): 1,\n",
              "          ('form', 'understood'): 1,\n",
              "          ('understood', 'computer'): 1,\n",
              "          ('computer', 'natural'): 1,\n",
              "          ('processing', 'collection'): 1,\n",
              "          ('collection', 'technique'): 1,\n",
              "          ('technique', 'employed'): 1,\n",
              "          ('employed', 'try'): 1,\n",
              "          ('try', 'accomplish'): 1,\n",
              "          ('accomplish', 'goal'): 1,\n",
              "          ('goal', 'field'): 1,\n",
              "          ('natural', 'l'): 1,\n",
              "          ('l', '9,abstract'): 1,\n",
              "          ('9,abstract', 'ambiguity'): 1,\n",
              "          ('ambiguity', 'referred'): 1,\n",
              "          ('referred', 'ability'): 1,\n",
              "          ('ability', 'one'): 1,\n",
              "          ('one', 'meaning'): 1,\n",
              "          ('meaning', 'understood'): 1,\n",
              "          ('understood', 'one'): 1,\n",
              "          ('one', 'way'): 1,\n",
              "          ('way', 'natural'): 1,\n",
              "          ('language', 'ambiguous'): 1,\n",
              "          ('ambiguous', 'computer'): 1,\n",
              "          ('computer', 'able'): 1,\n",
              "          ('able', 'understand'): 1,\n",
              "          ('understand', 'language'): 1,\n",
              "          ('language', 'way'): 2,\n",
              "          ('way', 'people'): 1,\n",
              "          ('people', 'natural'): 1,\n",
              "          ('nlp', 'concerned'): 2,\n",
              "          ('concerned', 'development'): 1,\n",
              "          ('development', 'co'): 1,\n",
              "          ('co', '10,introduction'): 1,\n",
              "          ('10,introduction', 'statistical'): 1,\n",
              "          ('statistical', 'natural'): 1,\n",
              "          ('processing', 'snlp'): 1,\n",
              "          ('snlp', 'field'): 1,\n",
              "          ('field', 'lying'): 1,\n",
              "          ('lying', 'intersection'): 1,\n",
              "          ('intersection', 'natural'): 1,\n",
              "          ('processing', 'machine'): 1,\n",
              "          ('machine', 'learning'): 10,\n",
              "          ('learning', 'snlp'): 1,\n",
              "          ('snlp', 'diers'): 1,\n",
              "          ('diers', 'traditional'): 1,\n",
              "          ('traditional', 'natural'): 1,\n",
              "          ('processing', 'instead'): 1,\n",
              "          ('instead', 'linguist'): 1,\n",
              "          ('linguist', 'manually'): 1,\n",
              "          ('manually', 'construct'): 1,\n",
              "          ('construct', 'model'): 1,\n",
              "          ('model', 'given'): 1,\n",
              "          ('given', 'linguistic'): 1,\n",
              "          ('linguistic', '11,paper'): 1,\n",
              "          ('11,paper', 'summarizes'): 1,\n",
              "          ('summarizes', 'essential'): 1,\n",
              "          ('essential', 'property'): 1,\n",
              "          ('property', 'document'): 1,\n",
              "          ('document', 'retrieval'): 2,\n",
              "          ('retrieval', 'review'): 1,\n",
              "          ('review', 'conventional'): 1,\n",
              "          ('conventional', 'practice'): 1,\n",
              "          ('practice', 'research'): 1,\n",
              "          ('research', 'finding'): 1,\n",
              "          ('finding', 'latter'): 1,\n",
              "          ('latter', 'suggesting'): 1,\n",
              "          ('suggesting', 'simple'): 1,\n",
              "          ('simple', 'statistical'): 1,\n",
              "          ('statistical', 'technique'): 1,\n",
              "          ('technique', 'effective'): 1,\n",
              "          ('effective', 'considers'): 1,\n",
              "          ('considers', 'new'): 1,\n",
              "          ('new', 'opportunity'): 1,\n",
              "          ('opportunity', 'challenge'): 1,\n",
              "          ('challenge', 'presented'): 1,\n",
              "          ('presented', 'ability'): 1,\n",
              "          ('ability', 'search'): 1,\n",
              "          ('search', 'full'): 1,\n",
              "          ('full', '12,abstract'): 1,\n",
              "          ('12,abstract', 'language'): 1,\n",
              "          ('way', 'communicating'): 1,\n",
              "          ('communicating', 'word'): 1,\n",
              "          ('word', 'language'): 1,\n",
              "          ('language', 'help'): 2,\n",
              "          ('help', 'understanding'): 1,\n",
              "          ('understanding', 'worldwe'): 1,\n",
              "          ('worldwe', 'get'): 1,\n",
              "          ('get', 'better'): 1,\n",
              "          ('better', 'insight'): 1,\n",
              "          ('insight', 'world'): 1,\n",
              "          ('world', 'language'): 1,\n",
              "          ('help', 'speaker'): 1,\n",
              "          ('speaker', 'vague'): 1,\n",
              "          ('vague', 'precise'): 1,\n",
              "          ('precise', 'like'): 1,\n",
              "          ('like', 'nlp'): 1,\n",
              "          ('nlp', 'stand'): 1,\n",
              "          ('stand', 'natural'): 1,\n",
              "          ('processing', 'natural'): 1,\n",
              "          ('spoken', '13,report'): 1,\n",
              "          ('13,report', 'experiment'): 1,\n",
              "          ('experiment', 'use'): 1,\n",
              "          ('use', 'standard'): 1,\n",
              "          ('standard', 'natural'): 1,\n",
              "          ('nlp', 'tool'): 1,\n",
              "          ('tool', 'analysis'): 1,\n",
              "          ('analysis', 'music'): 1,\n",
              "          ('music', 'lyric'): 1,\n",
              "          ('lyric', 'significant'): 1,\n",
              "          ('significant', 'amount'): 1,\n",
              "          ('amount', 'music'): 1,\n",
              "          ('music', 'audio'): 1,\n",
              "          ('audio', 'lyric'): 1,\n",
              "          ('lyric', 'lyric'): 1,\n",
              "          ('lyric', 'encode'): 1,\n",
              "          ('encode', 'important'): 1,\n",
              "          ('important', 'part'): 1,\n",
              "          ('part', 'semantics'): 1,\n",
              "          ('semantics', 'song'): 1,\n",
              "          ('song', 'therefore'): 1,\n",
              "          ('therefore', 'analysis'): 1,\n",
              "          ('analysis', 'complement'): 1,\n",
              "          ('complement', 'acoustic'): 1,\n",
              "          ('acoustic', 'cultural'): 1,\n",
              "          ('cultural', 'metada'): 1,\n",
              "          ('metada', '14,paper'): 1,\n",
              "          ('14,paper', 'describe'): 1,\n",
              "          ('describe', 'simple'): 1,\n",
              "          ('simple', 'rulebased'): 1,\n",
              "          ('rulebased', 'approach'): 1,\n",
              "          ('approach', 'automated'): 1,\n",
              "          ('automated', 'learning'): 1,\n",
              "          ('learning', 'linguistic'): 1,\n",
              "          ('linguistic', 'knowledge'): 2,\n",
              "          ('knowledge', 'approach'): 1,\n",
              "          ('approach', 'shown'): 1,\n",
              "          ('shown', 'number'): 1,\n",
              "          ('number', 'task'): 2,\n",
              "          ('task', 'capture'): 1,\n",
              "          ('capture', 'information'): 1,\n",
              "          ('information', 'clearer'): 1,\n",
              "          ('clearer', 'direct'): 1,\n",
              "          ('direct', 'fashion'): 1,\n",
              "          ('fashion', 'without'): 1,\n",
              "          ('without', 'compromise'): 1,\n",
              "          ('compromise', 'performance'): 1,\n",
              "          ('performance', 'present'): 1,\n",
              "          ('present', 'detailed'): 2,\n",
              "          ('detailed', 'case'): 1,\n",
              "          ('case', 'study'): 1,\n",
              "          ('study', 'learni'): 1,\n",
              "          ('learni', '15,paper'): 1,\n",
              "          ('15,paper', 'focus'): 1,\n",
              "          ('focus', 'connectionist'): 1,\n",
              "          ('connectionist', 'model'): 1,\n",
              "          ('model', 'natural'): 1,\n",
              "          ('processing', 'briefly'): 1,\n",
              "          ('briefly', 'present'): 1,\n",
              "          ('present', 'discus'): 1,\n",
              "          ('discus', 'several'): 2,\n",
              "          ('several', 'aspect'): 1,\n",
              "          ('aspect', 'high'): 1,\n",
              "          ('high', 'level'): 1,\n",
              "          ('level', 'task'): 1,\n",
              "          ('task', 'recently'): 1,\n",
              "          ('recently', 'approached'): 1,\n",
              "          ('approached', 'connectionism'): 1,\n",
              "          ('connectionism', 'either'): 1,\n",
              "          ('either', 'localist'): 1,\n",
              "          ('localist', 'parallel'): 1,\n",
              "          ('parallel', 'distributed'): 1,\n",
              "          ('distributed', 'processing'): 1,\n",
              "          ('processing', 'model'): 1,\n",
              "          ('model', 'several'): 1,\n",
              "          ('several', 'interesting'): 1,\n",
              "          ('interesting', 'architecture'): 1,\n",
              "          ('architecture', '16,abstract'): 1,\n",
              "          ('16,abstract', 'article'): 1,\n",
              "          ('article', 'explores'): 1,\n",
              "          ('explores', 'possibility'): 1,\n",
              "          ('possibility', 'construct'): 1,\n",
              "          ('construct', 'unified'): 1,\n",
              "          ('unified', 'word'): 1,\n",
              "          ('word', 'feature'): 2,\n",
              "          ('feature', 'component'): 1,\n",
              "          ('component', 'feature'): 1,\n",
              "          ('feature', 'letter'): 1,\n",
              "          ('letter', 'letter'): 1,\n",
              "          ('letter', 'modeled'): 1,\n",
              "          ('modeled', 'different'): 1,\n",
              "          ('different', 'attractor'): 1,\n",
              "          ('attractor', 'finally'): 1,\n",
              "          ('finally', 'embedded'): 1,\n",
              "          ('embedded', 'quadratic'): 1,\n",
              "          ('quadratic', 'iterated'): 1,\n",
              "          ('iterated', 'map'): 1,\n",
              "          ('map', 'result'): 1,\n",
              "          ('result', 'word'): 1,\n",
              "          ('feature', 'account'): 1,\n",
              "          ('account', 'meaning'): 1,\n",
              "          ('meaning', 'extraction'): 1,\n",
              "          ('extraction', 'pr'): 1,\n",
              "          ('pr', '17,paper'): 1,\n",
              "          ('17,paper', 'see'): 1,\n",
              "          ('see', 'schank'): 1,\n",
              "          ('schank', 'theoretical'): 1,\n",
              "          ('theoretical', 'discussion'): 1,\n",
              "          ('discussion', 'ka'): 1,\n",
              "          ('ka', 'leake'): 1,\n",
              "          ('leake', 'owen'): 1,\n",
              "          ('owen', 'brief'): 1,\n",
              "          ('brief', 'discussion'): 1,\n",
              "          ('discussion', 'program'): 1,\n",
              "          ('program', 'built'): 1,\n",
              "          ('built', 'around'): 1,\n",
              "          ('around', 'principle'): 1,\n",
              "          ('principle', 'goal'): 1,\n",
              "          ('goal', 'simply'): 1,\n",
              "          ('simply', 'point'): 1,\n",
              "          ('point', 'interest'): 1,\n",
              "          ('interest', 'natural'): 1,\n",
              "          ('processing', 'led'): 1,\n",
              "          ('led', 'u'): 1,\n",
              "          ('u', 'naturally'): 1,\n",
              "          ('naturally', 'indeed'): 1,\n",
              "          ('indeed', 'inevitably'): 1,\n",
              "          ('inevitably', 'de'): 1,\n",
              "          ('de', '18,objective'): 1,\n",
              "          ('18,objective', 'provide'): 1,\n",
              "          ('provide', 'overview'): 1,\n",
              "          ('overview', 'tutorial'): 1,\n",
              "          ('tutorial', 'natural'): 1,\n",
              "          ('nlp', 'modern'): 1,\n",
              "          ('modern', 'nlpsystem'): 1,\n",
              "          ('nlpsystem', 'design'): 1,\n",
              "          ('design', 'target'): 1,\n",
              "          ('target', 'audience'): 1,\n",
              "          ('audience', 'tutorial'): 1,\n",
              "          ('tutorial', 'target'): 1,\n",
              "          ('target', 'medical'): 1,\n",
              "          ('medical', 'informatics'): 1,\n",
              "          ('informatics', 'generalist'): 1,\n",
              "          ('generalist', 'limited'): 1,\n",
              "          ('limited', 'acquaintance'): 1,\n",
              "          ('acquaintance', 'principle'): 1,\n",
              "          ('principle', 'behind'): 1,\n",
              "          ('behind', 'nlp'): 1,\n",
              "          ('nlp', 'andor'): 1,\n",
              "          ('andor', 'limited'): 1,\n",
              "          ('limited', 'knowledge'): 1,\n",
              "          ('knowledge', 'current'): 1,\n",
              "          ('current', 'state'): 2,\n",
              "          ('state', '19,paper'): 1,\n",
              "          ('19,paper', 'briefly'): 1,\n",
              "          ('briefly', 'describes'): 1,\n",
              "          ('describes', 'current'): 1,\n",
              "          ('current', 'implementation'): 1,\n",
              "          ('implementation', 'status'): 1,\n",
              "          ('status', 'intelligent'): 1,\n",
              "          ('intelligent', 'information'): 1,\n",
              "          ('information', 'retrieval'): 6,\n",
              "          ('retrieval', 'system'): 2,\n",
              "          ('system', 'marie'): 1,\n",
              "          ('marie', 'employ'): 1,\n",
              "          ('employ', 'natural'): 1,\n",
              "          ('processing', 'technique'): 2,\n",
              "          ('technique', 'descriptive'): 1,\n",
              "          ('descriptive', 'caption'): 1,\n",
              "          ('caption', 'used'): 1,\n",
              "          ('used', 'iden'): 1,\n",
              "          ('iden', 'tify'): 1,\n",
              "          ('tify', 'photographic'): 1,\n",
              "          ('photographic', 'image'): 1,\n",
              "          ('image', 'concerning'): 1,\n",
              "          ('concerning', 'various'): 1,\n",
              "          ('various', 'military'): 1,\n",
              "          ('military', 'project'): 1,\n",
              "          ('project', 'caption'): 1,\n",
              "          ('caption', 'parsed'): 1,\n",
              "          ('parsed', '20,abstract'): 1,\n",
              "          ('20,abstract', 'metabolism'): 1,\n",
              "          ('metabolism', 'machinery'): 1,\n",
              "          ('machinery', 'life'): 1,\n",
              "          ('life', 'signal'): 1,\n",
              "          ('signal', 'transduction'): 2,\n",
              "          ('transduction', 'provides'): 1,\n",
              "          ('provides', 'regulatory'): 1,\n",
              "          ('regulatory', 'mechanism'): 1,\n",
              "          ('mechanism', 'control'): 1,\n",
              "          ('control', 'machinery'): 1,\n",
              "          ('machinery', 'due'): 1,\n",
              "          ('due', 'complexity'): 1,\n",
              "          ('complexity', 'signal'): 1,\n",
              "          ('transduction', 'pathway'): 1,\n",
              "          ('pathway', 'computational'): 1,\n",
              "          ('computational', 'approach'): 1,\n",
              "          ('approach', 'needed'): 1,\n",
              "          ('needed', 'aid'): 1,\n",
              "          ('aid', 'biologist'): 1,\n",
              "          ('biologist', 'integrating'): 1,\n",
              "          ('integrating', 'available'): 1,\n",
              "          ('available', 'knowledge'): 1,\n",
              "          ('knowledge', 'formulatio'): 1,\n",
              "          ('formulatio', '21,report'): 1,\n",
              "          ('21,report', 'present'): 1,\n",
              "          ('detailed', 'analysis'): 1,\n",
              "          ('analysis', 'review'): 1,\n",
              "          ('review', 'nlp'): 1,\n",
              "          ('nlp', 'evaluation'): 1,\n",
              "          ('evaluation', 'principle'): 1,\n",
              "          ('principle', 'practice'): 1,\n",
              "          ('practice', 'part'): 1,\n",
              "          ('part', 'examines'): 1,\n",
              "          ('examines', 'evaluation'): 1,\n",
              "          ('evaluation', 'concept'): 1,\n",
              "          ('concept', 'establishes'): 1,\n",
              "          ('establishes', 'framework'): 1,\n",
              "          ('framework', 'nlp'): 1,\n",
              "          ('nlp', 'system'): 3,\n",
              "          ('system', 'evaluation'): 1,\n",
              "          ('evaluation', 'make'): 1,\n",
              "          ('make', 'use'): 3,\n",
              "          ('use', 'experience'): 1,\n",
              "          ('experience', 'related'): 1,\n",
              "          ('related', 'area'): 1,\n",
              "          ('area', 'information'): 1,\n",
              "          ('retrieval', 'analysis'): 1,\n",
              "          ('analysis', 'also'): 1,\n",
              "          ('also', 'refers'): 1,\n",
              "          ('refers', 'ev'): 1,\n",
              "          ('ev', '22,web'): 1,\n",
              "          ('22,web', 'emerged'): 1,\n",
              "          ('emerged', 'important'): 1,\n",
              "          ('important', 'source'): 1,\n",
              "          ('source', 'information'): 1,\n",
              "          ('information', 'world'): 1,\n",
              "          ('world', 'resulted'): 1,\n",
              "          ('resulted', 'need'): 1,\n",
              "          ('need', 'automated'): 1,\n",
              "          ('automated', 'software'): 1,\n",
              "          ('software', 'component'): 1,\n",
              "          ('component', 'analyze'): 1,\n",
              "          ('analyze', 'web'): 1,\n",
              "          ('web', 'page'): 2,\n",
              "          ('page', 'harvest'): 1,\n",
              "          ('harvest', 'useful'): 1,\n",
              "          ('useful', 'information'): 1,\n",
              "          ('information', 'however'): 1,\n",
              "          ('however', 'typical'): 1,\n",
              "          ('typical', 'web'): 1,\n",
              "          ('page', 'informative'): 1,\n",
              "          ('informative', 'content'): 1,\n",
              "          ('content', 'surrounded'): 1,\n",
              "          ('surrounded', 'high'): 1,\n",
              "          ('high', 'degree'): 1,\n",
              "          ('degree', 'noise'): 1,\n",
              "          ('noise', '23,abstract'): 1,\n",
              "          ('23,abstract', 'natural'): 1,\n",
              "          ('processing', 'theoretically'): 1,\n",
              "          ('theoretically', 'motivated'): 1,\n",
              "          ('motivated', 'range'): 1,\n",
              "          ('range', 'computational'): 1,\n",
              "          ('computational', 'technique'): 1,\n",
              "          ('technique', 'analysing'): 1,\n",
              "          ('analysing', 'representing'): 1,\n",
              "          ('representing', 'naturally'): 1,\n",
              "          ('naturally', 'occurring'): 1,\n",
              "          ('occurring', 'text'): 1,\n",
              "          ('text', 'one'): 1,\n",
              "          ('one', 'level'): 1,\n",
              "          ('level', 'linguistic'): 1,\n",
              "          ('linguistic', 'analysis'): 1,\n",
              "          ('analysis', 'purpose'): 1,\n",
              "          ('purpose', 'achieving'): 1,\n",
              "          ('achieving', 'humanlike'): 1,\n",
              "          ('humanlike', 'language'): 1,\n",
              "          ('processing', 'range'): 1,\n",
              "          ('range', 'task'): 1,\n",
              "          ('task', 'application'): 1,\n",
              "          ('application', '24,paper'): 1,\n",
              "          ('24,paper', 'review'): 1,\n",
              "          ('review', 'process'): 1,\n",
              "          ('process', 'involved'): 1,\n",
              "          ('involved', 'natural'): 1,\n",
              "          ('nlp', 'demonstrates'): 1,\n",
              "          ('demonstrates', 'various'): 1,\n",
              "          ('various', 'kind'): 1,\n",
              "          ('kind', 'choice'): 1,\n",
              "          ('choice', 'need'): 1,\n",
              "          ('need', 'taken'): 1,\n",
              "          ('taken', 'execution'): 1,\n",
              "          ('execution', 'word'): 1,\n",
              "          ('word', 'morphology'): 1,\n",
              "          ('morphology', 'syntactic'): 1,\n",
              "          ('syntactic', 'text'): 1,\n",
              "          ('text', 'analysis'): 2,\n",
              "          ('analysis', 'text'): 2,\n",
              "          ('text', 'generation'): 2,\n",
              "          ('generation', 'component'): 1,\n",
              "          ('component', 'compare'): 1,\n",
              "          ('compare', 'time'): 1,\n",
              "          ('time', 'complexity'): 1,\n",
              "          ('complexity', 'traditional'): 1,\n",
              "          ('traditional', '25,article'): 1,\n",
              "          ('25,article', 'focus'): 1,\n",
              "          ('focus', 'derivation'): 1,\n",
              "          ('derivation', 'large'): 1,\n",
              "          ('large', 'lexicon'): 1,\n",
              "          ('lexicon', 'natural'): 1,\n",
              "          ('processing', 'describe'): 1,\n",
              "          ('describe', 'development'): 1,\n",
              "          ('development', 'dictionary'): 1,\n",
              "          ('dictionary', 'support'): 1,\n",
              "          ('support', 'environment'): 1,\n",
              "          ('environment', 'linking'): 1,\n",
              "          ('linking', 'restructured'): 1,\n",
              "          ('restructured', 'version'): 1,\n",
              "          ('version', 'longman'): 1,\n",
              "          ('longman', 'dictionary'): 1,\n",
              "          ('dictionary', 'contemporary'): 1,\n",
              "          ('contemporary', 'english'): 1,\n",
              "          ('english', 'natural'): 1,\n",
              "          ('system', 'process'): 2,\n",
              "          ('process', 'restruc'): 1,\n",
              "          ('restruc', '26,introduce'): 1,\n",
              "          ('26,introduce', 'method'): 1,\n",
              "          ('method', 'analyzing'): 1,\n",
              "          ('analyzing', 'complexity'): 1,\n",
              "          ('complexity', 'natural'): 1,\n",
              "          ('task', 'predicting'): 1,\n",
              "          ('predicting', 'difficulty'): 1,\n",
              "          ('difficulty', 'new'): 1,\n",
              "          ('new', 'nlp'): 1,\n",
              "          ('nlp', 'task'): 4,\n",
              "          ('task', 'complexity'): 1,\n",
              "          ('complexity', 'measure'): 1,\n",
              "          ('measure', 'derived'): 1,\n",
              "          ('derived', 'kolmogorov'): 1,\n",
              "          ('kolmogorov', 'complexity'): 1,\n",
              "          ('complexity', 'class'): 1,\n",
              "          ('class', 'automaton'): 1,\n",
              "          ('automaton', 'meaning'): 1,\n",
              "          ('meaning', 'automaton'): 1,\n",
              "          ('automaton', 'whose'): 1,\n",
              "          ('whose', 'purpose'): 1,\n",
              "          ('purpose', 'extract'): 1,\n",
              "          ('extract', 'relevant'): 1,\n",
              "          ('relevant', 'piece'): 1,\n",
              "          ('piece', 'infor'): 1,\n",
              "          ('infor', '27,deep'): 1,\n",
              "          ('27,deep', 'learning'): 1,\n",
              "          ('learning', 'emerged'): 1,\n",
              "          ('emerged', 'new'): 1,\n",
              "          ('new', 'area'): 1,\n",
              "          ('area', 'machine'): 1,\n",
              "          ('learning', 'research'): 1,\n",
              "          ('research', 'try'): 1,\n",
              "          ('try', 'mimic'): 1,\n",
              "          ('mimic', 'human'): 1,\n",
              "          ('human', 'brain'): 1,\n",
              "          ('brain', 'capable'): 1,\n",
              "          ('capable', 'processing'): 1,\n",
              "          ('processing', 'learning'): 1,\n",
              "          ('learning', 'complex'): 1,\n",
              "          ('complex', 'input'): 1,\n",
              "          ('input', 'data'): 1,\n",
              "          ('data', 'solving'): 1,\n",
              "          ('solving', 'different'): 1,\n",
              "          ('different', 'kind'): 1,\n",
              "          ('kind', 'complicated'): 1,\n",
              "          ('complicated', 'task'): 1,\n",
              "          ('task', 'well'): 1,\n",
              "          ('well', 'successfully'): 1,\n",
              "          ('successfully', 'applied'): 1,\n",
              "          ('applied', 'several'): 1,\n",
              "          ('several', 'field'): 1,\n",
              "          ('field', 'image'): 1,\n",
              "          ('image', '28,authorproduced'): 1,\n",
              "          ('28,authorproduced', 'version'): 1,\n",
              "          ('version', 'paper'): 1,\n",
              "          ('paper', 'published'): 1,\n",
              "          ('published', '29,abstractnatural'): 1,\n",
              "          ('29,abstractnatural', 'language'): 1,\n",
              "          ('nlp', 'application'): 1,\n",
              "          ('application', 'automated'): 1,\n",
              "          ('automated', 'parsing'): 1,\n",
              "          ('parsing', 'machine'): 1,\n",
              "          ('learning', 'technique'): 2,\n",
              "          ('technique', 'analyze'): 1,\n",
              "          ('analyze', 'standard'): 1,\n",
              "          ('standard', 'text'): 1,\n",
              "          ('text', 'application'): 1,\n",
              "          ('application', 'nlp'): 2,\n",
              "          ('nlp', 'requirement'): 1,\n",
              "          ('requirement', 'engineering'): 1,\n",
              "          ('engineering', 'include'): 1,\n",
              "          ('include', 'extraction'): 1,\n",
              "          ('extraction', 'ontology'): 1,\n",
              "          ('ontology', 'requirement'): 1,\n",
              "          ('requirement', 'specification'): 1,\n",
              "          ('specification', 'use'): 1,\n",
              "          ('use', 'nlp'): 1,\n",
              "          ('nlp', 'verify'): 1,\n",
              "          ('verify', 'consistency'): 1,\n",
              "          ('consistency', '30,information'): 1,\n",
              "          ('30,information', 'retrieval'): 1,\n",
              "          ('retrieval', 'address'): 1,\n",
              "          ('address', 'problem'): 1,\n",
              "          ('problem', 'finding'): 1,\n",
              "          ('finding', 'document'): 2,\n",
              "          ('document', 'whose'): 1,\n",
              "          ('whose', 'content'): 1,\n",
              "          ('content', 'match'): 1,\n",
              "          ('match', 'useraposs'): 1,\n",
              "          ('useraposs', 'request'): 1,\n",
              "          ('request', 'among'): 1,\n",
              "          ('among', 'large'): 1,\n",
              "          ('large', 'collection'): 1,\n",
              "          ('collection', 'document'): 1,\n",
              "          ('document', 'currently'): 1,\n",
              "          ('currently', 'successful'): 1,\n",
              "          ('successful', 'general'): 1,\n",
              "          ('general', 'purpose'): 1,\n",
              "          ('purpose', 'retrieval'): 1,\n",
              "          ('retrieval', 'method'): 1,\n",
              "          ('method', 'statistical'): 1,\n",
              "          ('statistical', 'method'): 1,\n",
              "          ('method', 'treat'): 1,\n",
              "          ('treat', 'text'): 1,\n",
              "          ('text', 'little'): 1,\n",
              "          ('little', 'bag'): 1,\n",
              "          ('bag', 'w'): 1,\n",
              "          ('w', '31,work'): 1,\n",
              "          ('31,work', 'computational'): 1,\n",
              "          ('computational', 'linguistics'): 2,\n",
              "          ('linguistics', 'began'): 1,\n",
              "          ('began', 'soon'): 1,\n",
              "          ('soon', 'development'): 1,\n",
              "          ('development', 'first'): 1,\n",
              "          ('first', 'computer'): 1,\n",
              "          ('computer', 'booth'): 1,\n",
              "          ('booth', 'brandwood'): 1,\n",
              "          ('brandwood', 'cleave'): 1,\n",
              "          ('cleave', 'yet'): 1,\n",
              "          ('yet', 'intervening'): 1,\n",
              "          ('intervening', 'four'): 1,\n",
              "          ('four', 'decade'): 1,\n",
              "          ('decade', 'pervasive'): 1,\n",
              "          ('pervasive', 'feeling'): 1,\n",
              "          ('feeling', 'progress'): 1,\n",
              "          ('progress', 'computer'): 1,\n",
              "          ('computer', 'understanding'): 1,\n",
              "          ('understanding', 'natural'): 1,\n",
              "          ('language', 'commensurate'): 1,\n",
              "          ('commensurate', 'progres'): 1,\n",
              "          ('progres', '32,abstracta'): 1,\n",
              "          ('32,abstracta', 'system'): 1,\n",
              "          ('system', 'recognizes'): 1,\n",
              "          ('recognizes', 'authenticates'): 1,\n",
              "          ('authenticates', 'voice'): 1,\n",
              "          ('voice', 'user'): 1,\n",
              "          ('user', 'extracting'): 1,\n",
              "          ('extracting', 'distinct'): 1,\n",
              "          ('distinct', 'feature'): 1,\n",
              "          ('feature', 'voice'): 1,\n",
              "          ('voice', 'sample'): 1,\n",
              "          ('sample', 'usually'): 1,\n",
              "          ('usually', 'termed'): 1,\n",
              "          ('termed', 'voice'): 1,\n",
              "          ('voice', 'recognition'): 1,\n",
              "          ('recognition', 'system'): 1,\n",
              "          ('system', 'voice'): 1,\n",
              "          ('voice', 'identification'): 1,\n",
              "          ('identification', 'carried'): 1,\n",
              "          ('carried', 'converting'): 1,\n",
              "          ('converting', 'human'): 1,\n",
              "          ('human', 'voice'): 1,\n",
              "          ('voice', 'digital'): 1,\n",
              "          ('digital', 'data'): 1,\n",
              "          ('data', 'digitized'): 1,\n",
              "          ('digitized', 'audio'): 1,\n",
              "          ('audio', 'sample'): 1,\n",
              "          ('sample', 'unde'): 1,\n",
              "          ('unde', '33,abstract'): 1,\n",
              "          ('33,abstract', 'testing'): 1,\n",
              "          ('testing', 'natural'): 1,\n",
              "          ('language', 'requirement'): 1,\n",
              "          ('requirement', 'standard'): 1,\n",
              "          ('standard', 'approach'): 1,\n",
              "          ('approach', 'system'): 1,\n",
              "          ('system', 'acceptance'): 1,\n",
              "          ('acceptance', 'testing'): 1,\n",
              "          ('testing', 'test'): 1,\n",
              "          ('test', 'often'): 1,\n",
              "          ('often', 'performed'): 1,\n",
              "          ('performed', 'independent'): 1,\n",
              "          ('independent', 'test'): 1,\n",
              "          ('test', 'organization'): 1,\n",
              "          ('organization', 'unfamiliar'): 1,\n",
              "          ('unfamiliar', 'application'): 1,\n",
              "          ('application', 'area'): 1,\n",
              "          ('area', 'thing'): 1,\n",
              "          ('thing', 'tester'): 1,\n",
              "          ('tester', 'go'): 1,\n",
              "          ('go', 'written'): 1,\n",
              "          ('written', 'requirement'): 1,\n",
              "          ('requirement', '34,'): 1,\n",
              "          ('34,', '35,algorithm'): 1,\n",
              "          ('35,algorithm', 'allow'): 1,\n",
              "          ('allow', 'understanding'): 1,\n",
              "          ('understanding', 'generation'): 1,\n",
              "          ('generation', 'humor'): 1,\n",
              "          ('humor', 'general'): 1,\n",
              "          ('general', 'aim'): 1,\n",
              "          ('aim', 'modeling'): 1,\n",
              "          ('modeling', 'humor'): 1,\n",
              "          ('humor', 'provide'): 1,\n",
              "          ('provide', 'u'): 1,\n",
              "          ('u', 'lot'): 1,\n",
              "          ('lot', 'information'): 1,\n",
              "          ('information', 'cognitive'): 1,\n",
              "          ('cognitive', 'ability'): 1,\n",
              "          ('ability', 'general'): 1,\n",
              "          ('general', 'reasoning'): 1,\n",
              "          ('reasoning', 'remembering'): 1,\n",
              "          ('remembering', 'understanding'): 1,\n",
              "          ('understanding', 'situation'): 1,\n",
              "          ('situation', 'understanding'): 1,\n",
              "          ('understanding', 'conversati'): 1,\n",
              "          ('conversati', '36,'): 1,\n",
              "          ('36,', '37,recent'): 1,\n",
              "          ('37,recent', 'year'): 1,\n",
              "          ('year', 'machine'): 1,\n",
              "          ('learning', 'ml'): 2,\n",
              "          ('ml', 'used'): 1,\n",
              "          ('used', 'solve'): 1,\n",
              "          ('solve', 'complex'): 1,\n",
              "          ('complex', 'task'): 1,\n",
              "          ('task', 'different'): 1,\n",
              "          ('different', 'discipline'): 1,\n",
              "          ('discipline', 'ranging'): 1,\n",
              "          ('ranging', 'data'): 1,\n",
              "          ('data', 'mining'): 1,\n",
              "          ('mining', 'information'): 1,\n",
              "          ('information', '38,argue'): 1,\n",
              "          ('38,argue', 'manual'): 1,\n",
              "          ('manual', 'automatic'): 1,\n",
              "          ('automatic', 'thesaurus'): 1,\n",
              "          ('thesaurus', 'alternative'): 1,\n",
              "          ('alternative', 'resource'): 1,\n",
              "          ('resource', 'nlp'): 1,\n",
              "          ('task', 'involves'): 1,\n",
              "          ('involves', 'radical'): 1,\n",
              "          ('radical', 'step'): 1,\n",
              "          ('step', 'interpreting'): 1,\n",
              "          ('interpreting', 'manual'): 1,\n",
              "          ('manual', 'thesaurus'): 1,\n",
              "          ('thesaurus', 'classification'): 1,\n",
              "          ('classification', 'word'): 1,\n",
              "          ('word', 'rather'): 1,\n",
              "          ('rather', 'word'): 1,\n",
              "          ('word', 'sens'): 1,\n",
              "          ('sens', 'case'): 1,\n",
              "          ('case', 'made'): 1,\n",
              "          ('made', 'range'): 1,\n",
              "          ('range', 'role'): 1,\n",
              "          ('role', 'thesaurus'): 1,\n",
              "          ('thesaurus', 'within'): 1,\n",
              "          ('within', 'nlp'): 1,\n",
              "          ('nlp', 'briefly'): 1,\n",
              "          ('briefly', '39,introduction'): 1,\n",
              "          ('39,introduction', 'pattern'): 1,\n",
              "          ('pattern', 'music'): 1,\n",
              "          ('music', 'object'): 1,\n",
              "          ('object', 'intensive'): 1,\n",
              "          ('intensive', 'study'): 1,\n",
              "          ('study', 'past'): 1,\n",
              "          ('past', 'year'): 1,\n",
              "          ('year', 'one'): 1,\n",
              "          ('one', 'purpose'): 1,\n",
              "          ('purpose', 'analyzing'): 1,\n",
              "          ('analyzing', 'musical'): 1,\n",
              "          ('musical', 'structure'): 1,\n",
              "          ('structure', 'form'): 1,\n",
              "          ('form', 'discover'): 1,\n",
              "          ('discover', 'pattern'): 1,\n",
              "          ('pattern', 'explicit'): 1,\n",
              "          ('explicit', 'implicit'): 1,\n",
              "          ('implicit', 'musical'): 1,\n",
              "          ('musical', 'work'): 1,\n",
              "          ('work', 'simon'): 1,\n",
              "          ('simon', 'pattern'): 1,\n",
              "          ('pattern', 'comprise'): 1,\n",
              "          ('comprise', 'periodicity'): 1,\n",
              "          ('periodicity', 'make'): 1,\n",
              "          ('use', 'alphabet'): 1,\n",
              "          ('alphabet', '40,abstract'): 1,\n",
              "          ('40,abstract', 'many'): 1,\n",
              "          ('many', 'information'): 1,\n",
              "          ('information', 'retrievalir'): 1,\n",
              "          ('retrievalir', 'system'): 1,\n",
              "          ('system', 'retrieve'): 1,\n",
              "          ('retrieve', 'relevant'): 1,\n",
              "          ('relevant', 'document'): 1,\n",
              "          ('document', 'based'): 1,\n",
              "          ('based', 'exact'): 1,\n",
              "          ('exact', 'matching'): 1,\n",
              "          ('matching', 'keywords'): 1,\n",
              "          ('keywords', 'query'): 1,\n",
              "          ('query', 'document'): 1,\n",
              "          ('document', 'method'): 1,\n",
              "          ('method', 'degrades'): 1,\n",
              "          ('degrades', 'precision'): 1,\n",
              "          ('precision', 'rate'): 1,\n",
              "          ('rate', 'order'): 1,\n",
              "          ('order', 'solve'): 1,\n",
              "          ('solve', 'problem'): 1,\n",
              "          ('problem', 'collected'): 1,\n",
              "          ('collected', 'semantically'): 1,\n",
              "          ('semantically', 'related'): 1,\n",
              "          ('related', 'word'): 1,\n",
              "          ('word', 'assigned'): 1,\n",
              "          ('assigned', 'semantic'): 1,\n",
              "          ('semantic', 'relationship'): 1,\n",
              "          ('relationship', 'used'): 1,\n",
              "          ('used', 'gener'): 1,\n",
              "          ('gener', '41,paper'): 1,\n",
              "          ('41,paper', 'argue'): 1,\n",
              "          ('argue', 'questionanswering'): 1,\n",
              "          ('questionanswering', 'qa'): 1,\n",
              "          ('qa', 'technical'): 1,\n",
              "          ('technical', 'domain'): 1,\n",
              "          ('domain', 'distinctly'): 1,\n",
              "          ('distinctly', 'different'): 1,\n",
              "          ('different', 'trecbased'): 1,\n",
              "          ('trecbased', 'qa'): 1,\n",
              "          ('qa', 'webbased'): 1,\n",
              "          ('webbased', 'qa'): 1,\n",
              "          ('qa', 'cannot'): 1,\n",
              "          ('cannot', 'benefit'): 1,\n",
              "          ('benefit', 'lom'): 1,\n",
              "          ('lom', 'dataintensive'): 1,\n",
              "          ('dataintensive', 'approach'): 1,\n",
              "          ('approach', '42,universitquotat'): 1,\n",
              "          ('42,universitquotat', 'de'): 1,\n",
              "          ('de', 'saarlandes'): 1,\n",
              "          ('saarlandes', '43,proceeding'): 1,\n",
              "          ('43,proceeding', 'workshop'): 1,\n",
              "          ('workshop', '44,unihamburgde'): 1,\n",
              "          ('44,unihamburgde', '45,'): 1,\n",
              "          ('45,', '46,'): 1,\n",
              "          ('46,', '47,sri'): 1,\n",
              "          ('47,sri', 'developed'): 1,\n",
              "          ('developed', 'new'): 1,\n",
              "          ('new', 'architecture'): 1,\n",
              "          ('architecture', 'integrating'): 1,\n",
              "          ('integrating', 'speech'): 1,\n",
              "          ('speech', 'naturallanguage'): 1,\n",
              "          ('naturallanguage', 'processing'): 1,\n",
              "          ('processing', 'applies'): 1,\n",
              "          ('applies', 'linguistic'): 1,\n",
              "          ('linguistic', 'constraint'): 1,\n",
              "          ('constraint', 'recognition'): 1,\n",
              "          ('recognition', 'incrementally'): 1,\n",
              "          ('incrementally', 'expanding'): 1,\n",
              "          ('expanding', 'statetransition'): 1,\n",
              "          ('statetransition', 'network'): 1,\n",
              "          ('network', 'embodied'): 1,\n",
              "          ('embodied', 'unification'): 1,\n",
              "          ('unification', 'grammar'): 1,\n",
              "          ('grammar', 'compare'): 1,\n",
              "          ('compare', 'dynamicgralnlnarnetwork'): 1,\n",
              "          ('dynamicgralnlnarnetwork', 'dgn'): 1,\n",
              "          ('dgn', 'approach'): 1,\n",
              "          ('approach', '48,chapter'): 1,\n",
              "          ('48,chapter', 'considers'): 1,\n",
              "          ('considers', 'revolution'): 1,\n",
              "          ('revolution', 'taken'): 1,\n",
              "          ('taken', 'place'): 1,\n",
              "          ('place', 'natural'): 1,\n",
              "          ('processing', 'research'): 1,\n",
              "          ('research', 'last'): 1,\n",
              "          ('last', 'five'): 1,\n",
              "          ('five', 'year'): 1,\n",
              "          ('year', 'begin'): 1,\n",
              "          ('begin', 'providing'): 1,\n",
              "          ('providing', 'brief'): 1,\n",
              "          ('brief', 'guide'): 1,\n",
              "          ('guide', 'structure'): 1,\n",
              "          ('structure', 'field'): 1,\n",
              "          ('field', 'present'): 1,\n",
              "          ('present', 'caricature'): 1,\n",
              "          ('caricature', 'two'): 1,\n",
              "          ('two', 'competing'): 1,\n",
              "          ('competing', 'paradigm'): 1,\n",
              "          ('paradigm', 's'): 1,\n",
              "          ('s', 'nlp'): 1,\n",
              "          ('nlp', 'research'): 2,\n",
              "          ('research', 'indicates'): 1,\n",
              "          ('indicates', 'reason'): 1,\n",
              "          ('reason', 'wh'): 1,\n",
              "          ('wh', '49,visual'): 1,\n",
              "          ('49,visual', 'development'): 1,\n",
              "          ('development', 'environment'): 1,\n",
              "          ('environment', 'support'): 1,\n",
              "          ('support', 'visual'): 1,\n",
              "          ('visual', 'assembly'): 1,\n",
              "          ('assembly', 'execution'): 1,\n",
              "          ('execution', 'analysis'): 1,\n",
              "          ('analysis', 'modular'): 1,\n",
              "          ('modular', 'natural'): 1,\n",
              "          ('system', 'visual'): 1,\n",
              "          ('visual', 'model'): 1,\n",
              "          ('model', 'executable'): 1,\n",
              "          ('executable', 'data'): 1,\n",
              "          ('data', 'flow'): 1,\n",
              "          ('flow', 'program'): 1,\n",
              "          ('program', 'graph'): 1,\n",
              "          ('graph', 'automatically'): 1,\n",
              "          ('automatically', 'synthesised'): 1,\n",
              "          ('synthesised', 'data'): 1,\n",
              "          ('data', 'dependency'): 1,\n",
              "          ('dependency', 'declaration'): 1,\n",
              "          ('declaration', 'language'): 1,\n",
              "          ...})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w-_XgxArVrVD",
        "outputId": "28d50ab9-f459-4781-8d3e-09d3020ee0d4"
      },
      "source": [
        "#unigrams\r\n",
        "from nltk.util import ngrams\r\n",
        "d = open('abst2.csv', \"r\")\r\n",
        "u_grams = ngrams(d.read().split(), 1)\r\n",
        "u_freqdist=nltk.FreqDist(u_grams)      #count\r\n",
        "display(u_freqdist)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FreqDist({(',cleansentence',): 1,\n",
              "          ('0,',): 1,\n",
              "          ('1,concept',): 1,\n",
              "          ('maximum',): 1,\n",
              "          ('entropy',): 1,\n",
              "          ('traced',): 1,\n",
              "          ('back',): 1,\n",
              "          ('along',): 1,\n",
              "          ('multiple',): 1,\n",
              "          ('thread',): 1,\n",
              "          ('biblical',): 1,\n",
              "          ('time',): 2,\n",
              "          ('recently',): 3,\n",
              "          ('however',): 5,\n",
              "          ('computer',): 5,\n",
              "          ('become',): 3,\n",
              "          ('powerful',): 3,\n",
              "          ('enough',): 1,\n",
              "          ('permit',): 1,\n",
              "          ('widescale',): 1,\n",
              "          ('application',): 17,\n",
              "          ('concept',): 2,\n",
              "          ('real',): 1,\n",
              "          ('world',): 3,\n",
              "          ('problem',): 4,\n",
              "          ('statistical',): 5,\n",
              "          ('estimation',): 3,\n",
              "          ('pattern',): 4,\n",
              "          ('recognition',): 11,\n",
              "          ('paper',): 5,\n",
              "          ('de',): 4,\n",
              "          ('2,scaling',): 1,\n",
              "          ('conditional',): 1,\n",
              "          ('random',): 1,\n",
              "          ('field',): 9,\n",
              "          ('natural',): 69,\n",
              "          ('language',): 97,\n",
              "          ('processing',): 66,\n",
              "          ('term',): 2,\n",
              "          ('condition',): 2,\n",
              "          ('copyright',): 1,\n",
              "          ('work',): 8,\n",
              "          ('deposited',): 1,\n",
              "          ('minerva',): 1,\n",
              "          ('access',): 1,\n",
              "          ('retained',): 1,\n",
              "          ('3,paper',): 1,\n",
              "          ('address',): 3,\n",
              "          ('issue',): 5,\n",
              "          ('cooperation',): 2,\n",
              "          ('linguistics',): 5,\n",
              "          ('nlp',): 36,\n",
              "          ('general',): 4,\n",
              "          ('machine',): 15,\n",
              "          ('translation',): 3,\n",
              "          ('mt',): 1,\n",
              "          ('particular',): 3,\n",
              "          ('focus',): 7,\n",
              "          ('one',): 7,\n",
              "          ('direction',): 1,\n",
              "          ('namely',): 1,\n",
              "          ('virtually',): 1,\n",
              "          ('ignoring',): 1,\n",
              "          ('4,natural',): 1,\n",
              "          ('description',): 4,\n",
              "          ('logic',): 8,\n",
              "          ('used',): 11,\n",
              "          ('encode',): 2,\n",
              "          ('knowledge',): 10,\n",
              "          ('base',): 3,\n",
              "          ('syntactic',): 5,\n",
              "          ('semantic',): 7,\n",
              "          ('pragmatic',): 1,\n",
              "          ('element',): 4,\n",
              "          ('needed',): 2,\n",
              "          ('drive',): 2,\n",
              "          ('interpretation',): 3,\n",
              "          ('generation',): 4,\n",
              "          ('process',): 11,\n",
              "          ('u',): 3,\n",
              "          ('5,propose',): 1,\n",
              "          ('unified',): 2,\n",
              "          ('neural',): 4,\n",
              "          ('network',): 5,\n",
              "          ('architecture',): 5,\n",
              "          ('learning',): 20,\n",
              "          ('algorithm',): 4,\n",
              "          ('applied',): 4,\n",
              "          ('various',): 7,\n",
              "          ('task',): 16,\n",
              "          ('including',): 5,\n",
              "          ('partofspeech',): 2,\n",
              "          ('tagging',): 1,\n",
              "          ('chunking',): 2,\n",
              "          ('named',): 2,\n",
              "          ('entity',): 2,\n",
              "          ('role',): 4,\n",
              "          ('labeling',): 1,\n",
              "          ('versatility',): 1,\n",
              "          ('achieved',): 1,\n",
              "          ('trying',): 1,\n",
              "          ('avoid',): 2,\n",
              "          ('taskspecific',): 1,\n",
              "          ('eng',): 1,\n",
              "          ('6,natural',): 1,\n",
              "          ('subject',): 1,\n",
              "          ('considered',): 1,\n",
              "          ('broad',): 2,\n",
              "          ('narrow',): 1,\n",
              "          ('sens',): 2,\n",
              "          ('sense',): 4,\n",
              "          ('cover',): 1,\n",
              "          ('level',): 3,\n",
              "          ('understanding',): 8,\n",
              "          ('speech',): 7,\n",
              "          ('analysis',): 11,\n",
              "          ('sentence',): 3,\n",
              "          ('refer',): 1,\n",
              "          ('7,robot',): 1,\n",
              "          ('interact',): 1,\n",
              "          ('human',): 6,\n",
              "          ('facetoface',): 1,\n",
              "          ('using',): 4,\n",
              "          ('need',): 6,\n",
              "          ('responsive',): 1,\n",
              "          ('way',): 5,\n",
              "          ('use',): 10,\n",
              "          ('situation',): 2,\n",
              "          ('propose',): 1,\n",
              "          ('psychologicallyinspired',): 1,\n",
              "          ('system',): 26,\n",
              "          ('robot',): 1,\n",
              "          ('performs',): 2,\n",
              "          ('incremental',): 1,\n",
              "          ('spoken',): 4,\n",
              "          ('utterance',): 1,\n",
              "          ('8,natural',): 1,\n",
              "          ('currently',): 3,\n",
              "          ('yet',): 2,\n",
              "          ('point',): 3,\n",
              "          ('unprocessed',): 1,\n",
              "          ('form',): 3,\n",
              "          ('understood',): 2,\n",
              "          ('collection',): 3,\n",
              "          ('technique',): 11,\n",
              "          ('employed',): 1,\n",
              "          ('try',): 2,\n",
              "          ('accomplish',): 1,\n",
              "          ('goal',): 2,\n",
              "          ('l',): 1,\n",
              "          ('9,abstract',): 1,\n",
              "          ('ambiguity',): 1,\n",
              "          ('referred',): 1,\n",
              "          ('ability',): 3,\n",
              "          ('meaning',): 4,\n",
              "          ('ambiguous',): 1,\n",
              "          ('able',): 2,\n",
              "          ('understand',): 2,\n",
              "          ('people',): 1,\n",
              "          ('concerned',): 2,\n",
              "          ('development',): 9,\n",
              "          ('co',): 1,\n",
              "          ('10,introduction',): 1,\n",
              "          ('snlp',): 2,\n",
              "          ('lying',): 1,\n",
              "          ('intersection',): 1,\n",
              "          ('diers',): 1,\n",
              "          ('traditional',): 3,\n",
              "          ('instead',): 1,\n",
              "          ('linguist',): 1,\n",
              "          ('manually',): 1,\n",
              "          ('construct',): 3,\n",
              "          ('model',): 8,\n",
              "          ('given',): 5,\n",
              "          ('linguistic',): 8,\n",
              "          ('11,paper',): 1,\n",
              "          ('summarizes',): 1,\n",
              "          ('essential',): 1,\n",
              "          ('property',): 1,\n",
              "          ('document',): 13,\n",
              "          ('retrieval',): 12,\n",
              "          ('review',): 5,\n",
              "          ('conventional',): 1,\n",
              "          ('practice',): 2,\n",
              "          ('research',): 8,\n",
              "          ('finding',): 3,\n",
              "          ('latter',): 1,\n",
              "          ('suggesting',): 2,\n",
              "          ('simple',): 3,\n",
              "          ('effective',): 7,\n",
              "          ('considers',): 2,\n",
              "          ('new',): 8,\n",
              "          ('opportunity',): 3,\n",
              "          ('challenge',): 1,\n",
              "          ('presented',): 2,\n",
              "          ('search',): 1,\n",
              "          ('full',): 1,\n",
              "          ('12,abstract',): 1,\n",
              "          ('communicating',): 1,\n",
              "          ('word',): 14,\n",
              "          ('help',): 2,\n",
              "          ('worldwe',): 1,\n",
              "          ('get',): 1,\n",
              "          ('better',): 1,\n",
              "          ('insight',): 2,\n",
              "          ('speaker',): 2,\n",
              "          ('vague',): 1,\n",
              "          ('precise',): 1,\n",
              "          ('like',): 2,\n",
              "          ('stand',): 1,\n",
              "          ('13,report',): 1,\n",
              "          ('experiment',): 2,\n",
              "          ('standard',): 3,\n",
              "          ('tool',): 3,\n",
              "          ('music',): 3,\n",
              "          ('lyric',): 3,\n",
              "          ('significant',): 4,\n",
              "          ('amount',): 1,\n",
              "          ('audio',): 2,\n",
              "          ('important',): 3,\n",
              "          ('part',): 4,\n",
              "          ('semantics',): 1,\n",
              "          ('song',): 1,\n",
              "          ('therefore',): 2,\n",
              "          ('complement',): 1,\n",
              "          ('acoustic',): 1,\n",
              "          ('cultural',): 1,\n",
              "          ('metada',): 1,\n",
              "          ('14,paper',): 1,\n",
              "          ('describe',): 3,\n",
              "          ('rulebased',): 1,\n",
              "          ('approach',): 13,\n",
              "          ('automated',): 5,\n",
              "          ('shown',): 2,\n",
              "          ('number',): 4,\n",
              "          ('capture',): 3,\n",
              "          ('information',): 18,\n",
              "          ('clearer',): 1,\n",
              "          ('direct',): 1,\n",
              "          ('fashion',): 1,\n",
              "          ('without',): 1,\n",
              "          ('compromise',): 1,\n",
              "          ('performance',): 2,\n",
              "          ('present',): 7,\n",
              "          ('detailed',): 2,\n",
              "          ('case',): 2,\n",
              "          ('study',): 4,\n",
              "          ('learni',): 1,\n",
              "          ('15,paper',): 1,\n",
              "          ('connectionist',): 1,\n",
              "          ('briefly',): 3,\n",
              "          ('discus',): 2,\n",
              "          ('several',): 4,\n",
              "          ('aspect',): 2,\n",
              "          ('high',): 3,\n",
              "          ('approached',): 1,\n",
              "          ('connectionism',): 1,\n",
              "          ('either',): 1,\n",
              "          ('localist',): 1,\n",
              "          ('parallel',): 1,\n",
              "          ('distributed',): 1,\n",
              "          ('interesting',): 1,\n",
              "          ('16,abstract',): 1,\n",
              "          ('article',): 1,\n",
              "          ('explores',): 1,\n",
              "          ('possibility',): 1,\n",
              "          ('feature',): 8,\n",
              "          ('component',): 4,\n",
              "          ('letter',): 2,\n",
              "          ('modeled',): 1,\n",
              "          ('different',): 6,\n",
              "          ('attractor',): 1,\n",
              "          ('finally',): 1,\n",
              "          ('embedded',): 1,\n",
              "          ('quadratic',): 1,\n",
              "          ('iterated',): 1,\n",
              "          ('map',): 3,\n",
              "          ('result',): 6,\n",
              "          ('account',): 1,\n",
              "          ('extraction',): 5,\n",
              "          ('pr',): 2,\n",
              "          ('17,paper',): 1,\n",
              "          ('see',): 1,\n",
              "          ('schank',): 1,\n",
              "          ('theoretical',): 1,\n",
              "          ('discussion',): 2,\n",
              "          ('ka',): 1,\n",
              "          ('leake',): 1,\n",
              "          ('owen',): 1,\n",
              "          ('brief',): 3,\n",
              "          ('program',): 3,\n",
              "          ('built',): 2,\n",
              "          ('around',): 1,\n",
              "          ('principle',): 4,\n",
              "          ('simply',): 1,\n",
              "          ('interest',): 1,\n",
              "          ('led',): 1,\n",
              "          ('naturally',): 2,\n",
              "          ('indeed',): 1,\n",
              "          ('inevitably',): 1,\n",
              "          ('18,objective',): 1,\n",
              "          ('provide',): 2,\n",
              "          ('overview',): 2,\n",
              "          ('tutorial',): 2,\n",
              "          ('modern',): 1,\n",
              "          ('nlpsystem',): 1,\n",
              "          ('design',): 3,\n",
              "          ('target',): 2,\n",
              "          ('audience',): 1,\n",
              "          ('medical',): 2,\n",
              "          ('informatics',): 1,\n",
              "          ('generalist',): 1,\n",
              "          ('limited',): 4,\n",
              "          ('acquaintance',): 1,\n",
              "          ('behind',): 1,\n",
              "          ('andor',): 1,\n",
              "          ('current',): 7,\n",
              "          ('state',): 2,\n",
              "          ('19,paper',): 1,\n",
              "          ('describes',): 2,\n",
              "          ('implementation',): 2,\n",
              "          ('status',): 1,\n",
              "          ('intelligent',): 1,\n",
              "          ('marie',): 1,\n",
              "          ('employ',): 1,\n",
              "          ('descriptive',): 1,\n",
              "          ('caption',): 2,\n",
              "          ('iden',): 1,\n",
              "          ('tify',): 1,\n",
              "          ('photographic',): 1,\n",
              "          ('image',): 2,\n",
              "          ('concerning',): 2,\n",
              "          ('military',): 1,\n",
              "          ('project',): 3,\n",
              "          ('parsed',): 1,\n",
              "          ('20,abstract',): 1,\n",
              "          ('metabolism',): 1,\n",
              "          ('machinery',): 2,\n",
              "          ('life',): 1,\n",
              "          ('signal',): 2,\n",
              "          ('transduction',): 2,\n",
              "          ('provides',): 3,\n",
              "          ('regulatory',): 1,\n",
              "          ('mechanism',): 1,\n",
              "          ('control',): 1,\n",
              "          ('due',): 2,\n",
              "          ('complexity',): 5,\n",
              "          ('pathway',): 1,\n",
              "          ('computational',): 7,\n",
              "          ('aid',): 2,\n",
              "          ('biologist',): 1,\n",
              "          ('integrating',): 2,\n",
              "          ('available',): 2,\n",
              "          ('formulatio',): 1,\n",
              "          ('21,report',): 1,\n",
              "          ('evaluation',): 5,\n",
              "          ('examines',): 4,\n",
              "          ('establishes',): 1,\n",
              "          ('framework',): 3,\n",
              "          ('make',): 4,\n",
              "          ('experience',): 2,\n",
              "          ('related',): 3,\n",
              "          ('area',): 6,\n",
              "          ('also',): 4,\n",
              "          ('refers',): 1,\n",
              "          ('ev',): 1,\n",
              "          ('22,web',): 1,\n",
              "          ('emerged',): 2,\n",
              "          ('source',): 4,\n",
              "          ('resulted',): 1,\n",
              "          ('software',): 5,\n",
              "          ('analyze',): 2,\n",
              "          ('web',): 3,\n",
              "          ('page',): 2,\n",
              "          ('harvest',): 1,\n",
              "          ('useful',): 2,\n",
              "          ('typical',): 1,\n",
              "          ('informative',): 1,\n",
              "          ('content',): 2,\n",
              "          ('surrounded',): 1,\n",
              "          ('degree',): 2,\n",
              "          ('noise',): 1,\n",
              "          ('23,abstract',): 1,\n",
              "          ('theoretically',): 1,\n",
              "          ('motivated',): 1,\n",
              "          ('range',): 5,\n",
              "          ('analysing',): 1,\n",
              "          ('representing',): 2,\n",
              "          ('occurring',): 1,\n",
              "          ('text',): 13,\n",
              "          ('purpose',): 5,\n",
              "          ('achieving',): 1,\n",
              "          ('humanlike',): 1,\n",
              "          ('24,paper',): 1,\n",
              "          ('involved',): 1,\n",
              "          ('demonstrates',): 1,\n",
              "          ('kind',): 3,\n",
              "          ('choice',): 1,\n",
              "          ('taken',): 2,\n",
              "          ('execution',): 2,\n",
              "          ('morphology',): 1,\n",
              "          ('compare',): 2,\n",
              "          ('25,article',): 1,\n",
              "          ('derivation',): 1,\n",
              "          ('large',): 3,\n",
              "          ('lexicon',): 1,\n",
              "          ('dictionary',): 4,\n",
              "          ('support',): 4,\n",
              "          ('environment',): 2,\n",
              "          ('linking',): 1,\n",
              "          ('restructured',): 1,\n",
              "          ('version',): 2,\n",
              "          ('longman',): 1,\n",
              "          ('contemporary',): 1,\n",
              "          ('english',): 2,\n",
              "          ('restruc',): 1,\n",
              "          ('26,introduce',): 1,\n",
              "          ('method',): 7,\n",
              "          ('analyzing',): 2,\n",
              "          ('predicting',): 1,\n",
              "          ('difficulty',): 1,\n",
              "          ('measure',): 3,\n",
              "          ('derived',): 1,\n",
              "          ('kolmogorov',): 1,\n",
              "          ('class',): 3,\n",
              "          ('automaton',): 2,\n",
              "          ('whose',): 2,\n",
              "          ('extract',): 2,\n",
              "          ('relevant',): 2,\n",
              "          ('piece',): 1,\n",
              "          ('infor',): 1,\n",
              "          ('27,deep',): 1,\n",
              "          ('mimic',): 1,\n",
              "          ('brain',): 2,\n",
              "          ('capable',): 1,\n",
              "          ('complex',): 3,\n",
              "          ('input',): 3,\n",
              "          ('data',): 9,\n",
              "          ('solving',): 1,\n",
              "          ('complicated',): 1,\n",
              "          ('well',): 3,\n",
              "          ('successfully',): 1,\n",
              "          ('28,authorproduced',): 1,\n",
              "          ('published',): 2,\n",
              "          ('29,abstractnatural',): 1,\n",
              "          ('parsing',): 7,\n",
              "          ('requirement',): 5,\n",
              "          ('engineering',): 2,\n",
              "          ('include',): 2,\n",
              "          ('ontology',): 2,\n",
              "          ('specification',): 1,\n",
              "          ('verify',): 1,\n",
              "          ('consistency',): 1,\n",
              "          ('30,information',): 1,\n",
              "          ('match',): 1,\n",
              "          ('useraposs',): 1,\n",
              "          ('request',): 1,\n",
              "          ('among',): 4,\n",
              "          ('successful',): 1,\n",
              "          ('treat',): 1,\n",
              "          ('little',): 2,\n",
              "          ('bag',): 1,\n",
              "          ('w',): 2,\n",
              "          ('31,work',): 1,\n",
              "          ('began',): 1,\n",
              "          ('soon',): 1,\n",
              "          ('first',): 3,\n",
              "          ('booth',): 1,\n",
              "          ('brandwood',): 1,\n",
              "          ('cleave',): 1,\n",
              "          ('intervening',): 1,\n",
              "          ('four',): 1,\n",
              "          ('decade',): 1,\n",
              "          ('pervasive',): 1,\n",
              "          ('feeling',): 1,\n",
              "          ('progress',): 1,\n",
              "          ('commensurate',): 1,\n",
              "          ('progres',): 1,\n",
              "          ('32,abstracta',): 1,\n",
              "          ('recognizes',): 1,\n",
              "          ('authenticates',): 1,\n",
              "          ('voice',): 5,\n",
              "          ('user',): 3,\n",
              "          ('extracting',): 1,\n",
              "          ('distinct',): 1,\n",
              "          ('sample',): 2,\n",
              "          ('usually',): 2,\n",
              "          ('termed',): 1,\n",
              "          ('identification',): 1,\n",
              "          ('carried',): 1,\n",
              "          ('converting',): 1,\n",
              "          ('digital',): 1,\n",
              "          ('digitized',): 1,\n",
              "          ('unde',): 1,\n",
              "          ('33,abstract',): 1,\n",
              "          ('testing',): 2,\n",
              "          ('acceptance',): 1,\n",
              "          ('test',): 2,\n",
              "          ('often',): 2,\n",
              "          ('performed',): 1,\n",
              "          ('independent',): 2,\n",
              "          ('organization',): 2,\n",
              "          ('unfamiliar',): 1,\n",
              "          ('thing',): 1,\n",
              "          ('tester',): 1,\n",
              "          ('go',): 2,\n",
              "          ('written',): 1,\n",
              "          ('34,',): 1,\n",
              "          ('35,algorithm',): 1,\n",
              "          ('allow',): 1,\n",
              "          ('humor',): 2,\n",
              "          ('aim',): 2,\n",
              "          ('modeling',): 2,\n",
              "          ('lot',): 1,\n",
              "          ('cognitive',): 1,\n",
              "          ('reasoning',): 2,\n",
              "          ('remembering',): 1,\n",
              "          ('conversati',): 1,\n",
              "          ('36,',): 1,\n",
              "          ('37,recent',): 1,\n",
              "          ('year',): 7,\n",
              "          ('ml',): 2,\n",
              "          ('solve',): 2,\n",
              "          ('discipline',): 4,\n",
              "          ('ranging',): 2,\n",
              "          ('mining',): 1,\n",
              "          ('38,argue',): 1,\n",
              "          ('manual',): 3,\n",
              "          ('automatic',): 1,\n",
              "          ('thesaurus',): 3,\n",
              "          ('alternative',): 1,\n",
              "          ('resource',): 5,\n",
              "          ('involves',): 2,\n",
              "          ('radical',): 1,\n",
              "          ('step',): 1,\n",
              "          ('interpreting',): 1,\n",
              "          ('classification',): 2,\n",
              "          ('rather',): 2,\n",
              "          ('made',): 1,\n",
              "          ('within',): 3,\n",
              "          ('39,introduction',): 1,\n",
              "          ('object',): 3,\n",
              "          ('intensive',): 1,\n",
              "          ('past',): 1,\n",
              "          ('musical',): 2,\n",
              "          ('structure',): 5,\n",
              "          ('discover',): 1,\n",
              "          ('explicit',): 1,\n",
              "          ('implicit',): 1,\n",
              "          ('simon',): 1,\n",
              "          ('comprise',): 1,\n",
              "          ('periodicity',): 1,\n",
              "          ('alphabet',): 1,\n",
              "          ('40,abstract',): 1,\n",
              "          ('many',): 5,\n",
              "          ('retrievalir',): 1,\n",
              "          ('retrieve',): 1,\n",
              "          ('based',): 4,\n",
              "          ('exact',): 1,\n",
              "          ('matching',): 2,\n",
              "          ('keywords',): 1,\n",
              "          ('query',): 1,\n",
              "          ('degrades',): 1,\n",
              "          ('precision',): 1,\n",
              "          ('rate',): 1,\n",
              "          ('order',): 1,\n",
              "          ('collected',): 1,\n",
              "          ('semantically',): 2,\n",
              "          ('assigned',): 1,\n",
              "          ('relationship',): 2,\n",
              "          ('gener',): 1,\n",
              "          ('41,paper',): 1,\n",
              "          ('argue',): 1,\n",
              "          ('questionanswering',): 1,\n",
              "          ('qa',): 3,\n",
              "          ('technical',): 1,\n",
              "          ('domain',): 9,\n",
              "          ('distinctly',): 1,\n",
              "          ('trecbased',): 1,\n",
              "          ('webbased',): 2,\n",
              "          ('cannot',): 1,\n",
              "          ('benefit',): 2,\n",
              "          ('lom',): 1,\n",
              "          ('dataintensive',): 1,\n",
              "          ('42,universitquotat',): 1,\n",
              "          ('saarlandes',): 1,\n",
              "          ('43,proceeding',): 1,\n",
              "          ('workshop',): 1,\n",
              "          ('44,unihamburgde',): 1,\n",
              "          ('45,',): 1,\n",
              "          ('46,',): 1,\n",
              "          ('47,sri',): 1,\n",
              "          ('developed',): 2,\n",
              "          ('naturallanguage',): 1,\n",
              "          ('applies',): 1,\n",
              "          ('constraint',): 1,\n",
              "          ('incrementally',): 1,\n",
              "          ('expanding',): 1,\n",
              "          ('statetransition',): 1,\n",
              "          ('embodied',): 1,\n",
              "          ('unification',): 1,\n",
              "          ('grammar',): 4,\n",
              "          ('dynamicgralnlnarnetwork',): 1,\n",
              "          ('dgn',): 1,\n",
              "          ('48,chapter',): 1,\n",
              "          ('revolution',): 1,\n",
              "          ('place',): 1,\n",
              "          ('last',): 3,\n",
              "          ('five',): 1,\n",
              "          ('begin',): 1,\n",
              "          ('providing',): 2,\n",
              "          ('guide',): 1,\n",
              "          ('caricature',): 1,\n",
              "          ('two',): 7,\n",
              "          ('competing',): 1,\n",
              "          ('paradigm',): 2,\n",
              "          ('s',): 1,\n",
              "          ('indicates',): 1,\n",
              "          ('reason',): 1,\n",
              "          ('wh',): 1,\n",
              "          ('49,visual',): 1,\n",
              "          ('visual',): 2,\n",
              "          ('assembly',): 1,\n",
              "          ('modular',): 1,\n",
              "          ('executable',): 1,\n",
              "          ('flow',): 1,\n",
              "          ('graph',): 2,\n",
              "          ('automatically',): 1,\n",
              "          ('synthesised',): 1,\n",
              "          ('dependency',): 1,\n",
              "          ('declaration',): 1,\n",
              "          ('module',): 1,\n",
              "          ('th',): 3,\n",
              "          ('50,chapter',): 1,\n",
              "          ('basic',): 4,\n",
              "          ('us',): 2,\n",
              "          ('analysed',): 1,\n",
              "          ('together',): 1,\n",
              "          ('bit',): 1,\n",
              "          ('history',): 5,\n",
              "          ('art',): 1,\n",
              "          ('pointed',): 1,\n",
              "          ('introduction',): 2,\n",
              "          ('since',): 1,\n",
              "          ('early',): 1,\n",
              "          ('day',): 1,\n",
              "          ('51,applied',): 1,\n",
              "          ('maxmargin',): 1,\n",
              "          ('mm',): 1,\n",
              "          ('latent',): 1,\n",
              "          ('output',): 4,\n",
              "          ('formulate',): 1,\n",
              "          ('extension',): 1,\n",
              "          ('multiclass',): 1,\n",
              "          ('vector',): 1,\n",
              "          ('svm',): 1,\n",
              "          ('per',): 2,\n",
              "          ('52,vast',): 1,\n",
              "          ('quantity',): 2,\n",
              "          ('becoming',): 1,\n",
              "          ('electronic',): 2,\n",
              "          ('eg',): 2,\n",
              "          ('encyclopedia',): 1,\n",
              "          ('library',): 1,\n",
              "          ('archive',): 1,\n",
              "          ('service',): 1,\n",
              "          ('private',): 1,\n",
              "          ('database',): 1,\n",
              "          ('marketing',): 1,\n",
              "          ('legal',): 1,\n",
              "          ('record',): 1,\n",
              "          ('53,last',): 1,\n",
              "          ('begun',): 1,\n",
              "          ('applying',): 2,\n",
              "          ('graphbased',): 1,\n",
              "          ('others',): 1,\n",
              "          ('summarization',): 1,\n",
              "          ('disambiguation',): 2,\n",
              "          ('construction',): 2,\n",
              "          ('sentiment',): 1,\n",
              "          ('subjectivity',): 1,\n",
              "          ('clustering',): 1,\n",
              "          ('pa',): 1,\n",
              "          ('54,natural',): 1,\n",
              "          ('technology',): 4,\n",
              "          ('neglected',): 1,\n",
              "          ('55,kernelized',): 1,\n",
              "          ('sorting',): 1,\n",
              "          ('require',): 1,\n",
              "          ('prior',): 1,\n",
              "          ('notion',): 1,\n",
              "          ('similarity',): 3,\n",
              "          ('across',): 1,\n",
              "          ('unfortunately',): 2,\n",
              "          ('highly',): 1,\n",
              "          ('sensitive',): 3,\n",
              "          ('initialization',): 1,\n",
              "          ('dimensional',): 1,\n",
              "          ('variant',): 1,\n",
              "          ('kern',): 1,\n",
              "          ('56,natural',): 1,\n",
              "          ('compound',): 1,\n",
              "          ('represent',): 1,\n",
              "          ('nature',): 1,\n",
              "          ('sophisticated',): 1,\n",
              "          ('treatment',): 1,\n",
              "          ('57,paper',): 1,\n",
              "          ('developing',): 1,\n",
              "          ('probabilistic',): 2,\n",
              "          ('classifier',): 1,\n",
              "          ('formulating',): 1,\n",
              "          ('interdependency',): 1,\n",
              "          ('overfitting',): 1,\n",
              "          ('characterizing',): 1,\n",
              "          ('pro',): 1,\n",
              "          ('58,many',): 1,\n",
              "          ('encouraging',): 1,\n",
              "          ('stopwording',): 1,\n",
              "          ('porterstyle',): 1,\n",
              "          ('stemming',): 1,\n",
              "          ('etc',): 1,\n",
              "          ('yield',): 1,\n",
              "          ('improvement',): 4,\n",
              "          ('higherlevel',): 1,\n",
              "          ('e',): 2,\n",
              "          ('59,abstract',): 1,\n",
              "          ('explains',): 1,\n",
              "          ('malayalam',): 1,\n",
              "          ('60,research',): 1,\n",
              "          ('plan',): 2,\n",
              "          ('share',): 2,\n",
              "          ('common',): 2,\n",
              "          ('even',): 3,\n",
              "          ('dialog',): 2,\n",
              "          ('specifically',): 2,\n",
              "          ('recent',): 2,\n",
              "          ('mildly',): 2,\n",
              "          ('context',): 4,\n",
              "          ('leveraged',): 2,\n",
              "          ('61,research',): 1,\n",
              "          ('62,information',): 1,\n",
              "          ('satisfies',): 1,\n",
              "          ('motivation',): 1,\n",
              "          ('investigate',): 1,\n",
              "          ('improve',): 1,\n",
              "          ('performa',): 1,\n",
              "          ('63,computational',): 1,\n",
              "          ('widely',): 2,\n",
              "          ('crossfertilization',): 1,\n",
              "          ('programming',): 2,\n",
              "          ('rise',): 1,\n",
              "          ('known',): 1,\n",
              "          ('inductive',): 1,\n",
              "          ('inspired',): 1,\n",
              "          ('building',): 1,\n",
              "          ('achievement',): 1,\n",
              "          ('64,statistical',): 1,\n",
              "          ('start',): 1,\n",
              "          ('definition',): 1,\n",
              "          ('distinguish',): 1,\n",
              "          ('three',): 2,\n",
              "          ('65,report',): 1,\n",
              "          ('collaborative',): 1,\n",
              "          ('structured',): 1,\n",
              "          ('includes',): 3,\n",
              "          ('superficial',): 1,\n",
              "          ('comprehensive',): 1,\n",
              "          ('survey',): 1,\n",
              "          ('covering',): 2,\n",
              "          ('stateoftheart',): 2,\n",
              "          ('techniq',): 1,\n",
              "          ('66,abstract',): 1,\n",
              "          ('thesis',): 1,\n",
              "          ('mainly',): 1,\n",
              "          ('objective',): 1,\n",
              "          ('adaptability',): 1,\n",
              "          ('thematic',): 1,\n",
              "          ('lang',): 1,\n",
              "          ('67,chapter',): 1,\n",
              "          ('computerassisted',): 2,\n",
              "          ('thirtyfive',): 2,\n",
              "          ('68,traditional',): 1,\n",
              "          ('tointerpretation',): 1,\n",
              "          ('typically',): 2,\n",
              "          ('fall',): 2,\n",
              "          ('syntaxdriven',): 2,\n",
              "          ('semanticsdriven',): 1,\n",
              "          ('frametask',): 1,\n",
              "          ('domainindependent',): 1,\n",
              "          ('produce',): 1,\n",
              "          ('global',): 2,\n",
              "          ('parse',): 1,\n",
              "          ('69,natural',): 1,\n",
              "          ('diverse',): 1,\n",
              "          ('subtopic',): 1,\n",
              "          ('artificial',): 3,\n",
              "          ('intelligence',): 2,\n",
              "          ('subtopics',): 1,\n",
              "          ('optical',): 1,\n",
              "          ('character',): 1,\n",
              "          ('translator',): 1,\n",
              "          ('foreign',): 1,\n",
              "          ('reading',): 1,\n",
              "          ('writing',): 1,\n",
              "          ('70,probabilistic',): 1,\n",
              "          ('finitestate',): 1,\n",
              "          ('string',): 1,\n",
              "          ('transducer',): 1,\n",
              "          ('fsts',): 2,\n",
              "          ('extremely',): 1,\n",
              "          ('popular',): 2,\n",
              "          ('generic',): 2,\n",
              "          ('composing',): 1,\n",
              "          ('good',): 1,\n",
              "          ('fit',): 1,\n",
              "          ('much',): 1,\n",
              "          ('translati',): 1,\n",
              "          ('71,abstract',): 1,\n",
              "          ('special',): 1,\n",
              "          ('tal',): 1,\n",
              "          ('look',): 1,\n",
              "          ('fundamental',): 1,\n",
              "          ('underlying',): 1,\n",
              "          ('adopt',): 1,\n",
              "          ('view',): 1,\n",
              "          ('beyond',): 1,\n",
              "          ('horizon',): 1,\n",
              "          ('single',): 3,\n",
              "          ('campaign',): 1,\n",
              "          ('protocol',): 1,\n",
              "          ('terminology',): 1,\n",
              "          ('72,',): 1,\n",
              "          ('73,natural',): 1,\n",
              "          ('clinical',): 1,\n",
              "          ('textual',): 1,\n",
              "          ('report',): 1,\n",
              "          ('requires',): 1,\n",
              "          ('substantial',): 1,\n",
              "          ('develop',): 1,\n",
              "          ('beneficial',): 1,\n",
              "          ('designed',): 1,\n",
              "          ('easily',): 1,\n",
              "          ('74,propose',): 1,\n",
              "          ('bifurcated',): 1,\n",
              "          ('prolog',): 3,\n",
              "          ('body',): 1,\n",
              "          ('ie',): 1,\n",
              "          ('annotate',): 1,\n",
              "          ('corpus',): 1,\n",
              "          ('annotated',): 1,\n",
              "          ('second',): 1,\n",
              "          ('kb',): 1,\n",
              "          ('transform',): 1,\n",
              "          ('75,describe',): 1,\n",
              "          ('convolutional',): 1,\n",
              "          ('host',): 1,\n",
              "          ('prediction',): 1,\n",
              "          ('tag',): 2,\n",
              "          ('chunk',): 1,\n",
              "          ('similar',): 1,\n",
              "          ('likelihood',): 1,\n",
              "          ('grammatically',): 1,\n",
              "          ('sem',): 1,\n",
              "          ('76,developed',): 1,\n",
              "          ('prototype',): 1,\n",
              "          ('advanced',): 1,\n",
              "          ('enhance',): 1,\n",
              "          ('effectiveness',): 1,\n",
              "          ('keyword',): 1,\n",
              "          ('backbone',): 1,\n",
              "          ('engine',): 1,\n",
              "          ('indexing',): 1,\n",
              "          ('docum',): 1,\n",
              "          ('77,',): 1,\n",
              "          ('78,paper',): 1,\n",
              "          ('enabling',): 1,\n",
              "          ('contextadaptive',): 1,\n",
              "          ('fact',): 1,\n",
              "          ('emerging',): 1,\n",
              "          ('continuous',): 1,\n",
              "          ('restricted',): 1,\n",
              "          ('individual',): 1,\n",
              "          ('equipped',): 1,\n",
              "          ('79,fall',): 1,\n",
              "          ('introduced',): 1,\n",
              "          ('course',): 1,\n",
              "          ('called',): 2,\n",
              "          ('student',): 1,\n",
              "          ('acquire',): 2,\n",
              "          ('feasible',): 1,\n",
              "          ('practical',): 3,\n",
              "          ('80,',): 1,\n",
              "          ('81,abstract',): 1,\n",
              "          ('mathematical',): 1,\n",
              "          ('modelling',): 2,\n",
              "          ('wide',): 3,\n",
              "          ('arises',): 1,\n",
              "          ('innate',): 1,\n",
              "          ('facility',): 1,\n",
              "          ('possessed',): 1,\n",
              "          ('intellect',): 1,\n",
              "          ('may',): 1,\n",
              "          ('82,natural',): 1,\n",
              "          ('branch',): 1,\n",
              "          ('synthesis',): 1,\n",
              "          ('indian',): 2,\n",
              "          ('rural',): 1,\n",
              "          ('community',): 2,\n",
              "          ('unable',): 1,\n",
              "          ('83,evaluation',): 1,\n",
              "          ('lolita',): 3,\n",
              "          ('paul',): 1,\n",
              "          ('callaghan',): 1,\n",
              "          ('submitted',): 1,\n",
              "          ('university',): 1,\n",
              "          ('durham',): 1,\n",
              "          ('phd',): 1,\n",
              "          ('august',): 1,\n",
              "          ('question',): 1,\n",
              "          ('evaluate',): 1,\n",
              "          ('84,previous',): 1,\n",
              "          ('demonstrated',): 1,\n",
              "          ('count',): 2,\n",
              "          ('approximate',): 1,\n",
              "          ('bigram',): 1,\n",
              "          ('frequency',): 1,\n",
              "          ('variety',): 1,\n",
              "          ('far',): 1,\n",
              "          ('tested',): 1,\n",
              "          ('webscale',): 1,\n",
              "          ('set',): 3,\n",
              "          ('85,chapter',): 1,\n",
              "          ('chapter',): 1,\n",
              "          ('86,paper',): 1,\n",
              "          ('improves',): 1,\n",
              "          ('short',): 2,\n",
              "          ('narrative',): 2,\n",
              "          ('schema',): 1,\n",
              "          ('stereotypical',): 1,\n",
              "          ('action',): 1,\n",
              "          ('attempt',): 1,\n",
              "          ('87,classify',): 1,\n",
              "          ('infrastructure',): 1,\n",
              "          ('delivery',): 1,\n",
              "          ('88,confidence',): 1,\n",
              "          ('solution',): 2,\n",
              "          ('improving',): 1,\n",
              "          ('usefulness',): 1,\n",
              "          ('confidence',): 3,\n",
              "          ('deriving',): 1,\n",
              "          ('give',): 1,\n",
              "          ('n',): 1,\n",
              "          ('89,lexsign',): 1,\n",
              "          ('senseid',): 6,\n",
              "          ('ldoce',): 1,\n",
              "          ('lexsign',): 2,\n",
              "          ('ldbentryno',): 1,\n",
              "          ('senseno',): 1,\n",
              "          ('loaded',): 1,\n",
              "          ('lkb',): 1,\n",
              "          ('expanded',): 1,\n",
              "          ('fullyfledged',): 1,\n",
              "          ('representation',): 1,\n",
              "          ('transitive',): 1,\n",
              "          ('90,describe',): 1,\n",
              "          ('stanford',): 1,\n",
              "          ('corenlp',): 1,\n",
              "          ('toolkit',): 2,\n",
              "          ('extensible',): 1,\n",
              "          ('pipeline',): 1,\n",
              "          ('core',): 1,\n",
              "          ('quite',): 1,\n",
              "          ('commercial',): 1,\n",
              "          ('government',): 1,\n",
              "          ('open',): 1,\n",
              "          ('suggest',): 1,\n",
              "          ('91,gaussian',): 1,\n",
              "          ('gps',): 1,\n",
              "          ('incorporating',): 1,\n",
              "          ('kernel',): 1,\n",
              "          ('bayesian',): 1,\n",
              "          ('inference',): 1,\n",
              "          ('recognised',): 1,\n",
              "          ('92,fundamental',): 1,\n",
              "          ('prerequisite',): 1,\n",
              "          ('enormous',): 1,\n",
              "          ('preprogrammed',): 1,\n",
              "          ('examination',): 1,\n",
              "          ('acquisition',): 3,\n",
              "          ('tedious',): 1,\n",
              "          ('error',): 1,\n",
              "          ('prone',): 1,\n",
              "          ('93,general',): 1,\n",
              "          ('reusable',): 1,\n",
              "          ('veloped',): 1,\n",
              "          ('penman',): 1,\n",
              "          ('organizing',): 1,\n",
              "          ('appropriately',): 1,\n",
              "          ('realization',): 1,\n",
              "          ('upper',): 1,\n",
              "          ...})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17UAviUkWBVv",
        "outputId": "63748e67-d6fb-44d8-c603-121eca980deb"
      },
      "source": [
        "#probability for bigram\r\n",
        "def probigr():\r\n",
        "  for v in b_freqdist:\r\n",
        "    p=b_freqdist[v]/u_freqdist[(v[0],)] \r\n",
        "    print(v,'p=',p)      #probability of all bigrams\r\n",
        "probigr()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(',cleansentence', '0,') p= 1.0\n",
            "('0,', '1,concept') p= 1.0\n",
            "('1,concept', 'maximum') p= 1.0\n",
            "('maximum', 'entropy') p= 1.0\n",
            "('entropy', 'traced') p= 1.0\n",
            "('traced', 'back') p= 1.0\n",
            "('back', 'along') p= 1.0\n",
            "('along', 'multiple') p= 1.0\n",
            "('multiple', 'thread') p= 1.0\n",
            "('thread', 'biblical') p= 1.0\n",
            "('biblical', 'time') p= 1.0\n",
            "('time', 'recently') p= 0.5\n",
            "('recently', 'however') p= 0.3333333333333333\n",
            "('however', 'computer') p= 0.2\n",
            "('computer', 'become') p= 0.2\n",
            "('become', 'powerful') p= 0.3333333333333333\n",
            "('powerful', 'enough') p= 0.3333333333333333\n",
            "('enough', 'permit') p= 1.0\n",
            "('permit', 'widescale') p= 1.0\n",
            "('widescale', 'application') p= 1.0\n",
            "('application', 'concept') p= 0.058823529411764705\n",
            "('concept', 'real') p= 0.5\n",
            "('real', 'world') p= 1.0\n",
            "('world', 'problem') p= 0.3333333333333333\n",
            "('problem', 'statistical') p= 0.25\n",
            "('statistical', 'estimation') p= 0.2\n",
            "('estimation', 'pattern') p= 0.3333333333333333\n",
            "('pattern', 'recognition') p= 0.25\n",
            "('recognition', 'paper') p= 0.09090909090909091\n",
            "('paper', 'de') p= 0.2\n",
            "('de', '2,scaling') p= 0.25\n",
            "('2,scaling', 'conditional') p= 1.0\n",
            "('conditional', 'random') p= 1.0\n",
            "('random', 'field') p= 1.0\n",
            "('field', 'natural') p= 0.2222222222222222\n",
            "('natural', 'language') p= 0.9565217391304348\n",
            "('language', 'processing') p= 0.6288659793814433\n",
            "('processing', 'term') p= 0.015151515151515152\n",
            "('term', 'condition') p= 1.0\n",
            "('condition', 'term') p= 0.5\n",
            "('condition', 'copyright') p= 0.5\n",
            "('copyright', 'work') p= 1.0\n",
            "('work', 'deposited') p= 0.125\n",
            "('deposited', 'minerva') p= 1.0\n",
            "('minerva', 'access') p= 1.0\n",
            "('access', 'retained') p= 1.0\n",
            "('retained', '3,paper') p= 1.0\n",
            "('3,paper', 'address') p= 1.0\n",
            "('address', 'issue') p= 0.3333333333333333\n",
            "('issue', 'cooperation') p= 0.2\n",
            "('cooperation', 'linguistics') p= 0.5\n",
            "('linguistics', 'natural') p= 0.2\n",
            "('processing', 'nlp') p= 0.24242424242424243\n",
            "('nlp', 'general') p= 0.027777777777777776\n",
            "('general', 'linguistics') p= 0.25\n",
            "('linguistics', 'machine') p= 0.2\n",
            "('machine', 'translation') p= 0.2\n",
            "('translation', 'mt') p= 0.3333333333333333\n",
            "('mt', 'particular') p= 1.0\n",
            "('particular', 'focus') p= 0.3333333333333333\n",
            "('focus', 'one') p= 0.14285714285714285\n",
            "('one', 'direction') p= 0.14285714285714285\n",
            "('direction', 'cooperation') p= 1.0\n",
            "('cooperation', 'namely') p= 0.5\n",
            "('namely', 'application') p= 1.0\n",
            "('application', 'linguistics') p= 0.058823529411764705\n",
            "('linguistics', 'nlp') p= 0.2\n",
            "('nlp', 'virtually') p= 0.027777777777777776\n",
            "('virtually', 'ignoring') p= 1.0\n",
            "('ignoring', '4,natural') p= 1.0\n",
            "('4,natural', 'language') p= 1.0\n",
            "('processing', 'application') p= 0.030303030303030304\n",
            "('application', 'description') p= 0.058823529411764705\n",
            "('description', 'logic') p= 1.0\n",
            "('logic', 'used') p= 0.125\n",
            "('used', 'encode') p= 0.09090909090909091\n",
            "('encode', 'knowledge') p= 0.5\n",
            "('knowledge', 'base') p= 0.3\n",
            "('base', 'syntactic') p= 0.3333333333333333\n",
            "('syntactic', 'semantic') p= 0.4\n",
            "('semantic', 'pragmatic') p= 0.14285714285714285\n",
            "('pragmatic', 'element') p= 1.0\n",
            "('element', 'needed') p= 0.25\n",
            "('needed', 'drive') p= 0.5\n",
            "('drive', 'semantic') p= 0.5\n",
            "('semantic', 'interpretation') p= 0.2857142857142857\n",
            "('interpretation', 'natural') p= 0.3333333333333333\n",
            "('language', 'generation') p= 0.010309278350515464\n",
            "('generation', 'process') p= 0.25\n",
            "('process', 'recently') p= 0.09090909090909091\n",
            "('recently', 'description') p= 0.3333333333333333\n",
            "('logic', 'u') p= 0.125\n",
            "('u', '5,propose') p= 0.3333333333333333\n",
            "('5,propose', 'unified') p= 1.0\n",
            "('unified', 'neural') p= 0.5\n",
            "('neural', 'network') p= 1.0\n",
            "('network', 'architecture') p= 0.4\n",
            "('architecture', 'learning') p= 0.2\n",
            "('learning', 'algorithm') p= 0.05\n",
            "('algorithm', 'applied') p= 0.25\n",
            "('applied', 'various') p= 0.25\n",
            "('various', 'natural') p= 0.14285714285714285\n",
            "('processing', 'task') p= 0.030303030303030304\n",
            "('task', 'including') p= 0.0625\n",
            "('including', 'partofspeech') p= 0.2\n",
            "('partofspeech', 'tagging') p= 0.5\n",
            "('tagging', 'chunking') p= 1.0\n",
            "('chunking', 'named') p= 0.5\n",
            "('named', 'entity') p= 1.0\n",
            "('entity', 'recognition') p= 0.5\n",
            "('recognition', 'semantic') p= 0.09090909090909091\n",
            "('semantic', 'role') p= 0.2857142857142857\n",
            "('role', 'labeling') p= 0.25\n",
            "('labeling', 'versatility') p= 1.0\n",
            "('versatility', 'achieved') p= 1.0\n",
            "('achieved', 'trying') p= 1.0\n",
            "('trying', 'avoid') p= 1.0\n",
            "('avoid', 'taskspecific') p= 0.5\n",
            "('taskspecific', 'eng') p= 1.0\n",
            "('eng', '6,natural') p= 1.0\n",
            "('6,natural', 'language') p= 1.0\n",
            "('processing', 'subject') p= 0.015151515151515152\n",
            "('subject', 'natural') p= 1.0\n",
            "('processing', 'considered') p= 0.015151515151515152\n",
            "('considered', 'broad') p= 1.0\n",
            "('broad', 'narrow') p= 0.5\n",
            "('narrow', 'sens') p= 1.0\n",
            "('sens', 'broad') p= 0.5\n",
            "('broad', 'sense') p= 0.5\n",
            "('sense', 'cover') p= 0.25\n",
            "('cover', 'processing') p= 1.0\n",
            "('processing', 'issue') p= 0.015151515151515152\n",
            "('issue', 'level') p= 0.2\n",
            "('level', 'natural') p= 0.3333333333333333\n",
            "('language', 'understanding') p= 0.010309278350515464\n",
            "('understanding', 'including') p= 0.125\n",
            "('including', 'speech') p= 0.2\n",
            "('speech', 'recognition') p= 0.5714285714285714\n",
            "('recognition', 'syntactic') p= 0.09090909090909091\n",
            "('semantic', 'analysis') p= 0.14285714285714285\n",
            "('analysis', 'sentence') p= 0.09090909090909091\n",
            "('sentence', 'refer') p= 0.3333333333333333\n",
            "('refer', '7,robot') p= 1.0\n",
            "('7,robot', 'interact') p= 1.0\n",
            "('interact', 'human') p= 1.0\n",
            "('human', 'facetoface') p= 0.16666666666666666\n",
            "('facetoface', 'using') p= 1.0\n",
            "('using', 'natural') p= 0.5\n",
            "('language', 'need') p= 0.020618556701030927\n",
            "('need', 'responsive') p= 0.16666666666666666\n",
            "('responsive', 'way') p= 1.0\n",
            "('way', 'human') p= 0.2\n",
            "('human', 'use') p= 0.16666666666666666\n",
            "('use', 'language') p= 0.1\n",
            "('language', 'situation') p= 0.010309278350515464\n",
            "('situation', 'propose') p= 0.5\n",
            "('propose', 'psychologicallyinspired') p= 1.0\n",
            "('psychologicallyinspired', 'natural') p= 1.0\n",
            "('processing', 'system') p= 0.09090909090909091\n",
            "('system', 'robot') p= 0.038461538461538464\n",
            "('robot', 'performs') p= 1.0\n",
            "('performs', 'incremental') p= 0.5\n",
            "('incremental', 'semantic') p= 1.0\n",
            "('interpretation', 'spoken') p= 0.3333333333333333\n",
            "('spoken', 'utterance') p= 0.25\n",
            "('utterance', '8,natural') p= 1.0\n",
            "('8,natural', 'language') p= 1.0\n",
            "('language', 'language') p= 0.030927835051546393\n",
            "('language', 'spoken') p= 0.020618556701030927\n",
            "('spoken', 'human') p= 0.25\n",
            "('human', 'currently') p= 0.16666666666666666\n",
            "('currently', 'yet') p= 0.3333333333333333\n",
            "('yet', 'point') p= 0.5\n",
            "('point', 'language') p= 0.3333333333333333\n",
            "('language', 'unprocessed') p= 0.010309278350515464\n",
            "('unprocessed', 'form') p= 1.0\n",
            "('form', 'understood') p= 0.3333333333333333\n",
            "('understood', 'computer') p= 0.5\n",
            "('computer', 'natural') p= 0.2\n",
            "('processing', 'collection') p= 0.015151515151515152\n",
            "('collection', 'technique') p= 0.3333333333333333\n",
            "('technique', 'employed') p= 0.09090909090909091\n",
            "('employed', 'try') p= 1.0\n",
            "('try', 'accomplish') p= 0.5\n",
            "('accomplish', 'goal') p= 1.0\n",
            "('goal', 'field') p= 0.5\n",
            "('natural', 'l') p= 0.014492753623188406\n",
            "('l', '9,abstract') p= 1.0\n",
            "('9,abstract', 'ambiguity') p= 1.0\n",
            "('ambiguity', 'referred') p= 1.0\n",
            "('referred', 'ability') p= 1.0\n",
            "('ability', 'one') p= 0.3333333333333333\n",
            "('one', 'meaning') p= 0.14285714285714285\n",
            "('meaning', 'understood') p= 0.25\n",
            "('understood', 'one') p= 0.5\n",
            "('one', 'way') p= 0.14285714285714285\n",
            "('way', 'natural') p= 0.2\n",
            "('language', 'ambiguous') p= 0.010309278350515464\n",
            "('ambiguous', 'computer') p= 1.0\n",
            "('computer', 'able') p= 0.2\n",
            "('able', 'understand') p= 0.5\n",
            "('understand', 'language') p= 0.5\n",
            "('language', 'way') p= 0.020618556701030927\n",
            "('way', 'people') p= 0.2\n",
            "('people', 'natural') p= 1.0\n",
            "('nlp', 'concerned') p= 0.05555555555555555\n",
            "('concerned', 'development') p= 0.5\n",
            "('development', 'co') p= 0.1111111111111111\n",
            "('co', '10,introduction') p= 1.0\n",
            "('10,introduction', 'statistical') p= 1.0\n",
            "('statistical', 'natural') p= 0.2\n",
            "('processing', 'snlp') p= 0.015151515151515152\n",
            "('snlp', 'field') p= 0.5\n",
            "('field', 'lying') p= 0.1111111111111111\n",
            "('lying', 'intersection') p= 1.0\n",
            "('intersection', 'natural') p= 1.0\n",
            "('processing', 'machine') p= 0.015151515151515152\n",
            "('machine', 'learning') p= 0.6666666666666666\n",
            "('learning', 'snlp') p= 0.05\n",
            "('snlp', 'diers') p= 0.5\n",
            "('diers', 'traditional') p= 1.0\n",
            "('traditional', 'natural') p= 0.3333333333333333\n",
            "('processing', 'instead') p= 0.015151515151515152\n",
            "('instead', 'linguist') p= 1.0\n",
            "('linguist', 'manually') p= 1.0\n",
            "('manually', 'construct') p= 1.0\n",
            "('construct', 'model') p= 0.3333333333333333\n",
            "('model', 'given') p= 0.125\n",
            "('given', 'linguistic') p= 0.2\n",
            "('linguistic', '11,paper') p= 0.125\n",
            "('11,paper', 'summarizes') p= 1.0\n",
            "('summarizes', 'essential') p= 1.0\n",
            "('essential', 'property') p= 1.0\n",
            "('property', 'document') p= 1.0\n",
            "('document', 'retrieval') p= 0.15384615384615385\n",
            "('retrieval', 'review') p= 0.08333333333333333\n",
            "('review', 'conventional') p= 0.2\n",
            "('conventional', 'practice') p= 1.0\n",
            "('practice', 'research') p= 0.5\n",
            "('research', 'finding') p= 0.125\n",
            "('finding', 'latter') p= 0.3333333333333333\n",
            "('latter', 'suggesting') p= 1.0\n",
            "('suggesting', 'simple') p= 0.5\n",
            "('simple', 'statistical') p= 0.3333333333333333\n",
            "('statistical', 'technique') p= 0.2\n",
            "('technique', 'effective') p= 0.09090909090909091\n",
            "('effective', 'considers') p= 0.14285714285714285\n",
            "('considers', 'new') p= 0.5\n",
            "('new', 'opportunity') p= 0.125\n",
            "('opportunity', 'challenge') p= 0.3333333333333333\n",
            "('challenge', 'presented') p= 1.0\n",
            "('presented', 'ability') p= 0.5\n",
            "('ability', 'search') p= 0.3333333333333333\n",
            "('search', 'full') p= 1.0\n",
            "('full', '12,abstract') p= 1.0\n",
            "('12,abstract', 'language') p= 1.0\n",
            "('way', 'communicating') p= 0.2\n",
            "('communicating', 'word') p= 1.0\n",
            "('word', 'language') p= 0.07142857142857142\n",
            "('language', 'help') p= 0.020618556701030927\n",
            "('help', 'understanding') p= 0.5\n",
            "('understanding', 'worldwe') p= 0.125\n",
            "('worldwe', 'get') p= 1.0\n",
            "('get', 'better') p= 1.0\n",
            "('better', 'insight') p= 1.0\n",
            "('insight', 'world') p= 0.5\n",
            "('world', 'language') p= 0.3333333333333333\n",
            "('help', 'speaker') p= 0.5\n",
            "('speaker', 'vague') p= 0.5\n",
            "('vague', 'precise') p= 1.0\n",
            "('precise', 'like') p= 1.0\n",
            "('like', 'nlp') p= 0.5\n",
            "('nlp', 'stand') p= 0.027777777777777776\n",
            "('stand', 'natural') p= 1.0\n",
            "('processing', 'natural') p= 0.015151515151515152\n",
            "('spoken', '13,report') p= 0.25\n",
            "('13,report', 'experiment') p= 1.0\n",
            "('experiment', 'use') p= 0.5\n",
            "('use', 'standard') p= 0.1\n",
            "('standard', 'natural') p= 0.3333333333333333\n",
            "('nlp', 'tool') p= 0.027777777777777776\n",
            "('tool', 'analysis') p= 0.3333333333333333\n",
            "('analysis', 'music') p= 0.09090909090909091\n",
            "('music', 'lyric') p= 0.3333333333333333\n",
            "('lyric', 'significant') p= 0.3333333333333333\n",
            "('significant', 'amount') p= 0.25\n",
            "('amount', 'music') p= 1.0\n",
            "('music', 'audio') p= 0.3333333333333333\n",
            "('audio', 'lyric') p= 0.5\n",
            "('lyric', 'lyric') p= 0.3333333333333333\n",
            "('lyric', 'encode') p= 0.3333333333333333\n",
            "('encode', 'important') p= 0.5\n",
            "('important', 'part') p= 0.3333333333333333\n",
            "('part', 'semantics') p= 0.25\n",
            "('semantics', 'song') p= 1.0\n",
            "('song', 'therefore') p= 1.0\n",
            "('therefore', 'analysis') p= 0.5\n",
            "('analysis', 'complement') p= 0.09090909090909091\n",
            "('complement', 'acoustic') p= 1.0\n",
            "('acoustic', 'cultural') p= 1.0\n",
            "('cultural', 'metada') p= 1.0\n",
            "('metada', '14,paper') p= 1.0\n",
            "('14,paper', 'describe') p= 1.0\n",
            "('describe', 'simple') p= 0.3333333333333333\n",
            "('simple', 'rulebased') p= 0.3333333333333333\n",
            "('rulebased', 'approach') p= 1.0\n",
            "('approach', 'automated') p= 0.07692307692307693\n",
            "('automated', 'learning') p= 0.2\n",
            "('learning', 'linguistic') p= 0.05\n",
            "('linguistic', 'knowledge') p= 0.25\n",
            "('knowledge', 'approach') p= 0.1\n",
            "('approach', 'shown') p= 0.07692307692307693\n",
            "('shown', 'number') p= 0.5\n",
            "('number', 'task') p= 0.5\n",
            "('task', 'capture') p= 0.0625\n",
            "('capture', 'information') p= 0.3333333333333333\n",
            "('information', 'clearer') p= 0.05555555555555555\n",
            "('clearer', 'direct') p= 1.0\n",
            "('direct', 'fashion') p= 1.0\n",
            "('fashion', 'without') p= 1.0\n",
            "('without', 'compromise') p= 1.0\n",
            "('compromise', 'performance') p= 1.0\n",
            "('performance', 'present') p= 0.5\n",
            "('present', 'detailed') p= 0.2857142857142857\n",
            "('detailed', 'case') p= 0.5\n",
            "('case', 'study') p= 0.5\n",
            "('study', 'learni') p= 0.25\n",
            "('learni', '15,paper') p= 1.0\n",
            "('15,paper', 'focus') p= 1.0\n",
            "('focus', 'connectionist') p= 0.14285714285714285\n",
            "('connectionist', 'model') p= 1.0\n",
            "('model', 'natural') p= 0.125\n",
            "('processing', 'briefly') p= 0.015151515151515152\n",
            "('briefly', 'present') p= 0.3333333333333333\n",
            "('present', 'discus') p= 0.14285714285714285\n",
            "('discus', 'several') p= 1.0\n",
            "('several', 'aspect') p= 0.25\n",
            "('aspect', 'high') p= 0.5\n",
            "('high', 'level') p= 0.3333333333333333\n",
            "('level', 'task') p= 0.3333333333333333\n",
            "('task', 'recently') p= 0.0625\n",
            "('recently', 'approached') p= 0.3333333333333333\n",
            "('approached', 'connectionism') p= 1.0\n",
            "('connectionism', 'either') p= 1.0\n",
            "('either', 'localist') p= 1.0\n",
            "('localist', 'parallel') p= 1.0\n",
            "('parallel', 'distributed') p= 1.0\n",
            "('distributed', 'processing') p= 1.0\n",
            "('processing', 'model') p= 0.015151515151515152\n",
            "('model', 'several') p= 0.125\n",
            "('several', 'interesting') p= 0.25\n",
            "('interesting', 'architecture') p= 1.0\n",
            "('architecture', '16,abstract') p= 0.2\n",
            "('16,abstract', 'article') p= 1.0\n",
            "('article', 'explores') p= 1.0\n",
            "('explores', 'possibility') p= 1.0\n",
            "('possibility', 'construct') p= 1.0\n",
            "('construct', 'unified') p= 0.3333333333333333\n",
            "('unified', 'word') p= 0.5\n",
            "('word', 'feature') p= 0.14285714285714285\n",
            "('feature', 'component') p= 0.125\n",
            "('component', 'feature') p= 0.25\n",
            "('feature', 'letter') p= 0.125\n",
            "('letter', 'letter') p= 0.5\n",
            "('letter', 'modeled') p= 0.5\n",
            "('modeled', 'different') p= 1.0\n",
            "('different', 'attractor') p= 0.16666666666666666\n",
            "('attractor', 'finally') p= 1.0\n",
            "('finally', 'embedded') p= 1.0\n",
            "('embedded', 'quadratic') p= 1.0\n",
            "('quadratic', 'iterated') p= 1.0\n",
            "('iterated', 'map') p= 1.0\n",
            "('map', 'result') p= 0.3333333333333333\n",
            "('result', 'word') p= 0.16666666666666666\n",
            "('feature', 'account') p= 0.125\n",
            "('account', 'meaning') p= 1.0\n",
            "('meaning', 'extraction') p= 0.25\n",
            "('extraction', 'pr') p= 0.2\n",
            "('pr', '17,paper') p= 0.5\n",
            "('17,paper', 'see') p= 1.0\n",
            "('see', 'schank') p= 1.0\n",
            "('schank', 'theoretical') p= 1.0\n",
            "('theoretical', 'discussion') p= 1.0\n",
            "('discussion', 'ka') p= 0.5\n",
            "('ka', 'leake') p= 1.0\n",
            "('leake', 'owen') p= 1.0\n",
            "('owen', 'brief') p= 1.0\n",
            "('brief', 'discussion') p= 0.3333333333333333\n",
            "('discussion', 'program') p= 0.5\n",
            "('program', 'built') p= 0.3333333333333333\n",
            "('built', 'around') p= 0.5\n",
            "('around', 'principle') p= 1.0\n",
            "('principle', 'goal') p= 0.25\n",
            "('goal', 'simply') p= 0.5\n",
            "('simply', 'point') p= 1.0\n",
            "('point', 'interest') p= 0.3333333333333333\n",
            "('interest', 'natural') p= 1.0\n",
            "('processing', 'led') p= 0.015151515151515152\n",
            "('led', 'u') p= 1.0\n",
            "('u', 'naturally') p= 0.3333333333333333\n",
            "('naturally', 'indeed') p= 0.5\n",
            "('indeed', 'inevitably') p= 1.0\n",
            "('inevitably', 'de') p= 1.0\n",
            "('de', '18,objective') p= 0.25\n",
            "('18,objective', 'provide') p= 1.0\n",
            "('provide', 'overview') p= 0.5\n",
            "('overview', 'tutorial') p= 0.5\n",
            "('tutorial', 'natural') p= 0.5\n",
            "('nlp', 'modern') p= 0.027777777777777776\n",
            "('modern', 'nlpsystem') p= 1.0\n",
            "('nlpsystem', 'design') p= 1.0\n",
            "('design', 'target') p= 0.3333333333333333\n",
            "('target', 'audience') p= 0.5\n",
            "('audience', 'tutorial') p= 1.0\n",
            "('tutorial', 'target') p= 0.5\n",
            "('target', 'medical') p= 0.5\n",
            "('medical', 'informatics') p= 0.5\n",
            "('informatics', 'generalist') p= 1.0\n",
            "('generalist', 'limited') p= 1.0\n",
            "('limited', 'acquaintance') p= 0.25\n",
            "('acquaintance', 'principle') p= 1.0\n",
            "('principle', 'behind') p= 0.25\n",
            "('behind', 'nlp') p= 1.0\n",
            "('nlp', 'andor') p= 0.027777777777777776\n",
            "('andor', 'limited') p= 1.0\n",
            "('limited', 'knowledge') p= 0.25\n",
            "('knowledge', 'current') p= 0.1\n",
            "('current', 'state') p= 0.2857142857142857\n",
            "('state', '19,paper') p= 0.5\n",
            "('19,paper', 'briefly') p= 1.0\n",
            "('briefly', 'describes') p= 0.3333333333333333\n",
            "('describes', 'current') p= 0.5\n",
            "('current', 'implementation') p= 0.14285714285714285\n",
            "('implementation', 'status') p= 0.5\n",
            "('status', 'intelligent') p= 1.0\n",
            "('intelligent', 'information') p= 1.0\n",
            "('information', 'retrieval') p= 0.3333333333333333\n",
            "('retrieval', 'system') p= 0.16666666666666666\n",
            "('system', 'marie') p= 0.038461538461538464\n",
            "('marie', 'employ') p= 1.0\n",
            "('employ', 'natural') p= 1.0\n",
            "('processing', 'technique') p= 0.030303030303030304\n",
            "('technique', 'descriptive') p= 0.09090909090909091\n",
            "('descriptive', 'caption') p= 1.0\n",
            "('caption', 'used') p= 0.5\n",
            "('used', 'iden') p= 0.09090909090909091\n",
            "('iden', 'tify') p= 1.0\n",
            "('tify', 'photographic') p= 1.0\n",
            "('photographic', 'image') p= 1.0\n",
            "('image', 'concerning') p= 0.5\n",
            "('concerning', 'various') p= 0.5\n",
            "('various', 'military') p= 0.14285714285714285\n",
            "('military', 'project') p= 1.0\n",
            "('project', 'caption') p= 0.3333333333333333\n",
            "('caption', 'parsed') p= 0.5\n",
            "('parsed', '20,abstract') p= 1.0\n",
            "('20,abstract', 'metabolism') p= 1.0\n",
            "('metabolism', 'machinery') p= 1.0\n",
            "('machinery', 'life') p= 0.5\n",
            "('life', 'signal') p= 1.0\n",
            "('signal', 'transduction') p= 1.0\n",
            "('transduction', 'provides') p= 0.5\n",
            "('provides', 'regulatory') p= 0.3333333333333333\n",
            "('regulatory', 'mechanism') p= 1.0\n",
            "('mechanism', 'control') p= 1.0\n",
            "('control', 'machinery') p= 1.0\n",
            "('machinery', 'due') p= 0.5\n",
            "('due', 'complexity') p= 0.5\n",
            "('complexity', 'signal') p= 0.2\n",
            "('transduction', 'pathway') p= 0.5\n",
            "('pathway', 'computational') p= 1.0\n",
            "('computational', 'approach') p= 0.14285714285714285\n",
            "('approach', 'needed') p= 0.07692307692307693\n",
            "('needed', 'aid') p= 0.5\n",
            "('aid', 'biologist') p= 0.5\n",
            "('biologist', 'integrating') p= 1.0\n",
            "('integrating', 'available') p= 0.5\n",
            "('available', 'knowledge') p= 0.5\n",
            "('knowledge', 'formulatio') p= 0.1\n",
            "('formulatio', '21,report') p= 1.0\n",
            "('21,report', 'present') p= 1.0\n",
            "('detailed', 'analysis') p= 0.5\n",
            "('analysis', 'review') p= 0.09090909090909091\n",
            "('review', 'nlp') p= 0.2\n",
            "('nlp', 'evaluation') p= 0.027777777777777776\n",
            "('evaluation', 'principle') p= 0.2\n",
            "('principle', 'practice') p= 0.25\n",
            "('practice', 'part') p= 0.5\n",
            "('part', 'examines') p= 0.25\n",
            "('examines', 'evaluation') p= 0.25\n",
            "('evaluation', 'concept') p= 0.2\n",
            "('concept', 'establishes') p= 0.5\n",
            "('establishes', 'framework') p= 1.0\n",
            "('framework', 'nlp') p= 0.3333333333333333\n",
            "('nlp', 'system') p= 0.08333333333333333\n",
            "('system', 'evaluation') p= 0.038461538461538464\n",
            "('evaluation', 'make') p= 0.2\n",
            "('make', 'use') p= 0.75\n",
            "('use', 'experience') p= 0.1\n",
            "('experience', 'related') p= 0.5\n",
            "('related', 'area') p= 0.3333333333333333\n",
            "('area', 'information') p= 0.16666666666666666\n",
            "('retrieval', 'analysis') p= 0.08333333333333333\n",
            "('analysis', 'also') p= 0.09090909090909091\n",
            "('also', 'refers') p= 0.25\n",
            "('refers', 'ev') p= 1.0\n",
            "('ev', '22,web') p= 1.0\n",
            "('22,web', 'emerged') p= 1.0\n",
            "('emerged', 'important') p= 0.5\n",
            "('important', 'source') p= 0.3333333333333333\n",
            "('source', 'information') p= 0.25\n",
            "('information', 'world') p= 0.05555555555555555\n",
            "('world', 'resulted') p= 0.3333333333333333\n",
            "('resulted', 'need') p= 1.0\n",
            "('need', 'automated') p= 0.16666666666666666\n",
            "('automated', 'software') p= 0.2\n",
            "('software', 'component') p= 0.2\n",
            "('component', 'analyze') p= 0.25\n",
            "('analyze', 'web') p= 0.5\n",
            "('web', 'page') p= 0.6666666666666666\n",
            "('page', 'harvest') p= 0.5\n",
            "('harvest', 'useful') p= 1.0\n",
            "('useful', 'information') p= 0.5\n",
            "('information', 'however') p= 0.05555555555555555\n",
            "('however', 'typical') p= 0.2\n",
            "('typical', 'web') p= 1.0\n",
            "('page', 'informative') p= 0.5\n",
            "('informative', 'content') p= 1.0\n",
            "('content', 'surrounded') p= 0.5\n",
            "('surrounded', 'high') p= 1.0\n",
            "('high', 'degree') p= 0.3333333333333333\n",
            "('degree', 'noise') p= 0.5\n",
            "('noise', '23,abstract') p= 1.0\n",
            "('23,abstract', 'natural') p= 1.0\n",
            "('processing', 'theoretically') p= 0.015151515151515152\n",
            "('theoretically', 'motivated') p= 1.0\n",
            "('motivated', 'range') p= 1.0\n",
            "('range', 'computational') p= 0.2\n",
            "('computational', 'technique') p= 0.14285714285714285\n",
            "('technique', 'analysing') p= 0.09090909090909091\n",
            "('analysing', 'representing') p= 1.0\n",
            "('representing', 'naturally') p= 0.5\n",
            "('naturally', 'occurring') p= 0.5\n",
            "('occurring', 'text') p= 1.0\n",
            "('text', 'one') p= 0.07692307692307693\n",
            "('one', 'level') p= 0.14285714285714285\n",
            "('level', 'linguistic') p= 0.3333333333333333\n",
            "('linguistic', 'analysis') p= 0.125\n",
            "('analysis', 'purpose') p= 0.09090909090909091\n",
            "('purpose', 'achieving') p= 0.2\n",
            "('achieving', 'humanlike') p= 1.0\n",
            "('humanlike', 'language') p= 1.0\n",
            "('processing', 'range') p= 0.015151515151515152\n",
            "('range', 'task') p= 0.2\n",
            "('task', 'application') p= 0.0625\n",
            "('application', '24,paper') p= 0.058823529411764705\n",
            "('24,paper', 'review') p= 1.0\n",
            "('review', 'process') p= 0.2\n",
            "('process', 'involved') p= 0.09090909090909091\n",
            "('involved', 'natural') p= 1.0\n",
            "('nlp', 'demonstrates') p= 0.027777777777777776\n",
            "('demonstrates', 'various') p= 1.0\n",
            "('various', 'kind') p= 0.14285714285714285\n",
            "('kind', 'choice') p= 0.3333333333333333\n",
            "('choice', 'need') p= 1.0\n",
            "('need', 'taken') p= 0.16666666666666666\n",
            "('taken', 'execution') p= 0.5\n",
            "('execution', 'word') p= 0.5\n",
            "('word', 'morphology') p= 0.07142857142857142\n",
            "('morphology', 'syntactic') p= 1.0\n",
            "('syntactic', 'text') p= 0.2\n",
            "('text', 'analysis') p= 0.15384615384615385\n",
            "('analysis', 'text') p= 0.18181818181818182\n",
            "('text', 'generation') p= 0.15384615384615385\n",
            "('generation', 'component') p= 0.25\n",
            "('component', 'compare') p= 0.25\n",
            "('compare', 'time') p= 0.5\n",
            "('time', 'complexity') p= 0.5\n",
            "('complexity', 'traditional') p= 0.2\n",
            "('traditional', '25,article') p= 0.3333333333333333\n",
            "('25,article', 'focus') p= 1.0\n",
            "('focus', 'derivation') p= 0.14285714285714285\n",
            "('derivation', 'large') p= 1.0\n",
            "('large', 'lexicon') p= 0.3333333333333333\n",
            "('lexicon', 'natural') p= 1.0\n",
            "('processing', 'describe') p= 0.015151515151515152\n",
            "('describe', 'development') p= 0.3333333333333333\n",
            "('development', 'dictionary') p= 0.1111111111111111\n",
            "('dictionary', 'support') p= 0.25\n",
            "('support', 'environment') p= 0.25\n",
            "('environment', 'linking') p= 0.5\n",
            "('linking', 'restructured') p= 1.0\n",
            "('restructured', 'version') p= 1.0\n",
            "('version', 'longman') p= 0.5\n",
            "('longman', 'dictionary') p= 1.0\n",
            "('dictionary', 'contemporary') p= 0.25\n",
            "('contemporary', 'english') p= 1.0\n",
            "('english', 'natural') p= 0.5\n",
            "('system', 'process') p= 0.07692307692307693\n",
            "('process', 'restruc') p= 0.09090909090909091\n",
            "('restruc', '26,introduce') p= 1.0\n",
            "('26,introduce', 'method') p= 1.0\n",
            "('method', 'analyzing') p= 0.14285714285714285\n",
            "('analyzing', 'complexity') p= 0.5\n",
            "('complexity', 'natural') p= 0.2\n",
            "('task', 'predicting') p= 0.0625\n",
            "('predicting', 'difficulty') p= 1.0\n",
            "('difficulty', 'new') p= 1.0\n",
            "('new', 'nlp') p= 0.125\n",
            "('nlp', 'task') p= 0.1111111111111111\n",
            "('task', 'complexity') p= 0.0625\n",
            "('complexity', 'measure') p= 0.2\n",
            "('measure', 'derived') p= 0.3333333333333333\n",
            "('derived', 'kolmogorov') p= 1.0\n",
            "('kolmogorov', 'complexity') p= 1.0\n",
            "('complexity', 'class') p= 0.2\n",
            "('class', 'automaton') p= 0.3333333333333333\n",
            "('automaton', 'meaning') p= 0.5\n",
            "('meaning', 'automaton') p= 0.25\n",
            "('automaton', 'whose') p= 0.5\n",
            "('whose', 'purpose') p= 0.5\n",
            "('purpose', 'extract') p= 0.2\n",
            "('extract', 'relevant') p= 0.5\n",
            "('relevant', 'piece') p= 0.5\n",
            "('piece', 'infor') p= 1.0\n",
            "('infor', '27,deep') p= 1.0\n",
            "('27,deep', 'learning') p= 1.0\n",
            "('learning', 'emerged') p= 0.05\n",
            "('emerged', 'new') p= 0.5\n",
            "('new', 'area') p= 0.125\n",
            "('area', 'machine') p= 0.16666666666666666\n",
            "('learning', 'research') p= 0.05\n",
            "('research', 'try') p= 0.125\n",
            "('try', 'mimic') p= 0.5\n",
            "('mimic', 'human') p= 1.0\n",
            "('human', 'brain') p= 0.16666666666666666\n",
            "('brain', 'capable') p= 0.5\n",
            "('capable', 'processing') p= 1.0\n",
            "('processing', 'learning') p= 0.015151515151515152\n",
            "('learning', 'complex') p= 0.05\n",
            "('complex', 'input') p= 0.3333333333333333\n",
            "('input', 'data') p= 0.3333333333333333\n",
            "('data', 'solving') p= 0.1111111111111111\n",
            "('solving', 'different') p= 1.0\n",
            "('different', 'kind') p= 0.16666666666666666\n",
            "('kind', 'complicated') p= 0.3333333333333333\n",
            "('complicated', 'task') p= 1.0\n",
            "('task', 'well') p= 0.0625\n",
            "('well', 'successfully') p= 0.3333333333333333\n",
            "('successfully', 'applied') p= 1.0\n",
            "('applied', 'several') p= 0.25\n",
            "('several', 'field') p= 0.25\n",
            "('field', 'image') p= 0.1111111111111111\n",
            "('image', '28,authorproduced') p= 0.5\n",
            "('28,authorproduced', 'version') p= 1.0\n",
            "('version', 'paper') p= 0.5\n",
            "('paper', 'published') p= 0.2\n",
            "('published', '29,abstractnatural') p= 0.5\n",
            "('29,abstractnatural', 'language') p= 1.0\n",
            "('nlp', 'application') p= 0.027777777777777776\n",
            "('application', 'automated') p= 0.058823529411764705\n",
            "('automated', 'parsing') p= 0.2\n",
            "('parsing', 'machine') p= 0.14285714285714285\n",
            "('learning', 'technique') p= 0.1\n",
            "('technique', 'analyze') p= 0.09090909090909091\n",
            "('analyze', 'standard') p= 0.5\n",
            "('standard', 'text') p= 0.3333333333333333\n",
            "('text', 'application') p= 0.07692307692307693\n",
            "('application', 'nlp') p= 0.11764705882352941\n",
            "('nlp', 'requirement') p= 0.027777777777777776\n",
            "('requirement', 'engineering') p= 0.2\n",
            "('engineering', 'include') p= 0.5\n",
            "('include', 'extraction') p= 0.5\n",
            "('extraction', 'ontology') p= 0.2\n",
            "('ontology', 'requirement') p= 0.5\n",
            "('requirement', 'specification') p= 0.2\n",
            "('specification', 'use') p= 1.0\n",
            "('use', 'nlp') p= 0.1\n",
            "('nlp', 'verify') p= 0.027777777777777776\n",
            "('verify', 'consistency') p= 1.0\n",
            "('consistency', '30,information') p= 1.0\n",
            "('30,information', 'retrieval') p= 1.0\n",
            "('retrieval', 'address') p= 0.08333333333333333\n",
            "('address', 'problem') p= 0.3333333333333333\n",
            "('problem', 'finding') p= 0.25\n",
            "('finding', 'document') p= 0.6666666666666666\n",
            "('document', 'whose') p= 0.07692307692307693\n",
            "('whose', 'content') p= 0.5\n",
            "('content', 'match') p= 0.5\n",
            "('match', 'useraposs') p= 1.0\n",
            "('useraposs', 'request') p= 1.0\n",
            "('request', 'among') p= 1.0\n",
            "('among', 'large') p= 0.25\n",
            "('large', 'collection') p= 0.3333333333333333\n",
            "('collection', 'document') p= 0.3333333333333333\n",
            "('document', 'currently') p= 0.07692307692307693\n",
            "('currently', 'successful') p= 0.3333333333333333\n",
            "('successful', 'general') p= 1.0\n",
            "('general', 'purpose') p= 0.25\n",
            "('purpose', 'retrieval') p= 0.2\n",
            "('retrieval', 'method') p= 0.08333333333333333\n",
            "('method', 'statistical') p= 0.14285714285714285\n",
            "('statistical', 'method') p= 0.2\n",
            "('method', 'treat') p= 0.14285714285714285\n",
            "('treat', 'text') p= 1.0\n",
            "('text', 'little') p= 0.07692307692307693\n",
            "('little', 'bag') p= 0.5\n",
            "('bag', 'w') p= 1.0\n",
            "('w', '31,work') p= 0.5\n",
            "('31,work', 'computational') p= 1.0\n",
            "('computational', 'linguistics') p= 0.2857142857142857\n",
            "('linguistics', 'began') p= 0.2\n",
            "('began', 'soon') p= 1.0\n",
            "('soon', 'development') p= 1.0\n",
            "('development', 'first') p= 0.1111111111111111\n",
            "('first', 'computer') p= 0.3333333333333333\n",
            "('computer', 'booth') p= 0.2\n",
            "('booth', 'brandwood') p= 1.0\n",
            "('brandwood', 'cleave') p= 1.0\n",
            "('cleave', 'yet') p= 1.0\n",
            "('yet', 'intervening') p= 0.5\n",
            "('intervening', 'four') p= 1.0\n",
            "('four', 'decade') p= 1.0\n",
            "('decade', 'pervasive') p= 1.0\n",
            "('pervasive', 'feeling') p= 1.0\n",
            "('feeling', 'progress') p= 1.0\n",
            "('progress', 'computer') p= 1.0\n",
            "('computer', 'understanding') p= 0.2\n",
            "('understanding', 'natural') p= 0.125\n",
            "('language', 'commensurate') p= 0.010309278350515464\n",
            "('commensurate', 'progres') p= 1.0\n",
            "('progres', '32,abstracta') p= 1.0\n",
            "('32,abstracta', 'system') p= 1.0\n",
            "('system', 'recognizes') p= 0.038461538461538464\n",
            "('recognizes', 'authenticates') p= 1.0\n",
            "('authenticates', 'voice') p= 1.0\n",
            "('voice', 'user') p= 0.2\n",
            "('user', 'extracting') p= 0.3333333333333333\n",
            "('extracting', 'distinct') p= 1.0\n",
            "('distinct', 'feature') p= 1.0\n",
            "('feature', 'voice') p= 0.125\n",
            "('voice', 'sample') p= 0.2\n",
            "('sample', 'usually') p= 0.5\n",
            "('usually', 'termed') p= 0.5\n",
            "('termed', 'voice') p= 1.0\n",
            "('voice', 'recognition') p= 0.2\n",
            "('recognition', 'system') p= 0.09090909090909091\n",
            "('system', 'voice') p= 0.038461538461538464\n",
            "('voice', 'identification') p= 0.2\n",
            "('identification', 'carried') p= 1.0\n",
            "('carried', 'converting') p= 1.0\n",
            "('converting', 'human') p= 1.0\n",
            "('human', 'voice') p= 0.16666666666666666\n",
            "('voice', 'digital') p= 0.2\n",
            "('digital', 'data') p= 1.0\n",
            "('data', 'digitized') p= 0.1111111111111111\n",
            "('digitized', 'audio') p= 1.0\n",
            "('audio', 'sample') p= 0.5\n",
            "('sample', 'unde') p= 0.5\n",
            "('unde', '33,abstract') p= 1.0\n",
            "('33,abstract', 'testing') p= 1.0\n",
            "('testing', 'natural') p= 0.5\n",
            "('language', 'requirement') p= 0.010309278350515464\n",
            "('requirement', 'standard') p= 0.2\n",
            "('standard', 'approach') p= 0.3333333333333333\n",
            "('approach', 'system') p= 0.07692307692307693\n",
            "('system', 'acceptance') p= 0.038461538461538464\n",
            "('acceptance', 'testing') p= 1.0\n",
            "('testing', 'test') p= 0.5\n",
            "('test', 'often') p= 0.5\n",
            "('often', 'performed') p= 0.5\n",
            "('performed', 'independent') p= 1.0\n",
            "('independent', 'test') p= 0.5\n",
            "('test', 'organization') p= 0.5\n",
            "('organization', 'unfamiliar') p= 0.5\n",
            "('unfamiliar', 'application') p= 1.0\n",
            "('application', 'area') p= 0.058823529411764705\n",
            "('area', 'thing') p= 0.16666666666666666\n",
            "('thing', 'tester') p= 1.0\n",
            "('tester', 'go') p= 1.0\n",
            "('go', 'written') p= 0.5\n",
            "('written', 'requirement') p= 1.0\n",
            "('requirement', '34,') p= 0.2\n",
            "('34,', '35,algorithm') p= 1.0\n",
            "('35,algorithm', 'allow') p= 1.0\n",
            "('allow', 'understanding') p= 1.0\n",
            "('understanding', 'generation') p= 0.125\n",
            "('generation', 'humor') p= 0.25\n",
            "('humor', 'general') p= 0.5\n",
            "('general', 'aim') p= 0.25\n",
            "('aim', 'modeling') p= 0.5\n",
            "('modeling', 'humor') p= 0.5\n",
            "('humor', 'provide') p= 0.5\n",
            "('provide', 'u') p= 0.5\n",
            "('u', 'lot') p= 0.3333333333333333\n",
            "('lot', 'information') p= 1.0\n",
            "('information', 'cognitive') p= 0.05555555555555555\n",
            "('cognitive', 'ability') p= 1.0\n",
            "('ability', 'general') p= 0.3333333333333333\n",
            "('general', 'reasoning') p= 0.25\n",
            "('reasoning', 'remembering') p= 0.5\n",
            "('remembering', 'understanding') p= 1.0\n",
            "('understanding', 'situation') p= 0.125\n",
            "('situation', 'understanding') p= 0.5\n",
            "('understanding', 'conversati') p= 0.125\n",
            "('conversati', '36,') p= 1.0\n",
            "('36,', '37,recent') p= 1.0\n",
            "('37,recent', 'year') p= 1.0\n",
            "('year', 'machine') p= 0.14285714285714285\n",
            "('learning', 'ml') p= 0.1\n",
            "('ml', 'used') p= 0.5\n",
            "('used', 'solve') p= 0.09090909090909091\n",
            "('solve', 'complex') p= 0.5\n",
            "('complex', 'task') p= 0.3333333333333333\n",
            "('task', 'different') p= 0.0625\n",
            "('different', 'discipline') p= 0.16666666666666666\n",
            "('discipline', 'ranging') p= 0.25\n",
            "('ranging', 'data') p= 0.5\n",
            "('data', 'mining') p= 0.1111111111111111\n",
            "('mining', 'information') p= 1.0\n",
            "('information', '38,argue') p= 0.05555555555555555\n",
            "('38,argue', 'manual') p= 1.0\n",
            "('manual', 'automatic') p= 0.3333333333333333\n",
            "('automatic', 'thesaurus') p= 1.0\n",
            "('thesaurus', 'alternative') p= 0.3333333333333333\n",
            "('alternative', 'resource') p= 1.0\n",
            "('resource', 'nlp') p= 0.2\n",
            "('task', 'involves') p= 0.0625\n",
            "('involves', 'radical') p= 0.5\n",
            "('radical', 'step') p= 1.0\n",
            "('step', 'interpreting') p= 1.0\n",
            "('interpreting', 'manual') p= 1.0\n",
            "('manual', 'thesaurus') p= 0.3333333333333333\n",
            "('thesaurus', 'classification') p= 0.3333333333333333\n",
            "('classification', 'word') p= 0.5\n",
            "('word', 'rather') p= 0.07142857142857142\n",
            "('rather', 'word') p= 0.5\n",
            "('word', 'sens') p= 0.07142857142857142\n",
            "('sens', 'case') p= 0.5\n",
            "('case', 'made') p= 0.5\n",
            "('made', 'range') p= 1.0\n",
            "('range', 'role') p= 0.2\n",
            "('role', 'thesaurus') p= 0.25\n",
            "('thesaurus', 'within') p= 0.3333333333333333\n",
            "('within', 'nlp') p= 0.3333333333333333\n",
            "('nlp', 'briefly') p= 0.027777777777777776\n",
            "('briefly', '39,introduction') p= 0.3333333333333333\n",
            "('39,introduction', 'pattern') p= 1.0\n",
            "('pattern', 'music') p= 0.25\n",
            "('music', 'object') p= 0.3333333333333333\n",
            "('object', 'intensive') p= 0.3333333333333333\n",
            "('intensive', 'study') p= 1.0\n",
            "('study', 'past') p= 0.25\n",
            "('past', 'year') p= 1.0\n",
            "('year', 'one') p= 0.14285714285714285\n",
            "('one', 'purpose') p= 0.14285714285714285\n",
            "('purpose', 'analyzing') p= 0.2\n",
            "('analyzing', 'musical') p= 0.5\n",
            "('musical', 'structure') p= 0.5\n",
            "('structure', 'form') p= 0.2\n",
            "('form', 'discover') p= 0.3333333333333333\n",
            "('discover', 'pattern') p= 1.0\n",
            "('pattern', 'explicit') p= 0.25\n",
            "('explicit', 'implicit') p= 1.0\n",
            "('implicit', 'musical') p= 1.0\n",
            "('musical', 'work') p= 0.5\n",
            "('work', 'simon') p= 0.125\n",
            "('simon', 'pattern') p= 1.0\n",
            "('pattern', 'comprise') p= 0.25\n",
            "('comprise', 'periodicity') p= 1.0\n",
            "('periodicity', 'make') p= 1.0\n",
            "('use', 'alphabet') p= 0.1\n",
            "('alphabet', '40,abstract') p= 1.0\n",
            "('40,abstract', 'many') p= 1.0\n",
            "('many', 'information') p= 0.2\n",
            "('information', 'retrievalir') p= 0.05555555555555555\n",
            "('retrievalir', 'system') p= 1.0\n",
            "('system', 'retrieve') p= 0.038461538461538464\n",
            "('retrieve', 'relevant') p= 1.0\n",
            "('relevant', 'document') p= 0.5\n",
            "('document', 'based') p= 0.07692307692307693\n",
            "('based', 'exact') p= 0.25\n",
            "('exact', 'matching') p= 1.0\n",
            "('matching', 'keywords') p= 0.5\n",
            "('keywords', 'query') p= 1.0\n",
            "('query', 'document') p= 1.0\n",
            "('document', 'method') p= 0.07692307692307693\n",
            "('method', 'degrades') p= 0.14285714285714285\n",
            "('degrades', 'precision') p= 1.0\n",
            "('precision', 'rate') p= 1.0\n",
            "('rate', 'order') p= 1.0\n",
            "('order', 'solve') p= 1.0\n",
            "('solve', 'problem') p= 0.5\n",
            "('problem', 'collected') p= 0.25\n",
            "('collected', 'semantically') p= 1.0\n",
            "('semantically', 'related') p= 0.5\n",
            "('related', 'word') p= 0.3333333333333333\n",
            "('word', 'assigned') p= 0.07142857142857142\n",
            "('assigned', 'semantic') p= 1.0\n",
            "('semantic', 'relationship') p= 0.14285714285714285\n",
            "('relationship', 'used') p= 0.5\n",
            "('used', 'gener') p= 0.09090909090909091\n",
            "('gener', '41,paper') p= 1.0\n",
            "('41,paper', 'argue') p= 1.0\n",
            "('argue', 'questionanswering') p= 1.0\n",
            "('questionanswering', 'qa') p= 1.0\n",
            "('qa', 'technical') p= 0.3333333333333333\n",
            "('technical', 'domain') p= 1.0\n",
            "('domain', 'distinctly') p= 0.1111111111111111\n",
            "('distinctly', 'different') p= 1.0\n",
            "('different', 'trecbased') p= 0.16666666666666666\n",
            "('trecbased', 'qa') p= 1.0\n",
            "('qa', 'webbased') p= 0.3333333333333333\n",
            "('webbased', 'qa') p= 0.5\n",
            "('qa', 'cannot') p= 0.3333333333333333\n",
            "('cannot', 'benefit') p= 1.0\n",
            "('benefit', 'lom') p= 0.5\n",
            "('lom', 'dataintensive') p= 1.0\n",
            "('dataintensive', 'approach') p= 1.0\n",
            "('approach', '42,universitquotat') p= 0.07692307692307693\n",
            "('42,universitquotat', 'de') p= 1.0\n",
            "('de', 'saarlandes') p= 0.25\n",
            "('saarlandes', '43,proceeding') p= 1.0\n",
            "('43,proceeding', 'workshop') p= 1.0\n",
            "('workshop', '44,unihamburgde') p= 1.0\n",
            "('44,unihamburgde', '45,') p= 1.0\n",
            "('45,', '46,') p= 1.0\n",
            "('46,', '47,sri') p= 1.0\n",
            "('47,sri', 'developed') p= 1.0\n",
            "('developed', 'new') p= 0.5\n",
            "('new', 'architecture') p= 0.125\n",
            "('architecture', 'integrating') p= 0.2\n",
            "('integrating', 'speech') p= 0.5\n",
            "('speech', 'naturallanguage') p= 0.14285714285714285\n",
            "('naturallanguage', 'processing') p= 1.0\n",
            "('processing', 'applies') p= 0.015151515151515152\n",
            "('applies', 'linguistic') p= 1.0\n",
            "('linguistic', 'constraint') p= 0.125\n",
            "('constraint', 'recognition') p= 1.0\n",
            "('recognition', 'incrementally') p= 0.09090909090909091\n",
            "('incrementally', 'expanding') p= 1.0\n",
            "('expanding', 'statetransition') p= 1.0\n",
            "('statetransition', 'network') p= 1.0\n",
            "('network', 'embodied') p= 0.2\n",
            "('embodied', 'unification') p= 1.0\n",
            "('unification', 'grammar') p= 1.0\n",
            "('grammar', 'compare') p= 0.25\n",
            "('compare', 'dynamicgralnlnarnetwork') p= 0.5\n",
            "('dynamicgralnlnarnetwork', 'dgn') p= 1.0\n",
            "('dgn', 'approach') p= 1.0\n",
            "('approach', '48,chapter') p= 0.07692307692307693\n",
            "('48,chapter', 'considers') p= 1.0\n",
            "('considers', 'revolution') p= 0.5\n",
            "('revolution', 'taken') p= 1.0\n",
            "('taken', 'place') p= 0.5\n",
            "('place', 'natural') p= 1.0\n",
            "('processing', 'research') p= 0.015151515151515152\n",
            "('research', 'last') p= 0.125\n",
            "('last', 'five') p= 0.3333333333333333\n",
            "('five', 'year') p= 1.0\n",
            "('year', 'begin') p= 0.14285714285714285\n",
            "('begin', 'providing') p= 1.0\n",
            "('providing', 'brief') p= 0.5\n",
            "('brief', 'guide') p= 0.3333333333333333\n",
            "('guide', 'structure') p= 1.0\n",
            "('structure', 'field') p= 0.2\n",
            "('field', 'present') p= 0.1111111111111111\n",
            "('present', 'caricature') p= 0.14285714285714285\n",
            "('caricature', 'two') p= 1.0\n",
            "('two', 'competing') p= 0.14285714285714285\n",
            "('competing', 'paradigm') p= 1.0\n",
            "('paradigm', 's') p= 0.5\n",
            "('s', 'nlp') p= 1.0\n",
            "('nlp', 'research') p= 0.05555555555555555\n",
            "('research', 'indicates') p= 0.125\n",
            "('indicates', 'reason') p= 1.0\n",
            "('reason', 'wh') p= 1.0\n",
            "('wh', '49,visual') p= 1.0\n",
            "('49,visual', 'development') p= 1.0\n",
            "('development', 'environment') p= 0.1111111111111111\n",
            "('environment', 'support') p= 0.5\n",
            "('support', 'visual') p= 0.25\n",
            "('visual', 'assembly') p= 0.5\n",
            "('assembly', 'execution') p= 1.0\n",
            "('execution', 'analysis') p= 0.5\n",
            "('analysis', 'modular') p= 0.09090909090909091\n",
            "('modular', 'natural') p= 1.0\n",
            "('system', 'visual') p= 0.038461538461538464\n",
            "('visual', 'model') p= 0.5\n",
            "('model', 'executable') p= 0.125\n",
            "('executable', 'data') p= 1.0\n",
            "('data', 'flow') p= 0.1111111111111111\n",
            "('flow', 'program') p= 1.0\n",
            "('program', 'graph') p= 0.3333333333333333\n",
            "('graph', 'automatically') p= 0.5\n",
            "('automatically', 'synthesised') p= 1.0\n",
            "('synthesised', 'data') p= 1.0\n",
            "('data', 'dependency') p= 0.1111111111111111\n",
            "('dependency', 'declaration') p= 1.0\n",
            "('declaration', 'language') p= 1.0\n",
            "('processing', 'module') p= 0.015151515151515152\n",
            "('module', 'graph') p= 1.0\n",
            "('graph', 'th') p= 0.5\n",
            "('th', '50,chapter') p= 0.3333333333333333\n",
            "('50,chapter', 'basic') p= 1.0\n",
            "('basic', 'us') p= 0.25\n",
            "('us', 'description') p= 0.5\n",
            "('logic', 'natural') p= 0.125\n",
            "('processing', 'analysed') p= 0.015151515151515152\n",
            "('analysed', 'together') p= 1.0\n",
            "('together', 'little') p= 1.0\n",
            "('little', 'bit') p= 0.5\n",
            "('bit', 'history') p= 1.0\n",
            "('history', 'role') p= 0.2\n",
            "('role', 'description') p= 0.25\n",
            "('logic', 'current') p= 0.125\n",
            "('state', 'art') p= 0.5\n",
            "('art', 'computational') p= 1.0\n",
            "('linguistics', 'pointed') p= 0.2\n",
            "('pointed', 'introduction') p= 1.0\n",
            "('introduction', 'since') p= 0.5\n",
            "('since', 'early') p= 1.0\n",
            "('early', 'day') p= 1.0\n",
            "('day', '51,applied') p= 1.0\n",
            "('51,applied', 'structure') p= 1.0\n",
            "('structure', 'learning') p= 0.2\n",
            "('learning', 'model') p= 0.05\n",
            "('model', 'maxmargin') p= 0.125\n",
            "('maxmargin', 'structure') p= 1.0\n",
            "('structure', 'mm') p= 0.2\n",
            "('mm', 'natural') p= 1.0\n",
            "('task', 'aim') p= 0.0625\n",
            "('aim', 'capture') p= 0.5\n",
            "('capture', 'latent') p= 0.3333333333333333\n",
            "('latent', 'relationship') p= 1.0\n",
            "('relationship', 'within') p= 0.5\n",
            "('within', 'output') p= 0.3333333333333333\n",
            "('output', 'language') p= 0.25\n",
            "('language', 'domain') p= 0.020618556701030927\n",
            "('domain', 'formulate') p= 0.1111111111111111\n",
            "('formulate', 'model') p= 1.0\n",
            "('model', 'extension') p= 0.125\n",
            "('extension', 'multiclass') p= 1.0\n",
            "('multiclass', 'support') p= 1.0\n",
            "('support', 'vector') p= 0.25\n",
            "('vector', 'machine') p= 1.0\n",
            "('machine', 'svm') p= 0.06666666666666667\n",
            "('svm', 'present') p= 1.0\n",
            "('present', 'per') p= 0.14285714285714285\n",
            "('per', '52,vast') p= 0.5\n",
            "('52,vast', 'quantity') p= 1.0\n",
            "('quantity', 'text') p= 0.5\n",
            "('text', 'becoming') p= 0.07692307692307693\n",
            "('becoming', 'available') p= 1.0\n",
            "('available', 'electronic') p= 0.5\n",
            "('electronic', 'form') p= 0.5\n",
            "('form', 'ranging') p= 0.3333333333333333\n",
            "('ranging', 'published') p= 0.5\n",
            "('published', 'document') p= 0.5\n",
            "('document', 'eg') p= 0.07692307692307693\n",
            "('eg', 'electronic') p= 0.5\n",
            "('electronic', 'dictionary') p= 0.5\n",
            "('dictionary', 'encyclopedia') p= 0.25\n",
            "('encyclopedia', 'library') p= 1.0\n",
            "('library', 'archive') p= 1.0\n",
            "('archive', 'information') p= 1.0\n",
            "('retrieval', 'service') p= 0.08333333333333333\n",
            "('service', 'private') p= 1.0\n",
            "('private', 'database') p= 1.0\n",
            "('database', 'eg') p= 1.0\n",
            "('eg', 'marketing') p= 0.5\n",
            "('marketing', 'information') p= 1.0\n",
            "('information', 'legal') p= 0.05555555555555555\n",
            "('legal', 'record') p= 1.0\n",
            "('record', 'medical') p= 1.0\n",
            "('medical', 'history') p= 0.5\n",
            "('history', 'per') p= 0.2\n",
            "('per', '53,last') p= 0.5\n",
            "('53,last', 'year') p= 1.0\n",
            "('year', 'number') p= 0.14285714285714285\n",
            "('number', 'area') p= 0.25\n",
            "('area', 'natural') p= 0.16666666666666666\n",
            "('processing', 'begun') p= 0.015151515151515152\n",
            "('begun', 'applying') p= 1.0\n",
            "('applying', 'graphbased') p= 0.5\n",
            "('graphbased', 'technique') p= 1.0\n",
            "('technique', 'include') p= 0.09090909090909091\n",
            "('include', 'among') p= 0.5\n",
            "('among', 'others') p= 0.25\n",
            "('others', 'text') p= 1.0\n",
            "('text', 'summarization') p= 0.07692307692307693\n",
            "('summarization', 'syntactic') p= 1.0\n",
            "('syntactic', 'parsing') p= 0.2\n",
            "('parsing', 'word') p= 0.2857142857142857\n",
            "('word', 'sense') p= 0.14285714285714285\n",
            "('sense', 'disambiguation') p= 0.5\n",
            "('disambiguation', 'ontology') p= 0.5\n",
            "('ontology', 'construction') p= 0.5\n",
            "('construction', 'sentiment') p= 0.5\n",
            "('sentiment', 'subjectivity') p= 1.0\n",
            "('subjectivity', 'analysis') p= 1.0\n",
            "('text', 'clustering') p= 0.07692307692307693\n",
            "('clustering', 'pa') p= 1.0\n",
            "('pa', '54,natural') p= 1.0\n",
            "('54,natural', 'language') p= 1.0\n",
            "('research', 'result') p= 0.125\n",
            "('result', 'software') p= 0.16666666666666666\n",
            "('software', 'engineering') p= 0.2\n",
            "('engineering', 'software') p= 0.5\n",
            "('software', 'technology') p= 0.2\n",
            "('technology', 'often') p= 0.25\n",
            "('often', 'neglected') p= 0.5\n",
            "('neglected', '55,kernelized') p= 1.0\n",
            "('55,kernelized', 'sorting') p= 1.0\n",
            "('sorting', 'approach') p= 1.0\n",
            "('approach', 'matching') p= 0.07692307692307693\n",
            "('matching', 'object') p= 0.5\n",
            "('object', 'two') p= 0.3333333333333333\n",
            "('two', 'source') p= 0.2857142857142857\n",
            "('source', 'domain') p= 0.25\n",
            "('domain', 'require') p= 0.1111111111111111\n",
            "('require', 'prior') p= 1.0\n",
            "('prior', 'notion') p= 1.0\n",
            "('notion', 'similarity') p= 1.0\n",
            "('similarity', 'object') p= 0.3333333333333333\n",
            "('object', 'across') p= 0.3333333333333333\n",
            "('across', 'two') p= 1.0\n",
            "('source', 'unfortunately') p= 0.25\n",
            "('unfortunately', 'technique') p= 0.5\n",
            "('technique', 'highly') p= 0.09090909090909091\n",
            "('highly', 'sensitive') p= 1.0\n",
            "('sensitive', 'initialization') p= 0.3333333333333333\n",
            "('initialization', 'high') p= 1.0\n",
            "('high', 'dimensional') p= 0.3333333333333333\n",
            "('dimensional', 'data') p= 1.0\n",
            "('data', 'present') p= 0.1111111111111111\n",
            "('present', 'variant') p= 0.14285714285714285\n",
            "('variant', 'kern') p= 1.0\n",
            "('kern', '56,natural') p= 1.0\n",
            "('56,natural', 'language') p= 1.0\n",
            "('language', 'complex') p= 0.010309278350515464\n",
            "('complex', 'compound') p= 0.3333333333333333\n",
            "('compound', 'organization') p= 1.0\n",
            "('organization', 'structure') p= 0.5\n",
            "('structure', 'basic') p= 0.2\n",
            "('basic', 'linguistic') p= 0.25\n",
            "('linguistic', 'element') p= 0.125\n",
            "('element', 'represent') p= 0.25\n",
            "('represent', 'various') p= 1.0\n",
            "('various', 'meaning') p= 0.14285714285714285\n",
            "('meaning', 'therefore') p= 0.25\n",
            "('therefore', 'understand') p= 0.5\n",
            "('understand', 'nature') p= 0.5\n",
            "('nature', 'natural') p= 1.0\n",
            "('need', 'sophisticated') p= 0.16666666666666666\n",
            "('sophisticated', 'treatment') p= 1.0\n",
            "('treatment', 'basic') p= 1.0\n",
            "('basic', 'element') p= 0.25\n",
            "('element', 'well') p= 0.25\n",
            "('well', 'insight') p= 0.3333333333333333\n",
            "('insight', 'element') p= 0.5\n",
            "('element', '57,paper') p= 0.25\n",
            "('57,paper', 'describe') p= 1.0\n",
            "('describe', 'framework') p= 0.3333333333333333\n",
            "('framework', 'developing') p= 0.3333333333333333\n",
            "('developing', 'probabilistic') p= 1.0\n",
            "('probabilistic', 'classifier') p= 0.5\n",
            "('classifier', 'natural') p= 1.0\n",
            "('processing', 'focus') p= 0.015151515151515152\n",
            "('focus', 'formulating') p= 0.14285714285714285\n",
            "('formulating', 'model') p= 1.0\n",
            "('model', 'capture') p= 0.125\n",
            "('capture', 'important') p= 0.3333333333333333\n",
            "('important', 'interdependency') p= 0.3333333333333333\n",
            "('interdependency', 'among') p= 1.0\n",
            "('among', 'feature') p= 0.25\n",
            "('feature', 'avoid') p= 0.125\n",
            "('avoid', 'overfitting') p= 0.5\n",
            "('overfitting', 'data') p= 1.0\n",
            "('data', 'also') p= 0.1111111111111111\n",
            "('also', 'characterizing') p= 0.25\n",
            "('characterizing', 'data') p= 1.0\n",
            "('data', 'well') p= 0.1111111111111111\n",
            "('well', 'class') p= 0.3333333333333333\n",
            "('class', 'pro') p= 0.3333333333333333\n",
            "('pro', '58,many') p= 1.0\n",
            "('58,many', 'natural') p= 1.0\n",
            "('nlp', 'technique') p= 0.027777777777777776\n",
            "('technique', 'used') p= 0.09090909090909091\n",
            "('used', 'information') p= 0.09090909090909091\n",
            "('retrieval', 'result') p= 0.08333333333333333\n",
            "('result', 'encouraging') p= 0.16666666666666666\n",
            "('encouraging', 'simple') p= 1.0\n",
            "('simple', 'method') p= 0.3333333333333333\n",
            "('method', 'stopwording') p= 0.14285714285714285\n",
            "('stopwording', 'porterstyle') p= 1.0\n",
            "('porterstyle', 'stemming') p= 1.0\n",
            "('stemming', 'etc') p= 1.0\n",
            "('etc', 'usually') p= 1.0\n",
            "('usually', 'yield') p= 0.5\n",
            "('yield', 'significant') p= 1.0\n",
            "('significant', 'improvement') p= 0.25\n",
            "('improvement', 'higherlevel') p= 0.25\n",
            "('higherlevel', 'processing') p= 1.0\n",
            "('processing', 'chunking') p= 0.015151515151515152\n",
            "('chunking', 'parsing') p= 0.5\n",
            "('disambiguation', 'e') p= 0.5\n",
            "('e', '59,abstract') p= 0.5\n",
            "('59,abstract', 'paper') p= 1.0\n",
            "('paper', 'explains') p= 0.2\n",
            "('explains', 'information') p= 1.0\n",
            "('retrieval', 'using') p= 0.08333333333333333\n",
            "('processing', 'malayalam') p= 0.015151515151515152\n",
            "('malayalam', 'language') p= 1.0\n",
            "('language', 'basic') p= 0.010309278350515464\n",
            "('basic', '60,research') p= 0.25\n",
            "('60,research', 'area') p= 1.0\n",
            "('area', 'plan') p= 0.3333333333333333\n",
            "('plan', 'recognition') p= 1.0\n",
            "('recognition', 'natural') p= 0.18181818181818182\n",
            "('language', 'parsing') p= 0.020618556701030927\n",
            "('parsing', 'share') p= 0.2857142857142857\n",
            "('share', 'many') p= 1.0\n",
            "('many', 'common') p= 0.4\n",
            "('common', 'feature') p= 1.0\n",
            "('feature', 'even') p= 0.25\n",
            "('even', 'algorithm') p= 0.6666666666666666\n",
            "('algorithm', 'however') p= 0.5\n",
            "('however', 'dialog') p= 0.4\n",
            "('dialog', 'two') p= 1.0\n",
            "('two', 'discipline') p= 0.2857142857142857\n",
            "('discipline', 'effective') p= 0.5\n",
            "('effective', 'specifically') p= 0.2857142857142857\n",
            "('specifically', 'significant') p= 1.0\n",
            "('significant', 'recent') p= 0.5\n",
            "('recent', 'result') p= 1.0\n",
            "('result', 'parsing') p= 0.3333333333333333\n",
            "('parsing', 'mildly') p= 0.2857142857142857\n",
            "('mildly', 'context') p= 1.0\n",
            "('context', 'sensitive') p= 0.5\n",
            "('sensitive', 'grammar') p= 0.6666666666666666\n",
            "('grammar', 'leveraged') p= 0.5\n",
            "('leveraged', '61,research') p= 0.5\n",
            "('61,research', 'area') p= 1.0\n",
            "('leveraged', '62,information') p= 0.5\n",
            "('62,information', 'retrieval') p= 1.0\n",
            "('retrieval', 'process') p= 0.08333333333333333\n",
            "('process', 'finding') p= 0.09090909090909091\n",
            "('document', 'document') p= 0.07692307692307693\n",
            "('document', 'collection') p= 0.07692307692307693\n",
            "('collection', 'satisfies') p= 0.3333333333333333\n",
            "('satisfies', 'information') p= 1.0\n",
            "('information', 'need') p= 0.05555555555555555\n",
            "('need', 'user') p= 0.16666666666666666\n",
            "('user', 'document') p= 0.3333333333333333\n",
            "('document', 'natural') p= 0.07692307692307693\n",
            "('language', 'construct') p= 0.010309278350515464\n",
            "('construct', 'motivation') p= 0.3333333333333333\n",
            "('motivation', 'work') p= 1.0\n",
            "('work', 'investigate') p= 0.125\n",
            "('investigate', 'natural') p= 1.0\n",
            "('processing', 'used') p= 0.015151515151515152\n",
            "('used', 'improve') p= 0.09090909090909091\n",
            "('improve', 'performa') p= 1.0\n",
            "('performa', '63,computational') p= 1.0\n",
            "('63,computational', 'logic') p= 1.0\n",
            "('logic', 'become') p= 0.125\n",
            "('become', 'widely') p= 0.3333333333333333\n",
            "('widely', 'used') p= 1.0\n",
            "('used', 'representing') p= 0.09090909090909091\n",
            "('representing', 'reasoning') p= 0.5\n",
            "('reasoning', 'linguistic') p= 0.5\n",
            "('knowledge', 'crossfertilization') p= 0.1\n",
            "('crossfertilization', 'logic') p= 1.0\n",
            "('logic', 'programming') p= 0.25\n",
            "('programming', 'machine') p= 0.5\n",
            "('learning', 'given') p= 0.05\n",
            "('given', 'rise') p= 0.2\n",
            "('rise', 'new') p= 1.0\n",
            "('new', 'discipline') p= 0.125\n",
            "('discipline', 'known') p= 0.25\n",
            "('known', 'inductive') p= 1.0\n",
            "('inductive', 'logic') p= 1.0\n",
            "('programming', 'inspired') p= 0.5\n",
            "('inspired', 'building') p= 1.0\n",
            "('building', 'achievement') p= 1.0\n",
            "('achievement', '64,statistical') p= 1.0\n",
            "('64,statistical', 'method') p= 1.0\n",
            "('method', 'used') p= 0.14285714285714285\n",
            "('used', 'natural') p= 0.09090909090909091\n",
            "('nlp', 'paper') p= 0.027777777777777776\n",
            "('paper', 'start') p= 0.2\n",
            "('start', 'definition') p= 1.0\n",
            "('definition', 'nlp') p= 1.0\n",
            "('concerned', 'design') p= 0.5\n",
            "('design', 'implementation') p= 0.3333333333333333\n",
            "('implementation', 'effective') p= 0.5\n",
            "('effective', 'natural') p= 0.14285714285714285\n",
            "('language', 'input') p= 0.010309278350515464\n",
            "('input', 'output') p= 0.3333333333333333\n",
            "('output', 'component') p= 0.25\n",
            "('component', 'computational') p= 0.25\n",
            "('computational', 'system') p= 0.14285714285714285\n",
            "('system', 'distinguish') p= 0.038461538461538464\n",
            "('distinguish', 'three') p= 1.0\n",
            "('three', 'kind') p= 0.5\n",
            "('kind', '65,report') p= 0.3333333333333333\n",
            "('65,report', 'collaborative') p= 1.0\n",
            "('collaborative', 'work') p= 1.0\n",
            "('work', 'field') p= 0.375\n",
            "('field', 'machine') p= 0.1111111111111111\n",
            "('ml', 'natural') p= 0.5\n",
            "('nlp', 'presented') p= 0.027777777777777776\n",
            "('presented', 'document') p= 0.5\n",
            "('document', 'structured') p= 0.07692307692307693\n",
            "('structured', 'two') p= 1.0\n",
            "('two', 'part') p= 0.14285714285714285\n",
            "('part', 'first') p= 0.25\n",
            "('first', 'part') p= 0.3333333333333333\n",
            "('part', 'includes') p= 0.25\n",
            "('includes', 'superficial') p= 0.3333333333333333\n",
            "('superficial', 'comprehensive') p= 1.0\n",
            "('comprehensive', 'survey') p= 1.0\n",
            "('survey', 'covering') p= 1.0\n",
            "('covering', 'stateoftheart') p= 0.5\n",
            "('stateoftheart', 'machine') p= 0.5\n",
            "('learning', 'techniq') p= 0.05\n",
            "('techniq', '66,abstract') p= 1.0\n",
            "('66,abstract', 'thesis') p= 1.0\n",
            "('thesis', 'examines') p= 1.0\n",
            "('examines', 'use') p= 0.25\n",
            "('use', 'machine') p= 0.1\n",
            "('technique', 'various') p= 0.09090909090909091\n",
            "('various', 'task') p= 0.14285714285714285\n",
            "('task', 'natural') p= 0.0625\n",
            "('processing', 'mainly') p= 0.015151515151515152\n",
            "('mainly', 'task') p= 1.0\n",
            "('task', 'information') p= 0.0625\n",
            "('information', 'extraction') p= 0.16666666666666666\n",
            "('extraction', 'text') p= 0.2\n",
            "('text', 'objective') p= 0.07692307692307693\n",
            "('objective', 'improvement') p= 1.0\n",
            "('improvement', 'adaptability') p= 0.25\n",
            "('adaptability', 'information') p= 1.0\n",
            "('extraction', 'system') p= 0.2\n",
            "('system', 'new') p= 0.038461538461538464\n",
            "('new', 'thematic') p= 0.125\n",
            "('thematic', 'domain') p= 1.0\n",
            "('domain', 'even') p= 0.1111111111111111\n",
            "('even', 'lang') p= 0.3333333333333333\n",
            "('lang', '67,chapter') p= 1.0\n",
            "('67,chapter', 'examines') p= 1.0\n",
            "('examines', 'application') p= 0.5\n",
            "('application', 'natural') p= 0.11764705882352941\n",
            "('processing', 'computerassisted') p= 0.030303030303030304\n",
            "('computerassisted', 'language') p= 1.0\n",
            "('language', 'learning') p= 0.020618556701030927\n",
            "('learning', 'including') p= 0.1\n",
            "('including', 'history') p= 0.4\n",
            "('history', 'work') p= 0.4\n",
            "('field', 'last') p= 0.2222222222222222\n",
            "('last', 'thirtyfive') p= 0.6666666666666666\n",
            "('thirtyfive', 'year') p= 1.0\n",
            "('year', 'focus') p= 0.2857142857142857\n",
            "('focus', 'current') p= 0.2857142857142857\n",
            "('current', 'development') p= 0.2857142857142857\n",
            "('development', 'opportunity') p= 0.2222222222222222\n",
            "('opportunity', '68,traditional') p= 0.3333333333333333\n",
            "('68,traditional', 'approach') p= 1.0\n",
            "('approach', 'tointerpretation') p= 0.07692307692307693\n",
            "('tointerpretation', 'natural') p= 1.0\n",
            "('processing', 'typically') p= 0.015151515151515152\n",
            "('typically', 'fall') p= 0.5\n",
            "('fall', 'one') p= 0.5\n",
            "('one', 'three') p= 0.14285714285714285\n",
            "('three', 'class') p= 0.5\n",
            "('class', 'syntaxdriven') p= 0.3333333333333333\n",
            "('syntaxdriven', 'semanticsdriven') p= 0.5\n",
            "('semanticsdriven', 'frametask') p= 1.0\n",
            "('frametask', 'based') p= 1.0\n",
            "('based', 'syntaxdriven') p= 0.25\n",
            "('syntaxdriven', 'approach') p= 0.5\n",
            "('approach', 'use') p= 0.07692307692307693\n",
            "('use', 'domainindependent') p= 0.1\n",
            "('domainindependent', 'grammar') p= 1.0\n",
            "('grammar', 'drive') p= 0.25\n",
            "('drive', 'interpretation') p= 0.5\n",
            "('interpretation', 'process') p= 0.3333333333333333\n",
            "('process', 'produce') p= 0.09090909090909091\n",
            "('produce', 'global') p= 1.0\n",
            "('global', 'parse') p= 0.5\n",
            "('parse', 'input') p= 1.0\n",
            "('input', '69,natural') p= 0.3333333333333333\n",
            "('69,natural', 'language') p= 1.0\n",
            "('nlp', 'large') p= 0.027777777777777776\n",
            "('large', 'diverse') p= 0.3333333333333333\n",
            "('diverse', 'subtopic') p= 1.0\n",
            "('subtopic', 'artificial') p= 1.0\n",
            "('artificial', 'intelligence') p= 0.6666666666666666\n",
            "('intelligence', 'result') p= 0.5\n",
            "('result', 'nlp') p= 0.16666666666666666\n",
            "('nlp', 'many') p= 0.027777777777777776\n",
            "('many', 'subtopics') p= 0.2\n",
            "('subtopics', 'including') p= 1.0\n",
            "('including', 'optical') p= 0.2\n",
            "('optical', 'character') p= 1.0\n",
            "('character', 'recognition') p= 1.0\n",
            "('recognition', 'text') p= 0.09090909090909091\n",
            "('text', 'speech') p= 0.07692307692307693\n",
            "('speech', 'translator') p= 0.14285714285714285\n",
            "('translator', 'foreign') p= 1.0\n",
            "('foreign', 'language') p= 1.0\n",
            "('language', 'reading') p= 0.010309278350515464\n",
            "('reading', 'writing') p= 1.0\n",
            "('writing', 'aid') p= 1.0\n",
            "('aid', 'machine') p= 0.5\n",
            "('translation', 'speech') p= 0.3333333333333333\n",
            "('recognition', 'w') p= 0.09090909090909091\n",
            "('w', '70,probabilistic') p= 0.5\n",
            "('70,probabilistic', 'finitestate') p= 1.0\n",
            "('finitestate', 'string') p= 1.0\n",
            "('string', 'transducer') p= 1.0\n",
            "('transducer', 'fsts') p= 1.0\n",
            "('fsts', 'extremely') p= 0.5\n",
            "('extremely', 'popular') p= 1.0\n",
            "('popular', 'natural') p= 0.5\n",
            "('processing', 'due') p= 0.015151515151515152\n",
            "('due', 'powerful') p= 0.5\n",
            "('powerful', 'generic') p= 0.3333333333333333\n",
            "('generic', 'method') p= 0.5\n",
            "('method', 'applying') p= 0.14285714285714285\n",
            "('applying', 'composing') p= 0.5\n",
            "('composing', 'learning') p= 1.0\n",
            "('learning', 'unfortunately') p= 0.05\n",
            "('unfortunately', 'fsts') p= 0.5\n",
            "('fsts', 'good') p= 0.5\n",
            "('good', 'fit') p= 1.0\n",
            "('fit', 'much') p= 1.0\n",
            "('much', 'current') p= 1.0\n",
            "('current', 'work') p= 0.14285714285714285\n",
            "('work', 'probabilistic') p= 0.125\n",
            "('probabilistic', 'modeling') p= 0.5\n",
            "('modeling', 'machine') p= 0.5\n",
            "('machine', 'translati') p= 0.06666666666666667\n",
            "('translati', '71,abstract') p= 1.0\n",
            "('71,abstract', 'special') p= 1.0\n",
            "('special', 'issue') p= 1.0\n",
            "('issue', 'tal') p= 0.2\n",
            "('tal', 'look') p= 1.0\n",
            "('look', 'fundamental') p= 1.0\n",
            "('fundamental', 'principle') p= 1.0\n",
            "('principle', 'underlying') p= 0.25\n",
            "('underlying', 'evaluation') p= 1.0\n",
            "('evaluation', 'natural') p= 0.2\n",
            "('processing', 'adopt') p= 0.015151515151515152\n",
            "('adopt', 'global') p= 1.0\n",
            "('global', 'point') p= 0.5\n",
            "('point', 'view') p= 0.3333333333333333\n",
            "('view', 'go') p= 1.0\n",
            "('go', 'beyond') p= 0.5\n",
            "('beyond', 'horizon') p= 1.0\n",
            "('horizon', 'single') p= 1.0\n",
            "('single', 'evaluation') p= 0.3333333333333333\n",
            "('evaluation', 'campaign') p= 0.2\n",
            "('campaign', 'particular') p= 1.0\n",
            "('particular', 'protocol') p= 0.3333333333333333\n",
            "('protocol', 'brief') p= 1.0\n",
            "('brief', 'review') p= 0.3333333333333333\n",
            "('review', 'history') p= 0.2\n",
            "('history', 'terminology') p= 0.2\n",
            "('terminology', '72,') p= 1.0\n",
            "('72,', '73,natural') p= 1.0\n",
            "('73,natural', 'language') p= 1.0\n",
            "('system', 'nlp') p= 0.038461538461538464\n",
            "('nlp', 'extract') p= 0.027777777777777776\n",
            "('extract', 'clinical') p= 0.5\n",
            "('clinical', 'information') p= 1.0\n",
            "('information', 'textual') p= 0.05555555555555555\n",
            "('textual', 'report') p= 1.0\n",
            "('report', 'shown') p= 1.0\n",
            "('shown', 'effective') p= 0.5\n",
            "('effective', 'limited') p= 0.14285714285714285\n",
            "('limited', 'domain') p= 0.25\n",
            "('domain', 'particular') p= 0.1111111111111111\n",
            "('particular', 'application') p= 0.3333333333333333\n",
            "('system', 'typically') p= 0.038461538461538464\n",
            "('typically', 'requires') p= 0.5\n",
            "('requires', 'substantial') p= 1.0\n",
            "('substantial', 'resource') p= 1.0\n",
            "('resource', 'develop') p= 0.2\n",
            "('develop', 'beneficial') p= 1.0\n",
            "('beneficial', 'designed') p= 1.0\n",
            "('designed', 'easily') p= 1.0\n",
            "('easily', '74,propose') p= 1.0\n",
            "('74,propose', 'bifurcated') p= 1.0\n",
            "('bifurcated', 'paradigm') p= 1.0\n",
            "('paradigm', 'construction') p= 0.5\n",
            "('construction', 'prolog') p= 0.5\n",
            "('prolog', 'knowledge') p= 0.6666666666666666\n",
            "('base', 'body') p= 0.3333333333333333\n",
            "('body', 'document') p= 1.0\n",
            "('document', 'first') p= 0.07692307692307693\n",
            "('first', 'information') p= 0.3333333333333333\n",
            "('extraction', 'ie') p= 0.2\n",
            "('ie', 'application') p= 1.0\n",
            "('application', 'annotate') p= 0.058823529411764705\n",
            "('annotate', 'corpus') p= 1.0\n",
            "('corpus', 'output') p= 1.0\n",
            "('output', 'annotated') p= 0.25\n",
            "('annotated', 'document') p= 1.0\n",
            "('document', 'second') p= 0.07692307692307693\n",
            "('second', 'prolog') p= 1.0\n",
            "('base', 'kb') p= 0.3333333333333333\n",
            "('kb', 'application') p= 1.0\n",
            "('application', 'transform') p= 0.058823529411764705\n",
            "('transform', 'th') p= 1.0\n",
            "('th', '75,describe') p= 0.3333333333333333\n",
            "('75,describe', 'single') p= 1.0\n",
            "('single', 'convolutional') p= 0.3333333333333333\n",
            "('convolutional', 'neural') p= 1.0\n",
            "('architecture', 'given') p= 0.2\n",
            "('given', 'sentence') p= 0.2\n",
            "('sentence', 'output') p= 0.3333333333333333\n",
            "('output', 'host') p= 0.25\n",
            "('host', 'language') p= 1.0\n",
            "('processing', 'prediction') p= 0.015151515151515152\n",
            "('prediction', 'partofspeech') p= 1.0\n",
            "('partofspeech', 'tag') p= 0.5\n",
            "('tag', 'chunk') p= 0.5\n",
            "('chunk', 'named') p= 1.0\n",
            "('entity', 'tag') p= 0.5\n",
            "('tag', 'semantic') p= 0.5\n",
            "('role', 'semantically') p= 0.25\n",
            "('semantically', 'similar') p= 0.5\n",
            "('similar', 'word') p= 1.0\n",
            "('word', 'likelihood') p= 0.07142857142857142\n",
            "('likelihood', 'sentence') p= 1.0\n",
            "('sentence', 'make') p= 0.3333333333333333\n",
            "('make', 'sense') p= 0.25\n",
            "('sense', 'grammatically') p= 0.25\n",
            "('grammatically', 'sem') p= 1.0\n",
            "('sem', '76,developed') p= 1.0\n",
            "('76,developed', 'prototype') p= 1.0\n",
            "('prototype', 'information') p= 1.0\n",
            "('system', 'us') p= 0.038461538461538464\n",
            "('us', 'advanced') p= 0.5\n",
            "('advanced', 'natural') p= 1.0\n",
            "('technique', 'enhance') p= 0.09090909090909091\n",
            "('enhance', 'effectiveness') p= 1.0\n",
            "('effectiveness', 'traditional') p= 1.0\n",
            "('traditional', 'keyword') p= 0.3333333333333333\n",
            "('keyword', 'based') p= 1.0\n",
            "('based', 'document') p= 0.25\n",
            "('retrieval', 'backbone') p= 0.08333333333333333\n",
            "('backbone', 'system') p= 1.0\n",
            "('system', 'statistical') p= 0.038461538461538464\n",
            "('statistical', 'retrieval') p= 0.2\n",
            "('retrieval', 'engine') p= 0.08333333333333333\n",
            "('engine', 'performs') p= 1.0\n",
            "('performs', 'automated') p= 0.5\n",
            "('automated', 'indexing') p= 0.2\n",
            "('indexing', 'docum') p= 1.0\n",
            "('docum', '77,') p= 1.0\n",
            "('77,', '78,paper') p= 1.0\n",
            "('78,paper', 'discus') p= 1.0\n",
            "('several', 'issue') p= 0.25\n",
            "('issue', 'requirement') p= 0.2\n",
            "('requirement', 'enabling') p= 0.2\n",
            "('enabling', 'natural') p= 1.0\n",
            "('system', 'become') p= 0.038461538461538464\n",
            "('become', 'contextadaptive') p= 0.3333333333333333\n",
            "('contextadaptive', 'given') p= 1.0\n",
            "('given', 'fact') p= 0.2\n",
            "('fact', 'emerging') p= 1.0\n",
            "('emerging', 'system') p= 1.0\n",
            "('system', 'feature') p= 0.038461538461538464\n",
            "('feature', 'speaker') p= 0.125\n",
            "('speaker', 'independent') p= 0.5\n",
            "('independent', 'continuous') p= 0.5\n",
            "('continuous', 'speech') p= 1.0\n",
            "('recognition', 'restricted') p= 0.09090909090909091\n",
            "('restricted', 'individual') p= 1.0\n",
            "('individual', 'domain') p= 1.0\n",
            "('domain', 'equipped') p= 0.1111111111111111\n",
            "('equipped', 'syntactic') p= 1.0\n",
            "('syntactic', '79,fall') p= 0.2\n",
            "('79,fall', 'introduced') p= 1.0\n",
            "('introduced', 'new') p= 1.0\n",
            "('new', 'course') p= 0.125\n",
            "('course', 'called') p= 1.0\n",
            "('called', 'applied') p= 0.5\n",
            "('applied', 'natural') p= 0.25\n",
            "('processing', 'student') p= 0.015151515151515152\n",
            "('student', 'acquire') p= 1.0\n",
            "('acquire', 'understanding') p= 0.5\n",
            "('understanding', 'text') p= 0.125\n",
            "('analysis', 'technique') p= 0.09090909090909091\n",
            "('technique', 'currently') p= 0.09090909090909091\n",
            "('currently', 'feasible') p= 0.3333333333333333\n",
            "('feasible', 'practical') p= 1.0\n",
            "('practical', 'application') p= 0.3333333333333333\n",
            "('application', '80,') p= 0.058823529411764705\n",
            "('80,', '81,abstract') p= 1.0\n",
            "('81,abstract', 'natural') p= 1.0\n",
            "('processing', 'study') p= 0.015151515151515152\n",
            "('study', 'mathematical') p= 0.25\n",
            "('mathematical', 'computational') p= 1.0\n",
            "('computational', 'modelling') p= 0.14285714285714285\n",
            "('modelling', 'various') p= 0.5\n",
            "('various', 'aspect') p= 0.14285714285714285\n",
            "('aspect', 'language') p= 0.5\n",
            "('language', 'improvement') p= 0.010309278350515464\n",
            "('improvement', 'wide') p= 0.25\n",
            "('wide', 'range') p= 0.6666666666666666\n",
            "('range', 'system') p= 0.2\n",
            "('system', 'natural') p= 0.038461538461538464\n",
            "('language', 'arises') p= 0.010309278350515464\n",
            "('arises', 'innate') p= 1.0\n",
            "('innate', 'facility') p= 1.0\n",
            "('facility', 'language') p= 1.0\n",
            "('language', 'possessed') p= 0.010309278350515464\n",
            "('possessed', 'human') p= 1.0\n",
            "('human', 'intellect') p= 0.16666666666666666\n",
            "('intellect', 'may') p= 1.0\n",
            "('may', '82,natural') p= 1.0\n",
            "('82,natural', 'language') p= 1.0\n",
            "('nlp', 'branch') p= 0.027777777777777776\n",
            "('branch', 'artificial') p= 1.0\n",
            "('intelligence', 'includes') p= 0.5\n",
            "('includes', 'speech') p= 0.3333333333333333\n",
            "('speech', 'synthesis') p= 0.14285714285714285\n",
            "('synthesis', 'speech') p= 1.0\n",
            "('recognition', 'machine') p= 0.09090909090909091\n",
            "('translation', 'natural') p= 0.3333333333333333\n",
            "('processing', 'wide') p= 0.015151515151515152\n",
            "('range', 'application') p= 0.2\n",
            "('application', 'indian') p= 0.058823529411764705\n",
            "('indian', 'context') p= 0.5\n",
            "('context', 'rural') p= 0.25\n",
            "('rural', 'indian') p= 1.0\n",
            "('indian', 'community') p= 0.5\n",
            "('community', 'unable') p= 0.5\n",
            "('unable', 'make') p= 1.0\n",
            "('use', 'th') p= 0.1\n",
            "('th', '83,evaluation') p= 0.3333333333333333\n",
            "('83,evaluation', 'lolita') p= 1.0\n",
            "('lolita', 'related') p= 0.3333333333333333\n",
            "('related', 'natural') p= 0.3333333333333333\n",
            "('system', 'paul') p= 0.038461538461538464\n",
            "('paul', 'callaghan') p= 1.0\n",
            "('callaghan', 'submitted') p= 1.0\n",
            "('submitted', 'university') p= 1.0\n",
            "('university', 'durham') p= 1.0\n",
            "('durham', 'degree') p= 1.0\n",
            "('degree', 'phd') p= 0.5\n",
            "('phd', 'august') p= 1.0\n",
            "('august', 'research') p= 1.0\n",
            "('research', 'address') p= 0.125\n",
            "('address', 'question') p= 0.3333333333333333\n",
            "('question', 'evaluate') p= 1.0\n",
            "('evaluate', 'system') p= 1.0\n",
            "('system', 'like') p= 0.038461538461538464\n",
            "('like', 'lolita') p= 0.5\n",
            "('lolita', 'lolita') p= 0.3333333333333333\n",
            "('lolita', 'natural') p= 0.3333333333333333\n",
            "('natural', '84,previous') p= 0.014492753623188406\n",
            "('84,previous', 'work') p= 1.0\n",
            "('work', 'demonstrated') p= 0.125\n",
            "('demonstrated', 'web') p= 1.0\n",
            "('web', 'count') p= 0.3333333333333333\n",
            "('count', 'used') p= 0.5\n",
            "('used', 'approximate') p= 0.09090909090909091\n",
            "('approximate', 'bigram') p= 1.0\n",
            "('bigram', 'count') p= 1.0\n",
            "('count', 'suggesting') p= 0.5\n",
            "('suggesting', 'webbased') p= 0.5\n",
            "('webbased', 'frequency') p= 0.5\n",
            "('frequency', 'useful') p= 1.0\n",
            "('useful', 'wide') p= 0.5\n",
            "('wide', 'variety') p= 0.3333333333333333\n",
            "('variety', 'natural') p= 1.0\n",
            "('task', 'however') p= 0.0625\n",
            "('however', 'limited') p= 0.2\n",
            "('limited', 'number') p= 0.25\n",
            "('task', 'far') p= 0.0625\n",
            "('far', 'tested') p= 1.0\n",
            "('tested', 'using') p= 1.0\n",
            "('using', 'webscale') p= 0.25\n",
            "('webscale', 'data') p= 1.0\n",
            "('data', 'set') p= 0.1111111111111111\n",
            "('set', 'pr') p= 0.3333333333333333\n",
            "('pr', '85,chapter') p= 0.5\n",
            "('85,chapter', 'examines') p= 1.0\n",
            "('opportunity', 'introduction') p= 0.3333333333333333\n",
            "('introduction', 'chapter') p= 0.5\n",
            "('chapter', 'focus') p= 1.0\n",
            "('focus', 'application') p= 0.14285714285714285\n",
            "('application', '86,paper') p= 0.058823529411764705\n",
            "('86,paper', 'describes') p= 1.0\n",
            "('describes', 'natural') p= 0.5\n",
            "('language', 'system') p= 0.010309278350515464\n",
            "('system', 'improves') p= 0.038461538461538464\n",
            "('improves', 'performance') p= 1.0\n",
            "('performance', 'learning') p= 0.5\n",
            "('learning', 'system') p= 0.05\n",
            "('process', 'short') p= 0.09090909090909091\n",
            "('short', 'english') p= 0.5\n",
            "('english', 'narrative') p= 0.5\n",
            "('narrative', 'able') p= 0.5\n",
            "('able', 'acquire') p= 0.5\n",
            "('acquire', 'single') p= 0.5\n",
            "('single', 'narrative') p= 0.3333333333333333\n",
            "('narrative', 'new') p= 0.5\n",
            "('new', 'schema') p= 0.125\n",
            "('schema', 'stereotypical') p= 1.0\n",
            "('stereotypical', 'set') p= 1.0\n",
            "('set', 'action') p= 0.3333333333333333\n",
            "('action', 'understanding') p= 1.0\n",
            "('understanding', 'process') p= 0.125\n",
            "('process', 'system') p= 0.09090909090909091\n",
            "('system', 'attempt') p= 0.038461538461538464\n",
            "('attempt', '87,classify') p= 1.0\n",
            "('87,classify', 'review') p= 1.0\n",
            "('review', 'current') p= 0.2\n",
            "('current', 'approach') p= 0.14285714285714285\n",
            "('approach', 'software') p= 0.07692307692307693\n",
            "('software', 'infrastructure') p= 0.2\n",
            "('infrastructure', 'research') p= 1.0\n",
            "('research', 'development') p= 0.125\n",
            "('development', 'delivery') p= 0.1111111111111111\n",
            "('delivery', 'nlp') p= 1.0\n",
            "('system', 'task') p= 0.038461538461538464\n",
            "('task', '88,confidence') p= 0.0625\n",
            "('88,confidence', 'measure') p= 1.0\n",
            "('measure', 'practical') p= 0.3333333333333333\n",
            "('practical', 'solution') p= 0.3333333333333333\n",
            "('solution', 'improving') p= 0.5\n",
            "('improving', 'usefulness') p= 1.0\n",
            "('usefulness', 'natural') p= 1.0\n",
            "('application', 'confidence') p= 0.11764705882352941\n",
            "('confidence', 'estimation') p= 0.6666666666666666\n",
            "('estimation', 'generic') p= 0.3333333333333333\n",
            "('generic', 'machine') p= 0.5\n",
            "('learning', 'approach') p= 0.05\n",
            "('approach', 'deriving') p= 0.07692307692307693\n",
            "('deriving', 'confidence') p= 1.0\n",
            "('confidence', 'measure') p= 0.3333333333333333\n",
            "('measure', 'give') p= 0.3333333333333333\n",
            "('give', 'overview') p= 1.0\n",
            "('overview', 'application') p= 0.5\n",
            "('estimation', 'various') p= 0.3333333333333333\n",
            "('various', 'field') p= 0.14285714285714285\n",
            "('field', 'n') p= 0.1111111111111111\n",
            "('n', '89,lexsign') p= 1.0\n",
            "('89,lexsign', 'senseid') p= 1.0\n",
            "('senseid', 'senseid') p= 0.5\n",
            "('senseid', 'dictionary') p= 0.16666666666666666\n",
            "('dictionary', 'ldoce') p= 0.25\n",
            "('ldoce', 'lexsign') p= 1.0\n",
            "('lexsign', 'senseid') p= 1.0\n",
            "('senseid', 'ldbentryno') p= 0.16666666666666666\n",
            "('ldbentryno', 'lexsign') p= 1.0\n",
            "('senseid', 'senseno') p= 0.16666666666666666\n",
            "('senseno', 'loaded') p= 1.0\n",
            "('loaded', 'lkb') p= 1.0\n",
            "('lkb', 'expanded') p= 1.0\n",
            "('expanded', 'fullyfledged') p= 1.0\n",
            "('fullyfledged', 'representation') p= 1.0\n",
            "('representation', 'transitive') p= 1.0\n",
            "('transitive', 'use') p= 1.0\n",
            "('use', 'e') p= 0.1\n",
            "('e', '90,describe') p= 0.5\n",
            "('90,describe', 'design') p= 1.0\n",
            "('design', 'use') p= 0.3333333333333333\n",
            "('use', 'stanford') p= 0.1\n",
            "('stanford', 'corenlp') p= 1.0\n",
            "('corenlp', 'toolkit') p= 1.0\n",
            "('toolkit', 'extensible') p= 0.5\n",
            "('extensible', 'pipeline') p= 1.0\n",
            "('pipeline', 'provides') p= 1.0\n",
            "('provides', 'core') p= 0.3333333333333333\n",
            "('core', 'natural') p= 1.0\n",
            "('language', 'analysis') p= 0.010309278350515464\n",
            "('analysis', 'toolkit') p= 0.09090909090909091\n",
            "('toolkit', 'quite') p= 0.5\n",
            "('quite', 'widely') p= 1.0\n",
            "('used', 'research') p= 0.09090909090909091\n",
            "('research', 'nlp') p= 0.125\n",
            "('nlp', 'community') p= 0.027777777777777776\n",
            "('community', 'also') p= 0.5\n",
            "('also', 'among') p= 0.25\n",
            "('among', 'commercial') p= 0.25\n",
            "('commercial', 'government') p= 1.0\n",
            "('government', 'user') p= 1.0\n",
            "('user', 'open') p= 0.3333333333333333\n",
            "('open', 'source') p= 1.0\n",
            "('source', 'nlp') p= 0.25\n",
            "('nlp', 'technology') p= 0.027777777777777776\n",
            "('technology', 'suggest') p= 0.25\n",
            "('suggest', '91,gaussian') p= 1.0\n",
            "('91,gaussian', 'process') p= 1.0\n",
            "('process', 'gps') p= 0.09090909090909091\n",
            "('gps', 'powerful') p= 1.0\n",
            "('powerful', 'modelling') p= 0.3333333333333333\n",
            "('modelling', 'framework') p= 0.5\n",
            "('framework', 'incorporating') p= 0.3333333333333333\n",
            "('incorporating', 'kernel') p= 1.0\n",
            "('kernel', 'bayesian') p= 1.0\n",
            "('bayesian', 'inference') p= 1.0\n",
            "('inference', 'recognised') p= 1.0\n",
            "('recognised', 'stateoftheart') p= 1.0\n",
            "('stateoftheart', 'many') p= 0.5\n",
            "('many', 'machine') p= 0.2\n",
            "('learning', 'task') p= 0.05\n",
            "('task', '92,fundamental') p= 0.0625\n",
            "('92,fundamental', 'issue') p= 1.0\n",
            "('issue', 'natural') p= 0.2\n",
            "('processing', 'prerequisite') p= 0.015151515151515152\n",
            "('prerequisite', 'enormous') p= 1.0\n",
            "('enormous', 'quantity') p= 1.0\n",
            "('quantity', 'preprogrammed') p= 0.5\n",
            "('preprogrammed', 'knowledge') p= 1.0\n",
            "('knowledge', 'concerning') p= 0.1\n",
            "('concerning', 'language') p= 0.5\n",
            "('domain', 'examination') p= 0.1111111111111111\n",
            "('examination', 'manual') p= 1.0\n",
            "('manual', 'acquisition') p= 0.3333333333333333\n",
            "('acquisition', 'knowledge') p= 0.3333333333333333\n",
            "('knowledge', 'tedious') p= 0.1\n",
            "('tedious', 'error') p= 1.0\n",
            "('error', 'prone') p= 1.0\n",
            "('prone', 'development') p= 1.0\n",
            "('development', 'automated') p= 0.1111111111111111\n",
            "('automated', 'acquisition') p= 0.2\n",
            "('acquisition', 'process') p= 0.3333333333333333\n",
            "('process', '93,general') p= 0.09090909090909091\n",
            "('93,general', 'reusable') p= 1.0\n",
            "('reusable', 'computational') p= 1.0\n",
            "('computational', 'resource') p= 0.14285714285714285\n",
            "('resource', 'de') p= 0.2\n",
            "('de', 'veloped') p= 0.25\n",
            "('veloped', 'within') p= 1.0\n",
            "('within', 'penman') p= 0.3333333333333333\n",
            "('penman', 'text') p= 1.0\n",
            "('generation', 'project') p= 0.25\n",
            "('project', 'organizing') p= 0.3333333333333333\n",
            "('organizing', 'domain') p= 1.0\n",
            "('domain', 'knowledge') p= 0.1111111111111111\n",
            "('knowledge', 'appropriately') p= 0.1\n",
            "('appropriately', 'linguistic') p= 1.0\n",
            "('linguistic', 'realization') p= 0.125\n",
            "('realization', 'resource') p= 1.0\n",
            "('resource', 'called') p= 0.2\n",
            "('called', 'upper') p= 0.5\n",
            "('upper', 'model') p= 1.0\n",
            "('model', 'provides') p= 0.125\n",
            "('provides', 'domain') p= 0.3333333333333333\n",
            "('domain', 'taskindependent') p= 0.1111111111111111\n",
            "('taskindependent', 'classification') p= 1.0\n",
            "('classification', 'system') p= 0.5\n",
            "('system', 'support') p= 0.038461538461538464\n",
            "('support', '94,kohonenaposs') p= 0.25\n",
            "('94,kohonenaposs', 'selforganizing') p= 1.0\n",
            "('selforganizing', 'map') p= 1.0\n",
            "('map', 'som') p= 0.6666666666666666\n",
            "('som', 'one') p= 0.5\n",
            "('one', 'popular') p= 0.14285714285714285\n",
            "('popular', 'artificial') p= 0.5\n",
            "('artificial', 'neural') p= 0.3333333333333333\n",
            "('network', 'algorithm') p= 0.2\n",
            "('algorithm', 'word') p= 0.25\n",
            "('word', 'category') p= 0.07142857142857142\n",
            "('category', 'map') p= 1.0\n",
            "('som', 'organized') p= 0.5\n",
            "('organized', 'according') p= 1.0\n",
            "('according', 'word') p= 1.0\n",
            "('word', 'similarity') p= 0.07142857142857142\n",
            "('similarity', 'measured') p= 0.3333333333333333\n",
            "('measured', 'similarity') p= 1.0\n",
            "('similarity', 'short') p= 0.3333333333333333\n",
            "('short', 'context') p= 0.5\n",
            "('context', 'word') p= 0.25\n",
            "('word', 'conceptually') p= 0.07142857142857142\n",
            "('conceptually', 'interrelated') p= 1.0\n",
            "('interrelated', 'word') p= 1.0\n",
            "('word', 'tend') p= 0.07142857142857142\n",
            "('tend', 'fall') p= 1.0\n",
            "('fall', '95,paper') p= 0.5\n",
            "('95,paper', 'present') p= 1.0\n",
            "('present', 'workbench') p= 0.14285714285714285\n",
            "('workbench', 'built') p= 0.5\n",
            "('built', 'priberam') p= 0.5\n",
            "('priberam', 'informática') p= 1.0\n",
            "('informática', 'development') p= 1.0\n",
            "('development', 'company') p= 0.1111111111111111\n",
            "('company', 'natural') p= 1.0\n",
            "('processing', 'technology') p= 0.015151515151515152\n",
            "('technology', 'workbench') p= 0.25\n",
            "('workbench', 'includes') p= 0.5\n",
            "('includes', 'set') p= 0.3333333333333333\n",
            "('set', 'linguistic') p= 0.3333333333333333\n",
            "('linguistic', 'resource') p= 0.125\n",
            "('resource', 'software') p= 0.2\n",
            "('software', 'tool') p= 0.2\n",
            "('tool', 'applied') p= 0.3333333333333333\n",
            "('applied', 'considerable') p= 0.25\n",
            "('considerable', 'number') p= 1.0\n",
            "('number', 'practical') p= 0.25\n",
            "('practical', 'purpose') p= 0.3333333333333333\n",
            "('purpose', 'covering') p= 0.2\n",
            "('covering', 'proofing') p= 0.5\n",
            "('proofing', '96,abstractnatural') p= 1.0\n",
            "('96,abstractnatural', 'language') p= 1.0\n",
            "('nlp', 'effective') p= 0.027777777777777776\n",
            "('effective', 'approach') p= 0.2857142857142857\n",
            "('approach', 'bringing') p= 0.07692307692307693\n",
            "('bringing', 'improvement') p= 1.0\n",
            "('improvement', 'educational') p= 0.25\n",
            "('educational', 'setting') p= 0.5\n",
            "('setting', 'implementing') p= 1.0\n",
            "('implementing', 'nlp') p= 1.0\n",
            "('nlp', 'involves') p= 0.027777777777777776\n",
            "('involves', 'initiating') p= 0.5\n",
            "('initiating', 'process') p= 1.0\n",
            "('process', 'learning') p= 0.09090909090909091\n",
            "('learning', 'natural') p= 0.05\n",
            "('natural', 'acquisition') p= 0.014492753623188406\n",
            "('acquisition', 'educational') p= 0.3333333333333333\n",
            "('educational', 'system') p= 0.5\n",
            "('system', 'based') p= 0.038461538461538464\n",
            "('based', 'effective') p= 0.25\n",
            "('approach', 'providing') p= 0.07692307692307693\n",
            "('providing', 'solution') p= 0.5\n",
            "('solution', 'f') p= 0.5\n",
            "('f', '97,abstract') p= 1.0\n",
            "('97,abstract', 'twenty') p= 1.0\n",
            "('twenty', 'year') p= 1.0\n",
            "('year', 'disfavor') p= 0.14285714285714285\n",
            "('disfavor', 'technology') p= 1.0\n",
            "('technology', 'returned') p= 0.25\n",
            "('returned', 'imitates') p= 1.0\n",
            "('imitates', 'process') p= 1.0\n",
            "('process', 'brain') p= 0.09090909090909091\n",
            "('brain', 'natural') p= 0.5\n",
            "('language', 'experiment') p= 0.010309278350515464\n",
            "('experiment', 'sejnowski') p= 0.5\n",
            "('sejnowski', 'rosenberg') p= 1.0\n",
            "('rosenberg', 'demonstrate') p= 1.0\n",
            "('demonstrate', 'neural') p= 1.0\n",
            "('network', 'computing') p= 0.2\n",
            "('computing', 'architecture') p= 1.0\n",
            "('architecture', 'learn') p= 0.2\n",
            "('learn', 'actual') p= 1.0\n",
            "('actual', 'spoken') p= 1.0\n",
            "('spoken', 'language') p= 0.25\n",
            "('language', 'observe') p= 0.010309278350515464\n",
            "('observe', 'rule') p= 1.0\n",
            "('rule', 'pronunciation') p= 1.0\n",
            "('pronunciation', '98,text') p= 1.0\n",
            "('98,text', 'statistic') p= 1.0\n",
            "('statistic', 'frequently') p= 0.5\n",
            "('frequently', 'used') p= 1.0\n",
            "('used', 'stylometry') p= 0.09090909090909091\n",
            "('stylometry', 'cryptography') p= 1.0\n",
            "('cryptography', 'study') p= 1.0\n",
            "('study', 'paper') p= 0.25\n",
            "('paper', 'text') p= 0.2\n",
            "('text', 'statistic') p= 0.07692307692307693\n",
            "('statistic', 'tool') p= 0.5\n",
            "('tool', 'developed') p= 0.3333333333333333\n",
            "('developed', 'iso') p= 0.5\n",
            "('iso', 'prolog') p= 1.0\n",
            "('prolog', 'natural') p= 0.3333333333333333\n",
            "('processing', 'detail') p= 0.015151515151515152\n",
            "('detail', 'given') p= 1.0\n",
            "('given', 'usage') p= 0.2\n",
            "('usage', 'usercallable') p= 1.0\n",
            "('usercallable', 'predicate') p= 1.0\n",
            "('predicate', 'logic') p= 1.0\n",
            "('logic', 'limitation') p= 0.125\n",
            "('limitation', 'program') p= 1.0\n",
            "('program', 'also') p= 0.3333333333333333\n",
            "('also', 'discussed') p= 0.25\n",
            "('discussed', '99,summarize') p= 1.0\n",
            "('99,summarize', 'experience') p= 1.0\n",
            "('experience', 'using') p= 0.5\n",
            "('using', 'framenet') p= 0.25\n",
            "('framenet', 'two') p= 0.5\n",
            "('two', 'rather') p= 0.14285714285714285\n",
            "('rather', 'different') p= 0.5\n",
            "('different', 'project') p= 0.16666666666666666\n",
            "('project', 'natural') p= 0.3333333333333333\n",
            "('nlp', 'conclude') p= 0.027777777777777776\n",
            "('conclude', 'nlp') p= 1.0\n",
            "('nlp', 'benefit') p= 0.027777777777777776\n",
            "('benefit', 'framenet') p= 0.5\n",
            "('framenet', 'different') p= 0.5\n",
            "('different', 'way') p= 0.16666666666666666\n",
            "('way', 'sketch') p= 0.2\n",
            "('sketch', 'problem') p= 1.0\n",
            "('problem', 'need') p= 0.25\n",
            "('need', 'overcome') p= 0.16666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "1dG3n_9zWhcY",
        "outputId": "32eea930-d0c3-4f83-96a0-e323460b1afa"
      },
      "source": [
        "#NOUN PHRASES\r\n",
        "import pandas as pd\r\n",
        "from textblob import TextBlob\r\n",
        "nltk.download('brown')\r\n",
        "nltk.download('punkt')\r\n",
        "a={}\r\n",
        "for i in df['cleansentence']:\r\n",
        "  w = TextBlob(i).noun_phrases\r\n",
        "  for l in w:\r\n",
        "    if l in a:\r\n",
        "      a[l]+=1\r\n",
        "    else:\r\n",
        "      a[l] = 1\r\n",
        "al ={m: a[m] for m in list(a)[:100]}\r\n",
        "maximumfreq = max({ i for i in a.values()})\r\n",
        "print('maximum frequency',maximumfreq)\r\n",
        "b={}\r\n",
        "for wo,value in a.items():\r\n",
        "  b[wo]=value/maximumfreq                  #Relative Probability\r\n",
        "  dfnou = pd.DataFrame(list(b.items()),columns = ['NOUN PHRASES','RELATIVE PROBABILITY'])\r\n",
        "  dfnou['NOUN PHRASES'].append(pd.Series(), ignore_index=True)\r\n",
        "  dfnou['ABSTRACTS']=df['cleansentence']\r\n",
        "dfnou.T"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "maximum frequency 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>359</th>\n",
              "      <th>360</th>\n",
              "      <th>361</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOUN PHRASES</th>\n",
              "      <td>maximum entropy</td>\n",
              "      <td>multiple thread biblical time</td>\n",
              "      <td>widescale application concept</td>\n",
              "      <td>real world problem</td>\n",
              "      <td>statistical estimation pattern recognition paper</td>\n",
              "      <td>conditional random field</td>\n",
              "      <td>natural language processing term condition ter...</td>\n",
              "      <td>minerva access</td>\n",
              "      <td>paper address issue cooperation linguistics</td>\n",
              "      <td>natural language processing nlp general lingui...</td>\n",
              "      <td>particular focus</td>\n",
              "      <td>direction cooperation</td>\n",
              "      <td>application linguistics nlp</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>encode knowledge base syntactic semantic pragm...</td>\n",
              "      <td>drive semantic interpretation</td>\n",
              "      <td>natural language generation process</td>\n",
              "      <td>description logic u</td>\n",
              "      <td>neural network architecture learning algorithm</td>\n",
              "      <td>various natural language processing task</td>\n",
              "      <td>entity recognition semantic role</td>\n",
              "      <td>taskspecific eng</td>\n",
              "      <td>natural language processing subject</td>\n",
              "      <td>natural language processing</td>\n",
              "      <td>broad narrow sens</td>\n",
              "      <td>broad sense</td>\n",
              "      <td>processing issue level</td>\n",
              "      <td>natural language understanding</td>\n",
              "      <td>speech recognition syntactic semantic analysis...</td>\n",
              "      <td>robot interact human facetoface</td>\n",
              "      <td>natural language need responsive way human use...</td>\n",
              "      <td>natural language processing system robot perfo...</td>\n",
              "      <td>natural language language</td>\n",
              "      <td>point language</td>\n",
              "      <td>natural language processing collection technique</td>\n",
              "      <td>goal field</td>\n",
              "      <td>natural l</td>\n",
              "      <td>abstract ambiguity</td>\n",
              "      <td>natural language</td>\n",
              "      <td>ambiguous computer</td>\n",
              "      <td>...</td>\n",
              "      <td>prone development</td>\n",
              "      <td>acquisition process</td>\n",
              "      <td>general reusable computational resource</td>\n",
              "      <td>penman text generation project</td>\n",
              "      <td>domain knowledge</td>\n",
              "      <td>linguistic realization resource</td>\n",
              "      <td>upper model</td>\n",
              "      <td>domain taskindependent classification system s...</td>\n",
              "      <td>map som</td>\n",
              "      <td>popular artificial neural network algorithm wo...</td>\n",
              "      <td>word similarity</td>\n",
              "      <td>short context word</td>\n",
              "      <td>present workbench</td>\n",
              "      <td>priberam informática development company</td>\n",
              "      <td>natural language processing technology workbench</td>\n",
              "      <td>linguistic resource software tool</td>\n",
              "      <td>considerable number</td>\n",
              "      <td>practical purpose</td>\n",
              "      <td>abstractnatural language processing nlp</td>\n",
              "      <td>effective approach</td>\n",
              "      <td>educational setting</td>\n",
              "      <td>nlp involves</td>\n",
              "      <td>process learning</td>\n",
              "      <td>natural acquisition</td>\n",
              "      <td>educational system</td>\n",
              "      <td>solution f</td>\n",
              "      <td>year disfavor technology</td>\n",
              "      <td>imitates process brain</td>\n",
              "      <td>natural language experiment sejnowski rosenberg</td>\n",
              "      <td>neural network</td>\n",
              "      <td>language observe rule pronunciation</td>\n",
              "      <td>text statistic</td>\n",
              "      <td>stylometry cryptography study paper text stati...</td>\n",
              "      <td>iso prolog</td>\n",
              "      <td>natural language processing detail</td>\n",
              "      <td>usercallable predicate logic limitation program</td>\n",
              "      <td>summarize experience</td>\n",
              "      <td>different project</td>\n",
              "      <td>natural language processing nlp conclude nlp b...</td>\n",
              "      <td>different way sketch problem need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RELATIVE PROBABILITY</th>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "      <td>0.0714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ABSTRACTS</th>\n",
              "      <td></td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>natural language processing subject natural la...</td>\n",
              "      <td>robot interact human facetoface using natural ...</td>\n",
              "      <td>natural language language spoken human current...</td>\n",
              "      <td>abstract ambiguity referred ability one meanin...</td>\n",
              "      <td>introduction statistical natural language proc...</td>\n",
              "      <td>paper summarizes essential property document r...</td>\n",
              "      <td>abstract language way communicating word langu...</td>\n",
              "      <td>report experiment use standard natural languag...</td>\n",
              "      <td>paper describe simple rulebased approach autom...</td>\n",
              "      <td>paper focus connectionist model natural langua...</td>\n",
              "      <td>abstract article explores possibility construc...</td>\n",
              "      <td>paper see schank theoretical discussion ka lea...</td>\n",
              "      <td>objective provide overview tutorial natural la...</td>\n",
              "      <td>paper briefly describes current implementation...</td>\n",
              "      <td>abstract metabolism machinery life signal tran...</td>\n",
              "      <td>report present detailed analysis review nlp ev...</td>\n",
              "      <td>web emerged important source information world...</td>\n",
              "      <td>abstract natural language processing theoretic...</td>\n",
              "      <td>paper review process involved natural language...</td>\n",
              "      <td>article focus derivation large lexicon natural...</td>\n",
              "      <td>introduce method analyzing complexity natural ...</td>\n",
              "      <td>deep learning emerged new area machine learnin...</td>\n",
              "      <td>authorproduced version paper published</td>\n",
              "      <td>abstractnatural language processing nlp applic...</td>\n",
              "      <td>information retrieval address problem finding ...</td>\n",
              "      <td>work computational linguistics began soon deve...</td>\n",
              "      <td>abstracta system recognizes authenticates voic...</td>\n",
              "      <td>abstract testing natural language requirement ...</td>\n",
              "      <td></td>\n",
              "      <td>algorithm allow understanding generation humor...</td>\n",
              "      <td></td>\n",
              "      <td>recent year machine learning ml used solve com...</td>\n",
              "      <td>argue manual automatic thesaurus alternative r...</td>\n",
              "      <td>introduction pattern music object intensive st...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 399 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  0    ...                                398\n",
              "NOUN PHRASES          maximum entropy  ...  different way sketch problem need\n",
              "RELATIVE PROBABILITY        0.0714286  ...                          0.0714286\n",
              "ABSTRACTS                              ...                                NaN\n",
              "\n",
              "[3 rows x 399 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "afJbOQnGYpmv",
        "outputId": "ec35d7ca-7d2e-4b54-c377-3a2be4fa12ab"
      },
      "source": [
        "#Documents-terms weights(tf*idf)\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "sentences = list()\r\n",
        "with open(\"abst2.csv\") as file:\r\n",
        "    for line in file:\r\n",
        "        for l in re.split(r\"\\.\\s|\\?\\s|\\!\\s|\\n\",line):\r\n",
        "            if l:\r\n",
        "                sentences.append(l)\r\n",
        "cvec = CountVectorizer(stop_words='english', min_df=3, max_df=0.5, ngram_range=(1,2))\r\n",
        "s = cvec.fit_transform(sentences)\r\n",
        "transformer = TfidfTransformer()\r\n",
        "transformed_weights = transformer.fit_transform(s)\r\n",
        "w = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\r\n",
        "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'tf*idf': w})\r\n",
        "a=pd.DataFrame()\r\n",
        "a=weights_df.sort_values(by='tf*idf', ascending=False)\r\n",
        "a.head(100)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>tf*idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>nlp</td>\n",
              "      <td>0.061901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>paper</td>\n",
              "      <td>0.047086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>information</td>\n",
              "      <td>0.040820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.040657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>approach</td>\n",
              "      <td>0.036786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>support</td>\n",
              "      <td>0.011689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>program</td>\n",
              "      <td>0.011683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>neural network</td>\n",
              "      <td>0.011672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>neural</td>\n",
              "      <td>0.011672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>traditional</td>\n",
              "      <td>0.011575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               term    tf*idf\n",
              "89              nlp  0.061901\n",
              "94            paper  0.047086\n",
              "60      information  0.040820\n",
              "70         learning  0.040657\n",
              "7          approach  0.036786\n",
              "..              ...       ...\n",
              "139         support  0.011689\n",
              "105         program  0.011683\n",
              "87   neural network  0.011672\n",
              "86           neural  0.011672\n",
              "147     traditional  0.011575\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "ST5s2bI3Zc2x",
        "outputId": "be3a9b7c-9550-4fac-9c68-3a7f443cdbb3"
      },
      "source": [
        "#Cosine similarity\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "import numpy as np\r\n",
        "import numpy.linalg as LA\r\n",
        "from nltk.corpus import stopwords\r\n",
        "ta = df['cleansentence'].values.tolist()\r\n",
        "tb = \"How natural language processing is being useful in this world?\"   #Query\r\n",
        "tb= [tb]\r\n",
        "stopWords = stopwords.words('english')\r\n",
        "v= CountVectorizer(stop_words = stopWords)\r\n",
        "transformer = TfidfTransformer()\r\n",
        "taVectorizerArray = v.fit_transform(ta).toarray()\r\n",
        "tbVectorizerArray = v.transform(tb).toarray()\r\n",
        "x= lambda a, b : np.inner(a, b)/(LA.norm(a)*LA.norm(b))\r\n",
        "cosinev = []\r\n",
        "for vector in taVectorizerArray:\r\n",
        "        for teV in tbVectorizerArray:\r\n",
        "            cosine = x(vector, teV)\r\n",
        "            cosinev.append(cosine)\r\n",
        "df_re = df.filter(['cleansentence'], axis=1)\r\n",
        "s = pd.Series(cosinev)\r\n",
        "df_re['Cosine similarity'] = s.values\r\n",
        "df_re= df_re.iloc[1:]\r\n",
        "df_re"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Cosine similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>0.080322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>0.292770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>0.226779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>0.377964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>0.249136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "      <td>0.253546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "      <td>0.233550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "      <td>0.253546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>0.240966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>0.253546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleansentence  Cosine similarity\n",
              "1   concept maximum entropy traced back along mult...           0.080322\n",
              "2   scaling conditional random field natural langu...           0.292770\n",
              "3   paper address issue cooperation linguistics na...           0.226779\n",
              "4   natural language processing application descri...           0.377964\n",
              "5   propose unified neural network architecture le...           0.249136\n",
              "..                                                ...                ...\n",
              "95  paper present workbench built priberam informá...           0.253546\n",
              "96  abstractnatural language processing nlp effect...           0.233550\n",
              "97  abstract twenty year disfavor technology retur...           0.253546\n",
              "98  text statistic frequently used stylometry cryp...           0.240966\n",
              "99  summarize experience using framenet two rather...           0.253546\n",
              "\n",
              "[99 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "#The Github link of final CSV file:\n",
        "#Link: https://github.com/DurgalakshmiU/durgaa_INFO5731_Spring2021/blob/main/Abstr%20Sentiment.csv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}