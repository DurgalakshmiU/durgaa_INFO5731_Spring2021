{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurgalakshmiU/durgaa_INFO5731_Spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r4PofXVn4dk"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arv9mZkWn4dz"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58_5kPWFn4d0"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "yV918Mg8n4d1",
        "outputId": "76ccf1c6-98f9-4a20-b832-555de3b6eda9"
      },
      "source": [
        "!pip install TextBlob\n",
        "import pandas as pd\n",
        "d= pd.read_csv(\"/content/Abstr Sentiment.csv\")\n",
        "df=d[[\"cleansentence\"]]\n",
        "d.head(100)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: TextBlob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from TextBlob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->TextBlob) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_ID</th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>95</td>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Document_ID                                      cleansentence Sentiment\n",
              "0             1  concept maximum entropy traced back along mult...   Neutral\n",
              "1             2  scaling conditional random field natural langu...   Neutral\n",
              "2             3  paper address issue cooperation linguistics na...  Negative\n",
              "3             4  natural language processing application descri...  Positive\n",
              "4             5  propose unified neural network architecture le...  Positive\n",
              "..          ...                                                ...       ...\n",
              "94           95  paper present workbench built priberam informá...   Neutral\n",
              "95           96  abstractnatural language processing nlp effect...  Positive\n",
              "96           97  abstract twenty year disfavor technology retur...  Negative\n",
              "97           98  text statistic frequently used stylometry cryp...   Neutral\n",
              "98           99  summarize experience using framenet two rather...  Positive\n",
              "\n",
              "[99 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "dbengNE8qac_",
        "outputId": "add2e6c3-32e5-466e-c0b1-8de4b7e26032"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "df[\"Tokens\"] = df[\"cleansentence\"].apply(lambda x : nltk.word_tokenize(str(x)))\n",
        "df.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>[concept, maximum, entropy, traced, back, alon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>[scaling, conditional, random, field, natural,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>[paper, address, issue, cooperation, linguisti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>[natural, language, processing, application, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>[propose, unified, neural, network, architectu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "      <td>[paper, present, workbench, built, priberam, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "      <td>[abstractnatural, language, processing, nlp, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "      <td>[abstract, twenty, year, disfavor, technology,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>[text, statistic, frequently, used, stylometry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>[summarize, experience, using, framenet, two, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleansentence                                             Tokens\n",
              "0   concept maximum entropy traced back along mult...  [concept, maximum, entropy, traced, back, alon...\n",
              "1   scaling conditional random field natural langu...  [scaling, conditional, random, field, natural,...\n",
              "2   paper address issue cooperation linguistics na...  [paper, address, issue, cooperation, linguisti...\n",
              "3   natural language processing application descri...  [natural, language, processing, application, d...\n",
              "4   propose unified neural network architecture le...  [propose, unified, neural, network, architectu...\n",
              "..                                                ...                                                ...\n",
              "94  paper present workbench built priberam informá...  [paper, present, workbench, built, priberam, i...\n",
              "95  abstractnatural language processing nlp effect...  [abstractnatural, language, processing, nlp, e...\n",
              "96  abstract twenty year disfavor technology retur...  [abstract, twenty, year, disfavor, technology,...\n",
              "97  text statistic frequently used stylometry cryp...  [text, statistic, frequently, used, stylometry...\n",
              "98  summarize experience using framenet two rather...  [summarize, experience, using, framenet, two, ...\n",
              "\n",
              "[99 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "454TsXr-yMIE",
        "outputId": "3746dfc6-a412-42c0-ca3d-a62a3ec08411"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "def cvalues(p):\n",
        "  re =pd.value_counts(p)\n",
        "  if(len(re)==0 ):\n",
        "    re= [0]\n",
        "  return re\n",
        "                                                 \n",
        "df1 = df[\"Tokens\"].apply(lambda x : cvalues(x))  \n",
        "df1 = df1.fillna(0)\n",
        "fi_df = pd.DataFrame(df1.columns, columns=[\"Tokens\"])\n",
        "res = pd.DataFrame(df1.T.sum(axis=1),columns = [\"value\"]).values.tolist()\n",
        "fi_df[\"Frequency\"] = pd.DataFrame(res)\n",
        "from textblob  import TextBlob\n",
        "fi_df[\"Polarity\"] = fi_df['Tokens'].apply(lambda x: TextBlob(x).sentiment.polarity)      #finding polarity\n",
        "i_v = fi_df[\"Polarity\"] != 0\n",
        "i_v_filter = fi_df[i_v]\n",
        "i_v_filter.head(100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>powerful</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>real</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>random</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>natural</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>particular</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910</th>\n",
              "      <td>tedious</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>appropriately</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>considerable</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>educational</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>frequently</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Tokens  Frequency  Polarity\n",
              "5         powerful        3.0  0.300000\n",
              "18            real        1.0  0.200000\n",
              "35          random        1.0 -0.500000\n",
              "36         natural       77.0  0.100000\n",
              "51      particular        3.0  0.166667\n",
              "..             ...        ...       ...\n",
              "910        tedious        1.0 -0.500000\n",
              "922  appropriately        1.0  0.500000\n",
              "935   considerable        1.0  0.100000\n",
              "940    educational        2.0  0.250000\n",
              "961     frequently        1.0  0.100000\n",
              "\n",
              "[91 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "sMhMb_NOz35A",
        "outputId": "8b02a866-3a3f-46eb-db5e-796df49cd206"
      },
      "source": [
        "#ranks based on the frequency\n",
        "Result = i_v_filter.sort_values(by = [\"Frequency\"],ascending = False).reset_index()\n",
        "Result[\"Rank\"] = pd.DataFrame(range(1,200))\n",
        "Result.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>natural</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163</td>\n",
              "      <td>linguistic</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>181</td>\n",
              "      <td>new</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>186</td>\n",
              "      <td>effective</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>536</td>\n",
              "      <td>many</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>57</td>\n",
              "      <td>general</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>216</td>\n",
              "      <td>significant</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>285</td>\n",
              "      <td>limited</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>powerful</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>831</td>\n",
              "      <td>wide</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>239</td>\n",
              "      <td>high</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>375</td>\n",
              "      <td>kind</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>766</td>\n",
              "      <td>single</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>199</td>\n",
              "      <td>lyric</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>393</td>\n",
              "      <td>large</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>417</td>\n",
              "      <td>complex</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.300000</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>745</td>\n",
              "      <td>artificial</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>452</td>\n",
              "      <td>first</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>564</td>\n",
              "      <td>developed</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>204</td>\n",
              "      <td>important</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index       Tokens  Frequency  Polarity  Rank\n",
              "0      36      natural       77.0  0.100000     1\n",
              "1     163   linguistic        8.0  0.100000     2\n",
              "2     181          new        8.0  0.136364     3\n",
              "3     186    effective        7.0  0.600000     4\n",
              "4     536         many        6.0  0.500000     5\n",
              "5      57      general        5.0  0.050000     6\n",
              "6     216  significant        4.0  0.375000     7\n",
              "7     285      limited        4.0 -0.071429     8\n",
              "8       5     powerful        3.0  0.300000     9\n",
              "9     831         wide        3.0 -0.100000    10\n",
              "10    239         high        3.0  0.160000    11\n",
              "11    375         kind        3.0  0.600000    12\n",
              "12    766       single        3.0 -0.071429    13\n",
              "13    199        lyric        3.0  0.250000    14\n",
              "14    393        large        3.0  0.214286    15\n",
              "15    417      complex        3.0 -0.300000    16\n",
              "16    745   artificial        3.0 -0.600000    17\n",
              "17    452        first        3.0  0.250000    18\n",
              "18    564    developed        3.0  0.100000    19\n",
              "19    204    important        3.0  0.400000    20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwSz9aWn4d4"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE98e8h2n4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a86eed78-be02-470c-8189-e9c12cc02e93"
      },
      "source": [
        "#Textblob\n",
        "df2 = d.drop([\"Document_ID\"],axis=1).reset_index()\n",
        "df2[\"Polarity\"] = df2[\"cleansentence\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
        "df2[\"Tblb_Sentiment\"] = pd.cut(df2['Polarity'], bins=3, labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "df2[\"Sentiment\"]=df2[\"Sentiment\"].fillna(\"Negative\")\n",
        "df2.head(100)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Tblb_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0.105556</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>-0.150000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ... Tblb_Sentiment\n",
              "0       0  ...        Neutral\n",
              "1       1  ...       Negative\n",
              "2       2  ...        Neutral\n",
              "3       3  ...       Negative\n",
              "4       4  ...        Neutral\n",
              "..    ...  ...            ...\n",
              "94     94  ...        Neutral\n",
              "95     95  ...       Positive\n",
              "96     96  ...        Neutral\n",
              "97     97  ...        Neutral\n",
              "98     98  ...        Neutral\n",
              "\n",
              "[99 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUBgqMIiDZi",
        "outputId": "950601d5-e157-4975-dd23-8102fa8cbabc"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "textblobaccuracy = accuracy_score(df2['Sentiment'], df2['Tblb_Sentiment'])*100\n",
        "textblobf1_score = f1_score(df2['Sentiment'],df2['Tblb_Sentiment'], average = 'macro')\n",
        "print(\"Text Blob Accuracy : {0} ; F1 Score : {1}\".format(textblobaccuracy, textblobf1_score))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Blob Accuracy : 31.313131313131315 ; F1 Score : 0.22497795414462085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "Lw3LRgs6Ogz9",
        "outputId": "0da51c6c-68fc-4ddb-e505-52ddb6e80096"
      },
      "source": [
        "#Vader\n",
        "df3 = d.drop([\"Document_ID\"],axis=1).reset_index()\n",
        "df3[\"Sentiment\"] =df3[\"Sentiment\"].fillna(\"Negative\")\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sa\n",
        "sentiment_intensity_analyzer = sa()\n",
        "df3[\"Polaritydi\"] = df3[\"cleansentence\"].apply(lambda x: sentiment_intensity_analyzer.polarity_scores(str(x)))\n",
        "df3[\"Polarity\"] = df3[\"cleansentence\"].apply(lambda x: sentiment_intensity_analyzer.polarity_scores(str(x))[\"compound\"])\n",
        "df3['Va_Sentiment'] = pd.cut(df3['Polarity'], bins=3, labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "df3.head(100)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Polaritydi</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Va_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>{'neg': 0.083, 'neu': 0.831, 'pos': 0.086, 'co...</td>\n",
              "      <td>0.0258</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.806, 'pos': 0.194, 'comp...</td>\n",
              "      <td>0.3818</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>paper address issue cooperation linguistics na...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>{'neg': 0.096, 'neu': 0.816, 'pos': 0.089, 'co...</td>\n",
              "      <td>-0.0516</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>natural language processing application descri...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.821, 'pos': 0.179, 'comp...</td>\n",
              "      <td>0.6124</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>propose unified neural network architecture le...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>{'neg': 0.066, 'neu': 0.781, 'pos': 0.153, 'co...</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>paper present workbench built priberam informá...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>abstractnatural language processing nlp effect...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'comp...</td>\n",
              "      <td>0.9186</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>abstract twenty year disfavor technology retur...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.909, 'pos': 0.091, 'comp...</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>{'neg': 0.074, 'neu': 0.842, 'pos': 0.084, 'co...</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>summarize experience using framenet two rather...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>{'neg': 0.099, 'neu': 0.699, 'pos': 0.202, 'co...</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ... Va_Sentiment\n",
              "0       0  ...      Neutral\n",
              "1       1  ...      Neutral\n",
              "2       2  ...      Neutral\n",
              "3       3  ...     Positive\n",
              "4       4  ...      Neutral\n",
              "..    ...  ...          ...\n",
              "94     94  ...      Neutral\n",
              "95     95  ...     Positive\n",
              "96     96  ...      Neutral\n",
              "97     97  ...      Neutral\n",
              "98     98  ...      Neutral\n",
              "\n",
              "[99 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwYq_mHeofWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee6a46e-7b68-4fec-d32e-6abd1f4f7faa"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "vader_accuracy = accuracy_score(df3['Sentiment'],df3['Va_Sentiment'])*100\n",
        "vaderf1_score = f1_score(df3['Sentiment'],df3['Va_Sentiment'], average = 'macro')\n",
        "print(\"Vader Accuracy : {0} ; F1 Score : {1}\".format(vader_accuracy, vaderf1_score))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vader Accuracy : 42.42424242424242 ; F1 Score : 0.37585672952948507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOicKndIRvAV"
      },
      "source": [
        "#SVM\n",
        "from sklearn import feature_extraction, model_selection, svm, linear_model\n",
        "df4 = d[[\"cleansentence\",\"Sentiment\"]].reset_index()\n",
        "df4[\"Sentiment\"] = df4[\"Sentiment\"].fillna(\"Negative\")\n",
        "df4[\"cleansentence\"] =df4[\"cleansentence\"].fillna(\"  \")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lsLnzlk8Sdj8",
        "outputId": "d0eedd4d-0087-4452-837e-cd644b877439"
      },
      "source": [
        "train, test = model_selection.train_test_split(df4, test_size = 0.5)\n",
        "import sklearn\n",
        "from sklearn.pipeline import Pipeline as pipe\n",
        "pipeline = pipe([('countvector', feature_extraction.text.CountVectorizer()),('tf-idf', feature_extraction.text.TfidfTransformer()),('classifier', linear_model.SGDClassifier())])\n",
        "vector = pipeline.fit(train['cleansentence'], train['Sentiment'])\n",
        "test['SVM_Sentiment'] = vector.predict(test['cleansentence'])\n",
        "test.head(30)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>cleansentence</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SVM_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>natural language processing nlp branch artific...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>abstract many information retrievalir system r...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>paper review process involved natural language...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>information retrieval process finding document...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>work computational linguistics began soon deve...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>abstract metabolism machinery life signal tran...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>recent year machine learning ml used solve com...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>robot interact human facetoface using natural ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>88</td>\n",
              "      <td>lexsign senseid senseid dictionary ldoce lexsi...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>developed prototype information retrieval syst...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>68</td>\n",
              "      <td>natural language processing nlp large diverse ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>information retrieval address problem finding ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>abstract natural language processing study mat...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>abstractnatural language processing nlp applic...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>propose bifurcated paradigm construction prolo...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>concept maximum entropy traced back along mult...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>applied structure learning model maxmargin str...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>abstract thesis examines use machine learning ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>chapter basic us description logic natural lan...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>abstract paper explains information retrieval ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td></td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>web emerged important source information world...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>chapter examines application natural language ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>introduce method analyzing complexity natural ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>abstract article explores possibility construc...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>traditional approach tointerpretation natural ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>sri developed new architecture integrating spe...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>abstract natural language processing theoretic...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>report present detailed analysis review nlp ev...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>fundamental issue natural language processing ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ... SVM_Sentiment\n",
              "81     81  ...       Neutral\n",
              "39     39  ...       Neutral\n",
              "23     23  ...      Positive\n",
              "61     61  ...       Neutral\n",
              "30     30  ...      Negative\n",
              "19     19  ...       Neutral\n",
              "36     36  ...       Neutral\n",
              "6       6  ...      Positive\n",
              "88     88  ...       Neutral\n",
              "75     75  ...       Neutral\n",
              "68     68  ...       Neutral\n",
              "29     29  ...       Neutral\n",
              "80     80  ...      Negative\n",
              "28     28  ...      Negative\n",
              "73     73  ...      Positive\n",
              "0       0  ...       Neutral\n",
              "50     50  ...      Positive\n",
              "65     65  ...       Neutral\n",
              "49     49  ...      Negative\n",
              "58     58  ...      Negative\n",
              "76     76  ...      Negative\n",
              "21     21  ...      Negative\n",
              "84     84  ...      Negative\n",
              "25     25  ...       Neutral\n",
              "15     15  ...      Positive\n",
              "67     67  ...       Neutral\n",
              "46     46  ...      Positive\n",
              "22     22  ...      Positive\n",
              "20     20  ...       Neutral\n",
              "91     91  ...      Positive\n",
              "\n",
              "[30 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ_bFzd5U6vS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772e88df-d6d7-48db-d1fb-7c2d17de379b"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "SVM_accuracy = accuracy_score(test['Sentiment'], test['SVM_Sentiment'])*100\n",
        "SVMf1_score = f1_score(test['Sentiment'],test['SVM_Sentiment'], average = 'macro')\n",
        "print(\"SVM accuracy : {0} ; F1 Score : {1}\".format(SVM_accuracy, SVMf1_score))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM accuracy : 50.0 ; F1 Score : 0.49548668419015013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0696Y9_vk6s"
      },
      "source": [
        "'''\n",
        "Comparing all the three in sentiment Identifcation i found SVM is better than \n",
        "other two because as we can see the F1-score for SVM is higher than vader and \n",
        "Textblob.Therefore,SVM is better than vader and textblob in sentiment identification.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}